{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import CatVsDogs\n",
    "import Shared\n",
    "\n",
    "Shared.DIM = 299\n",
    "CatVsDogs.DIM = 299\n",
    "\n",
    "import tensorflow as tf\n",
    "from nets import inception_v3\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "parser = Shared.define_parser(klass='InceptionV3')\n",
    "parser.add_argument('--deep-logits', dest='deep_logits', default=False, action='store_true', help='Deep Logits?')\n",
    "parser.add_argument('--depth', nargs='*', help='Special Deep Logits Architecture?')\n",
    "parser.add_argument('--aux-logits', dest='aux_logits', default=False, action='store_true', help='Deep Aux Logits?')\n",
    "args, unknown_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InceptionV3:\n",
    "    def __init__(self, model_name, isTesting=False):\n",
    "        Shared.define_model(self, model_name, self.__model)\n",
    "    \n",
    "    def __get_init_fn(self):\n",
    "        return Shared.get_init_fn('inception_v3.ckpt', [\"InceptionV3/Logits\", \"InceptionV3/AuxLogits\"])\n",
    "        \n",
    "    def __model(self):\n",
    "        # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "        with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "            self.logits, self.end_points = inception_v3.inception_v3(self.X_Norm, 2, is_training=True)\n",
    "        \n",
    "        if args.deep_logits:\n",
    "            with tf.variable_scope('InceptionV3/Logits') as scope:\n",
    "                self.PreLogitsFlatten = slim.flatten(self.end_points['PreLogits'])\n",
    "                self.logits = slim.fully_connected(self.PreLogitsFlatten, 200)\n",
    "                self.logits = slim.fully_connected(self.logits, 2, activation_fn=None)\n",
    "        \n",
    "        if args.depth is not None and len(args.depth) > 0:\n",
    "            with tf.variable_scope('InceptionV3/Logits') as scope:\n",
    "                self.PreLogitsFlatten = slim.flatten(self.end_points['PreLogits'])\n",
    "                # Connect Input Layer\n",
    "                self.logits = slim.fully_connected(self.PreLogitsFlatten, int(args.depth[0])) # scope='fc0'\n",
    "                # Intermediary Layers\n",
    "                for idx, i in enumerate(args.depth[1:]):\n",
    "                    self.logits = slim.fully_connected(self.logits, int(i)) # scope='fc{}'.format(idx)\n",
    "                # Connect Output Layer\n",
    "                self.logits = slim.fully_connected(self.logits, 2, activation_fn=None) # scope='fc{}'.format(len(args.depth))\n",
    "        \n",
    "        if args.aux_logits:\n",
    "            self.logits = self.logits + self.end_points['AuxLogits']\n",
    "    \n",
    "    def train(self, sess, X, y, val_X, val_y, epochs=30, minibatch_size=50, optimizer=None):\n",
    "        self.init_fn = self.__get_init_fn()\n",
    "        return Shared.train_model(self, sess, X, y, val_X, val_y, epochs, minibatch_size, optimizer)\n",
    "        \n",
    "    def load_model(self, sess):\n",
    "        return Shared.load_model(self, sess)\n",
    "    \n",
    "    def predict_proba(self, sess, X, step=10):\n",
    "        return Shared.predict_proba(self, sess, X, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    Shared.main(InceptionV3, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
