{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "from sklearn.metrics import log_loss as nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alexNetPred_X_Original = np.load('Prediction.X.alexnet.distracted_driver.original.1.npy')\n",
    "alexNetPred_Xt_Original = np.load('Prediction.Xt.alexnet.distracted_driver.original.1.npy')\n",
    "alexNetPred_X_Segmented = np.load('Prediction.X.alexnet.distracted_driver.segmented.1.npy')\n",
    "alexNetPred_Xt_Segmented = np.load('Prediction.Xt.alexnet.distracted_driver.segmented.1.npy')\n",
    "alexNetPred_X_Face = np.load('Prediction.X.alexnet.distracted_driver.face.1.npy')\n",
    "alexNetPred_Xt_Face = np.load('Prediction.Xt.alexnet.distracted_driver.face.1.npy')\n",
    "alexNetPred_X_Hands = np.load('Prediction.X.alexnet.distracted_driver.hands.1.npy')\n",
    "alexNetPred_Xt_Hands = np.load('Prediction.Xt.alexnet.distracted_driver.hands.1.npy')\n",
    "alexNetPred_X_HandsAndFace = np.load('Prediction.X.alexnet.distracted_driver.hands_and_face.1.npy')\n",
    "alexNetPred_Xt_HandsAndFace = np.load('Prediction.Xt.alexnet.distracted_driver.hands_and_face.1.npy')\n",
    "inceptionV3Pred_X_Original = np.load('Prediction.X.inceptionV3.distracted_driver.original.1.npy')\n",
    "inceptionV3Pred_Xt_Original = np.load('Prediction.Xt.inceptionV3.distracted_driver.original.1.npy')\n",
    "inceptionV3Pred_X_Segmented = np.load('Prediction.X.inceptionV3.distracted_driver.segmented.1.npy')\n",
    "inceptionV3Pred_Xt_Segmented = np.load('Prediction.Xt.inceptionV3.distracted_driver.segmented.1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.load('cache/y.original.npy')\n",
    "yt = np.load('cache/yt.original.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble_train = [alexNetPred_X_Original, alexNetPred_X_Segmented, inceptionV3Pred_X_Original, inceptionV3Pred_X_Segmented, alexNetPred_X_Face, alexNetPred_X_Hands, alexNetPred_X_HandsAndFace] # \n",
    "ensemble_test = [alexNetPred_Xt_Original, alexNetPred_Xt_Segmented, inceptionV3Pred_Xt_Original, inceptionV3Pred_Xt_Segmented, alexNetPred_Xt_Face, alexNetPred_Xt_Hands, alexNetPred_Xt_HandsAndFace] #\n",
    "ensemble = reduce(lambda prev, curr: prev + curr, ensemble_test[1:], ensemble_test[0]) / len(ensemble_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93650427153082427"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred=alexNetPred_Xt_Original.argmax(axis=1), y_true=yt.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95428307550219349"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred=ensemble.argmax(axis=1), y_true=yt.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1897657263118924"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_pred=ensemble, y_true=yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_original = (alexNetPred_Xt_Original + inceptionV3Pred_Xt_Original)/2\n",
    "ensemble_segmented = (alexNetPred_Xt_Segmented + inceptionV3Pred_Xt_Segmented)/2\n",
    "ensemble_alexNet = (alexNetPred_Xt_Original + alexNetPred_Xt_Segmented)/2\n",
    "ensemble_inceptionV3 = (inceptionV3Pred_Xt_Original + inceptionV3Pred_Xt_Segmented)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951743246363\n",
      "0.234407342475\n",
      "0.949434310783\n",
      "0.235844395067\n",
      "0.942969291157\n",
      "0.272703629376\n",
      "0.955437543293\n",
      "0.223215475659\n"
     ]
    }
   ],
   "source": [
    "print metrics.accuracy_score(y_pred=ensemble_original.argmax(axis=1), y_true=yt.argmax(axis=1))\n",
    "print metrics.log_loss(y_pred=ensemble_original, y_true=yt)\n",
    "\n",
    "print metrics.accuracy_score(y_pred=ensemble_segmented.argmax(axis=1), y_true=yt.argmax(axis=1))\n",
    "print metrics.log_loss(y_pred=ensemble_segmented, y_true=yt)\n",
    "\n",
    "print metrics.accuracy_score(y_pred=ensemble_alexNet.argmax(axis=1), y_true=yt.argmax(axis=1))\n",
    "print metrics.log_loss(y_pred=ensemble_alexNet, y_true=yt)\n",
    "\n",
    "print metrics.accuracy_score(y_pred=ensemble_inceptionV3.argmax(axis=1), y_true=yt.argmax(axis=1))\n",
    "print metrics.log_loss(y_pred=ensemble_inceptionV3, y_true=yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23440734247500472"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_pred=ensemble, y_true=yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yt_seg = np.load('cache/yt.segmented.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Simple Network.')\n",
    "parser.add_argument('--gpu', default=3, help='GPU to use for train')\n",
    "parser.add_argument('--name', default=\"ensemble_network_distracted_driver.1\", help='Name of the model to use for train')\n",
    "args, unknown_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Shared\n",
    "\n",
    "Shared.select_gpu(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleNetwork():\n",
    "    def __init__(self, name, n_in, n_out, start_learning_rate=0.1, end_learning_rate=0.0001):\n",
    "        tf.reset_default_graph()\n",
    "        self.name = name\n",
    "        with tf.name_scope(\"SimpleNetwork\") as scope:\n",
    "            self.X = []\n",
    "            for i in range(n_in):\n",
    "                self.X += [tf.placeholder(tf.float32, shape=[None, n_out], name=\"X{}\".format(i))]\n",
    "\n",
    "            self.Y = tf.placeholder(tf.float32, shape=[None, n_out], name=\"Y\")\n",
    "            \n",
    "            self.W = [\n",
    "                slim.variable('W{}'.format(i),\n",
    "                             shape=[1],\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "                for i in range(n_in)\n",
    "            ]\n",
    "            \n",
    "            self.Logits = self.W[0] * self.X[0]\n",
    "            for i in range(n_in)[1:]:\n",
    "                self.Logits = self.Logits + self.weights[i] * self.X[i]\n",
    "            \n",
    "            self.Total = self.W[0]\n",
    "            for w in self.W[1:]:\n",
    "                self.Total += w\n",
    "                \n",
    "            self.Probs = tf.nn.softmax(self.Logits)\n",
    "\n",
    "            self.Cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.Logits, self.Y))\n",
    "            self.Optimizer = tf.train.AdamOptimizer(epsilon=.1, learning_rate=0.001).minimize(self.Cost)\n",
    "\n",
    "            # Evaluate model\n",
    "            self.CorrectPred = tf.equal(tf.argmax(self.Logits,1), tf.argmax(self.Y,1))\n",
    "            self.Top5CorrectPred = tf.nn.in_top_k(self.Probs, tf.argmax(self.Y,1), 5)\n",
    "\n",
    "            self.Accuracy = tf.reduce_mean(tf.cast(self.CorrectPred, tf.float32))\n",
    "            self.Top5Accuracy = tf.reduce_mean(tf.cast(self.Top5CorrectPred, tf.float32))\n",
    "            \n",
    "            self.saver = tf.train.Saver()\n",
    "    \n",
    "    def __iterate_minibatches(self, X,y, size):\n",
    "        '''Iterates over X and y in batches of a certain size'''\n",
    "        # if X.shape[0] % size > 0:\n",
    "        #     raise \"The minibatch size should be a divisor of the batch size.\"\n",
    "        \n",
    "        total = X[0].shape[0]\n",
    "        idx = np.arange(total)\n",
    "        np.random.shuffle(idx) # in-place shuffling\n",
    "        for i in range(total / size):\n",
    "            # To randomize the minibatches every time\n",
    "            _idx = idx[i*size:(i+1)*size]\n",
    "            yield [_X[_idx] for _X in X], y[_idx]\n",
    "    \n",
    "    def predict_proba(model, sess, X, step=10):\n",
    "        fc3ls = []\n",
    "\n",
    "        size = X[0].shape[0]\n",
    "        sample_idx = random.sample(range(0, size), size)\n",
    "        reverse_idx = list(map(sample_idx.index, range(0,size)))\n",
    "        for i in range(int(np.ceil(float(size) / step))):\n",
    "            feed_dict={}\n",
    "            for ModelX, BatchX in zip(model.X, X):\n",
    "                feed_dict[ModelX] = BatchX\n",
    "                \n",
    "            fc3l = sess.run(model.Logits, feed_dict=feed_dict)\n",
    "            fc3ls.append(fc3l)\n",
    "        \n",
    "        preds = np.vstack(fc3ls)\n",
    "        probs = sess.run(model.Probs, feed_dict={model.Logits: preds})\n",
    "\n",
    "        return preds[reverse_idx], probs[reverse_idx]\n",
    "    \n",
    "    def calculate_loss(self, sess, Xt, yt, size=1000, step=10):\n",
    "        preds, probs = self.predict_proba(sess, Xt, step=step)\n",
    "\n",
    "        loss, acc, top5acc = sess.run([self.Cost, self.Accuracy, self.Top5Accuracy], feed_dict={self.Logits: preds, self.Y: yt})\n",
    "\n",
    "        return loss, acc, top5acc\n",
    "        \n",
    "    def train(self, sess, X, Y, Xt, Yt, epochs=100, batch_size=100, display_step=25):\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        self.prev_acc = 10\n",
    "        for ep in range(epochs):\n",
    "            print(\"==== EPOCH {} ====\".format(ep))\n",
    "            step = 1\n",
    "            for _X, _Y in self.__iterate_minibatches(X, Y, batch_size):\n",
    "                feed_dict={self.Y: _Y}\n",
    "                for ModelX, BatchX in zip(self.X, _X):\n",
    "                    feed_dict[ModelX] = BatchX\n",
    "\n",
    "                sess.run(self.Optimizer, feed_dict=feed_dict)\n",
    "                if step % display_step == 0:\n",
    "                    loss, acc, top5acc = self.calculate_loss(sess, Xt, Yt)\n",
    "                    print(\"Iter \" + str(step) + \", Loss= \" + \"{:.4f}\".format(loss) + \", Acc= \" + \"{:.4f}\".format(acc) + \", Top-5 Acc= \" + \"{:.4f}\".format(top5acc))\n",
    "                step += 1\n",
    "\n",
    "            loss, acc, top5acc = self.calculate_loss(sess, Xt, Yt, size=Xt[0].shape[0])\n",
    "            print(\"====================================\")\n",
    "            print(\"Epoch {}: Loss={} Acc={} Top-5 Acc={}\".format(ep, loss, acc, top5acc))\n",
    "            print(\"====================================\")\n",
    "            if loss < self.prev_acc:\n",
    "                self.prev_acc = loss\n",
    "                self.saver.save(sess, \"{}.tfmodel\".format(self.name))\n",
    "                print(\"++++ Saved BEST LOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack(ensemble_train)\n",
    "Xt = np.hstack(ensemble_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = SimpleNetwork(args.name, len(ensemble_train), yt.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH 0 ====\n",
      "Iter 25, Loss= 2.3041, Acc= 0.1298, Top-5 Acc= 0.5110\n",
      "Iter 50, Loss= 2.3128, Acc= 0.1194, Top-5 Acc= 0.5031\n",
      "Iter 75, Loss= 2.3128, Acc= 0.1242, Top-5 Acc= 0.5031\n",
      "Iter 100, Loss= 2.3249, Acc= 0.1136, Top-5 Acc= 0.5216\n",
      "Iter 125, Loss= 2.3317, Acc= 0.1118, Top-5 Acc= 0.5033\n",
      "Iter 150, Loss= 2.3280, Acc= 0.1240, Top-5 Acc= 0.5190\n",
      "Iter 175, Loss= 2.3323, Acc= 0.1272, Top-5 Acc= 0.5124\n",
      "Iter 200, Loss= 2.3369, Acc= 0.1286, Top-5 Acc= 0.5253\n",
      "Iter 225, Loss= 2.3567, Acc= 0.1196, Top-5 Acc= 0.5200\n",
      "Iter 250, Loss= 2.3646, Acc= 0.1210, Top-5 Acc= 0.5264\n",
      "====================================\n",
      "Epoch 0: Loss=2.37286639214 Acc=0.115908548236 Top-5 Acc=0.522973835468\n",
      "====================================\n",
      "++++ Saved BEST LOSS\n",
      "==== EPOCH 1 ====\n",
      "Iter 25, Loss= 2.3726, Acc= 0.1258, Top-5 Acc= 0.5509\n",
      "Iter 50, Loss= 2.3857, Acc= 0.1242, Top-5 Acc= 0.5502\n",
      "Iter 75, Loss= 2.3994, Acc= 0.1233, Top-5 Acc= 0.5451\n",
      "Iter 100, Loss= 2.4335, Acc= 0.1106, Top-5 Acc= 0.5359\n",
      "Iter 125, Loss= 2.4292, Acc= 0.1238, Top-5 Acc= 0.5398\n",
      "Iter 150, Loss= 2.4419, Acc= 0.1256, Top-5 Acc= 0.5398\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-572e91a67333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-128-e70f029275f6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, X, Y, Xt, Yt, epochs, batch_size, display_step)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iter \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Loss= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Acc= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Top-5 Acc= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop5acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-128-e70f029275f6>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(self, sess, Xt, yt, size, step)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTop5Accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-128-e70f029275f6>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(model, sess, X, step)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModelX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mfc3l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mfc3ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc3l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    867\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[0;32m--> 869\u001b[0;31m                                                     allow_operation=False)\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    net.train(sess, ensemble_train, y, ensemble_test, yt, batch_size=50, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
