{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = argparse.ArgumentParser(description='RNN-CNN Network.')\n",
    "parser.add_argument('--gpu', default=3, help='GPU to use for train')\n",
    "parser.add_argument('--name', default=\"cats_vs_dogs_model\", help='Name of the RNN model to use for train')\n",
    "args, unknown_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "from os import listdir, environ\n",
    "import pandas as pd\n",
    "from IPython import embed\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from datasets import flowers\n",
    "from nets import inception\n",
    "from preprocessing import inception_preprocessing\n",
    "\n",
    "from datasets import dataset_utils\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "BEST_ACC = 0\n",
    "CHECKPOINTS_DIR = \"checkpoints/\"\n",
    "\n",
    "class InceptionV4:\n",
    "    def __init__(self, model_name, isTesting=False):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, 299,299,3])\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "        \n",
    "        self.X_preproc = tf.map_fn(lambda image: inception_preprocessing.preprocess_image(image, 299, 299), self.X)\n",
    "\n",
    "        self.name = model_name\n",
    "        \n",
    "        self.__model()\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        # Just in case a previous run was closed using a halt file.\n",
    "        if os.path.isfile(\"{}.halt\".format(self.name)):\n",
    "            os.remove(\"{}.halt\".format(self.name))\n",
    "\n",
    "        # if weights is not None and sess is not None:\n",
    "        #     self.load_weights(sess, weights)\n",
    "    \n",
    "    def __get_init_fn(self):\n",
    "        \"\"\"Returns a function run by the chief worker to warm-start the training.\"\"\"\n",
    "        checkpoint_exclude_scopes=[\"InceptionV4/Logits\", \"InceptionV4/AuxLogits\"]\n",
    "\n",
    "        exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "        variables_to_restore = []\n",
    "        for var in slim.get_model_variables():\n",
    "            excluded = False\n",
    "            for exclusion in exclusions:\n",
    "                if var.op.name.startswith(exclusion):\n",
    "                    excluded = True\n",
    "                    break\n",
    "            if not excluded:\n",
    "                variables_to_restore.append(var)\n",
    "\n",
    "        return slim.assign_from_checkpoint_fn(\n",
    "          os.path.join(CHECKPOINTS_DIR, 'inception_v4.ckpt'),\n",
    "          variables_to_restore)\n",
    "        \n",
    "    def __model(self):\n",
    "        self.image_size = inception.inception_v4.default_image_size\n",
    "\n",
    "        # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "        with slim.arg_scope(inception.inception_v4_arg_scope()):\n",
    "            self.logits, self.end_points = inception.inception_v4(self.X_preproc, num_classes=2, is_training=False)\n",
    "\n",
    "        # Specify the loss function:\n",
    "#         slim.losses.softmax_cross_entropy(self.logits, self.y)\n",
    "#         self.total_loss = slim.losses.get_total_loss()\n",
    "        self.total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.logits, self.y))\n",
    "        \n",
    "        self.probs = self.end_points[\"Predictions\"]\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.probs, 1), tf.argmax(self.y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        # Specify the optimizer and create the train op:\n",
    "        self.optimizer = tf.train.AdamOptimizer(epsilon=0.1)\n",
    "        self.train_step = slim.learning.create_train_op(self.total_loss, self.optimizer)\n",
    "\n",
    "        self.init_fn = self.__get_init_fn()\n",
    "\n",
    "    def __iterate_minibatches(self, X,y, size):\n",
    "        if X.shape[0] % size > 0:\n",
    "            raise \"The minibatch size should be a divisor of the batch size.\"\n",
    "\n",
    "        idx = np.arange(X.shape[0])\n",
    "        np.random.shuffle(idx) # in-place shuffling\n",
    "        for i in range(X.shape[0] / size):\n",
    "            # To randomize the minibatches every time\n",
    "            _idx = idx[i*size:(i+1)*size]\n",
    "            yield X[_idx], y[_idx]\n",
    "\n",
    "    def __update_screen(self, msg):\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def resize_images(self, X):\n",
    "        return np.array([ imresize(X[i], (299,299)) for i in range(X.shape[0])])\n",
    "    \n",
    "    def generate_base_features(self, sess, Xt, prefix=\"X\", size=1000, step=50):\n",
    "        images = []\n",
    "        sample_idx = range(0, size)\n",
    "        for i in range(size / step):\n",
    "            [image] = sess.run([self.end_points['PreLogitsFlatten']], feed_dict={self.X: Xt[sample_idx[i*step:(i+1)*step]] })\n",
    "            images.append(image)\n",
    "            self.__update_screen(\"\\r{} out of {}\".format(i, size/step))\n",
    "\n",
    "        images = np.vstack(images)\n",
    "        np.save(\"inception_catdogs/{}.npy\".format(prefix), images)\n",
    "        return images\n",
    "    \n",
    "    def calculate_loss(self, sess, Xt, yt, size=1000, step=10):\n",
    "        fc3ls = None\n",
    "        sample_idx = random.sample(range(0, Xt.shape[0]), size)\n",
    "        for i in range(size / step):\n",
    "            [fc3l] = sess.run([self.logits], feed_dict={self.X: Xt[sample_idx[i*step:(i+1)*step]], self.y: yt[sample_idx[i*step:(i+1)*step]]})\n",
    "            if i == 0:\n",
    "                fc3ls = fc3l\n",
    "            else:\n",
    "                fc3ls = np.vstack((fc3ls, fc3l))\n",
    "\n",
    "        loss, accuracy = sess.run([self.total_loss, self.accuracy], feed_dict={self.logits: fc3ls, self.y: yt[sample_idx]})\n",
    "\n",
    "        return loss, accuracy\n",
    "\n",
    "    def __graceful_halt(self, t_start_training):\n",
    "        # Save Trained Model\n",
    "        p = self.saver.save(sess, \"{}.tfmodel\".format(self.name))\n",
    "        t = time.time() - t_start_training\n",
    "        print(\"++ Training: END -- Exec. Time={0:.0f}m {1:.0f}s Model Path={2:s}\".format(t / 60, t % 60, p))\n",
    "\n",
    "\n",
    "    def train(self, sess, X, y, val_X, val_y, epochs=30, minibatch_size=500, optimizer=None):\n",
    "        print(\"++ Training with {} epochs and {} minibatch size.\".format(epochs, minibatch_size))\n",
    "        \n",
    "        BEST_ACC = 0\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            self.optimizer = optimizer\n",
    "        \n",
    "        # Initialize Model ...\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        self.init_fn(sess)\n",
    "        \n",
    "        # Resize Validation Once ...\n",
    "        val_X_res = self.resize_images(val_X)\n",
    "\n",
    "        t_start_training = time.time()\n",
    "        for i in range(epochs):\n",
    "            t_start_epoch = time.time()\n",
    "            t_start_minibatch = time.time()\n",
    "            print(\"+++ Epoch 1: START\")\n",
    "            cnt = 0\n",
    "            for _X, _y in self.__iterate_minibatches(X, y, minibatch_size):\n",
    "                # Resize Training Batches (to avoid consuming much memeory)\n",
    "                cnt += 1\n",
    "                _X_res = self.resize_images(_X)\n",
    "                self.__update_screen(\"\\r++++ Mini Batch ({} out of {}): \".format(cnt, X.shape[0]/minibatch_size))\n",
    "                sess.run([self.train_step], feed_dict={vgg.X: _X_res, vgg.y: _y})\n",
    "                if cnt % 25 == 0:\n",
    "                    # loss, accuracy = sess.run([self.cross_entropy, self.accuracy], feed_dict={self.X: val_X_res[test_sample], self.y: val_y[test_sample]})\n",
    "                    val_loss, val_accuracy = self.calculate_loss(sess, val_X_res, val_y, 1000)\n",
    "                    t = time.time() - t_start_minibatch\n",
    "                    self.__update_screen(\" Loss={0:.4f} Accuracy={1:.4f} Exec. Time={2:.0f}m {3:.0f}s\\n\".format(val_loss, val_accuracy, t / 60, t % 60))\n",
    "                    t_start_minibatch = time.time()\n",
    "\n",
    "                    # Handle Close Signals\n",
    "                    if os.path.isfile(\"{}.halt\".format(self.name)):\n",
    "                        self.__graceful_halt(t_start_training)\n",
    "                        os.remove(\"{}.halt\".format(self.name))\n",
    "                        exit(0)\n",
    "\n",
    "            self.__update_screen(\"\\n\")\n",
    "            val_loss, val_accuracy = self.calculate_loss(sess, val_X_res, val_y, val_X.shape[0])\n",
    "            t = time.time() - t_start_epoch\n",
    "            print(\"+++ Epoch {0:.0f}: END -- Loss={1:.4f} Accuracy={2:.4f} Exec. Time={3:.0f}m {4:.0f}s\".format(i, val_loss, val_accuracy, t / 60, t % 60))\n",
    "\n",
    "            # Always Save Best Accuracy\n",
    "            if val_accuracy > BEST_ACC:\n",
    "                BEST_ACC = val_accuracy\n",
    "                self.saver.save(sess, \"{}.tfmodel\".format(self.name))\n",
    "                print(\"+++ Epoch {0:.0f}: END -- SAVED BEST ACC\".format(i))\n",
    "\n",
    "        self.__graceful_halt(t_start_training)\n",
    "\n",
    "\n",
    "    def predict(self, sess, X):\n",
    "        prob = sess.run(vgg.probs, feed_dict={vgg.X: [X]})[0]\n",
    "        preds = (np.argsort(prob)[::-1])[0:5]\n",
    "        for p in preds:\n",
    "            print p, prob[p]\n",
    "\n",
    "\n",
    "\n",
    "    def load_weights(self, sess, weight_file):\n",
    "        # This includes optimizer variables as well.\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess.run(init)\n",
    "\n",
    "        weights = np.load(weight_file)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            if i == 30:\n",
    "                break\n",
    "            print i, k, np.shape(weights[k])\n",
    "            sess.run(self.parameters[i].assign(weights[k]))\n",
    "\n",
    "        # Transfer Learning\n",
    "        # Initialize the last fully connected layer\n",
    "        for par in self.parameters[-2:]:\n",
    "            print(\"Param: {}\".format(par.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_screen(msg):\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    TRAIN_DIR = '/home/devyhia/cats.vs.dogs/train/'\n",
    "    TEST_DIR = '/home/devyhia/cats.vs.dogs/test/'\n",
    "\n",
    "    ROWS = 299\n",
    "    COLS = 299\n",
    "    CHANNELS = 3\n",
    "    SLICE = 10000\n",
    "\n",
    "    train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "    train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "    train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "    # test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "\n",
    "    # slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "#     train_images = train_dogs[:SLICE] + train_cats[:SLICE]\n",
    "#     valid_images = train_dogs[SLICE:] + train_cats[SLICE:]\n",
    "\n",
    "#     np.random.shuffle(train_images)\n",
    "#     np.random.shuffle(valid_images)\n",
    "\n",
    "    def read_image(file_path):\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "        return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    def prep_data(images):\n",
    "        count = len(images)\n",
    "        data = np.ndarray((count, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "        for i, image_file in enumerate(images):\n",
    "            data[i] = read_image(image_file).astype(np.float32)\n",
    "            if i%250 == 0: update_screen('\\rProcessed {} of {}'.format(i, count))\n",
    "        \n",
    "        update_screen('\\n')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def get_label(path):\n",
    "        return 1 if re.search(\"(cat|dog)\\.(\\d+)\\.\", path).group(1) == 'cat' else 0\n",
    "    \n",
    "    print(\"Prep data ...\")\n",
    "    X = prep_data(train_images)\n",
    "#     Xt = prep_data(valid_images)\n",
    "    # test = prep_data(test_images)\n",
    "    \n",
    "#     pre_processing = tf.placeholder(tf.float32, shape=[None, 299,299,3])\n",
    "#     after_processing = tf.sub(tf.mul(pre_processing, 2.0/255.), 1.0)\n",
    "    \n",
    "#     def preprocess(sess, X, i, batch_size):\n",
    "#         update_screen(\"\\rPreprocessing {} ...\".format(i))\n",
    "#         return sess.run(after_processing, feed_dict={pre_processing: X[i*batch_size:(i+1)*batch_size]})\n",
    "    \n",
    "#     with tf.Session() as sess:\n",
    "#         Xs, Xts = [], []\n",
    "#         batch_size = 200\n",
    "        \n",
    "#         for i in range(X.shape[0] / batch_size):\n",
    "#             Xs.append(preprocess(sess, X, i, batch_size))\n",
    "#         update_screen(\"\\n\")\n",
    "        \n",
    "#         for i in range(Xt.shape[0] / batch_size):\n",
    "#             Xts.append(preprocess(sess, Xt, i, batch_size))\n",
    "#         update_screen(\"\\n\")\n",
    "        \n",
    "#         X = np.vstack(Xs)\n",
    "#         Xt = np.vstack(Xts)\n",
    "        \n",
    "    print(\"Train shape: {}\".format(X.shape))\n",
    "#     print(\"Valid shape: {}\".format(Xt.shape))\n",
    "\n",
    "    labels_train = [get_label(i) for i in train_images]\n",
    "#     labels_valid = [get_label(i) for i in valid_images]\n",
    "\n",
    "    print(pd.DataFrame(labels_train, columns=[\"label\"])[\"label\"].value_counts())\n",
    "#     print(pd.DataFrame(labels_valid, columns=[\"label\"])[\"label\"].value_counts())\n",
    "\n",
    "    y = np.zeros((X.shape[0], 2))\n",
    "#     yt = np.zeros((Xt.shape[0], 2))\n",
    "\n",
    "    for i in range(y.shape[0]):\n",
    "        y[i, labels_train[i]] = 1\n",
    "\n",
    "#     for i in range(yt.shape[0]):\n",
    "#         yt[i, labels_valid[i]] = 1\n",
    "\n",
    "    # print(labels_train)\n",
    "    # print(labels_valid)\n",
    "\n",
    "    print(y)\n",
    "#     print(yt)\n",
    "\n",
    "    print(\"X=\", X.shape, \"y=\", y.shape)\n",
    "#     print(\"Xt=\", Xt.shape, \"yt=\", yt.shape)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def prepare_test_data():\n",
    "    CACHE_PATH = \"cache/Xt.npy\"\n",
    "    if os.path.isfile(CACHE_PATH):\n",
    "        data = np.load(CACHE_PATH)\n",
    "        return range(1, data.shape[0]+1), data\n",
    "\n",
    "    TEST_DIR = '/home/devyhia/cats.vs.dogs/test/'\n",
    "\n",
    "    ROWS = 299\n",
    "    COLS = 299\n",
    "    CHANNELS = 3\n",
    "\n",
    "    file_key = lambda f: int(re.match(\"(\\d+)\\.jpg\", f).group(1))\n",
    "    test_images =  [TEST_DIR+i for i in sorted(os.listdir(TEST_DIR), key=file_key)]\n",
    "\n",
    "    def read_image(file_path):\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "        return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    def prep_data(images):\n",
    "        count = len(images)\n",
    "        data = np.ndarray((count, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "        ids = []\n",
    "\n",
    "        for i, image_file in enumerate(images):\n",
    "            data[i] = read_image(image_file)\n",
    "            ids.append(re.search(\"(\\d+)\\.\", image_file).group(1))\n",
    "\n",
    "            if i%250 == 0: update_screen('\\rProcessed {} of {}'.format(i, count))\n",
    "        \n",
    "        update_screen('\\n')\n",
    "        \n",
    "        return ids, data\n",
    "\n",
    "    ids, data = prep_data(test_images)\n",
    "\n",
    "    np.save(CACHE_PATH, data)\n",
    "\n",
    "    return ids, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "\n",
    "DATA_DIR = \"/home/devyhia/vgg/\"\n",
    "\n",
    "model_name = args.name\n",
    "vgg = InceptionV4(model_name)\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prep data ...\n",
      "Processed 24750 of 25000\n",
      "Train shape: (25000, 299, 299, 3)\n",
      "1    12500\n",
      "0    12500\n",
      "Name: label, dtype: int64\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "('X=', (25000, 299, 299, 3), 'y=', (25000, 2))\n"
     ]
    }
   ],
   "source": [
    "# tinyImageNetDir = \"/home/devyhia/vgg\"\n",
    "# X, y = np.load(\"{}/X.npy\".format(tinyImageNetDir)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "# Xt, yt = np.load(\"{}/Xt.npy\".format(tinyImageNetDir)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))\n",
    "X, y = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12250 of 12500\n"
     ]
    }
   ],
   "source": [
    "ids, Xt = prepare_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize Model ...\n",
    "# sess.run(tf.initialize_all_variables())\n",
    "vgg.init_fn(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 out of 500"
     ]
    }
   ],
   "source": [
    "images = vgg.generate_base_features(sess, X, size=X.shape[0], prefix='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"inception_catdogs/y.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 out of 250"
     ]
    }
   ],
   "source": [
    "vgg.generate_base_features(sess, Xt, size=Xt.shape[0], prefix='Xt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert map(lambda x: int(x), ids) == sorted(map(lambda x: int(x), ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'shpe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2a8c2052ba9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'shpe'"
     ]
    }
   ],
   "source": [
    "images.shapepe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide Data\n",
    "N = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"FullyConnected\") as sc:\n",
    "    X = tf.placeholder(tf.float32, shape=[None, images.shape[1]])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "    net = slim.stack(X, slim.fully_connected, [32, 2], scope='fc')\n",
    "\n",
    "    with tf.name_scope(\"cost\"):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net, Y))\n",
    "        train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "        # Add scalar summary for cost\n",
    "        tf.scalar_summary(\"cost\", cost)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(net, 1)) # Count correct predictions\n",
    "        acc_op = tf.reduce_mean(tf.cast(correct_pred, \"float\")) # Cast boolean to float to average\n",
    "        # Add scalar summary for accuracy\n",
    "        tf.scalar_summary(\"accuracy\", acc_op)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # create a log writer. run 'tensorboard --logdir=./logs/nn_logs'\n",
    "        writer = tf.train.SummaryWriter(\"logs/nn_logs\", sess.graph) # for 0.8\n",
    "        merged = tf.merge_all_summaries()\n",
    "\n",
    "        # you need to initialize all variables\n",
    "        tf.initialize_all_variables().run()\n",
    "\n",
    "        for i in range(100):\n",
    "            for start, end in zip(range(0, images.shape[0], 100), range(100, images.shape[0]+1, 100)):\n",
    "                sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "            summary, acc = sess.run([merged, acc_op], feed_dict={X: teX, Y: teY})\n",
    "            writer.add_summary(summary, i)  # Write summary\n",
    "            print(i, acc)                   # Report the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
