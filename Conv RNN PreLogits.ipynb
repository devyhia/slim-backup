{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "from matplotlib.mlab import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='RNN-CNN Network.')\n",
    "parser.add_argument('--depth', default=1, help='Depth of the RNN network')\n",
    "parser.add_argument('--hidden', default=128, help='Hidden units of the RNN network')\n",
    "parser.add_argument('--gpu', default=2, help='GPU to use for train')\n",
    "parser.add_argument('--name', default=\"cnn_rnn_softmax\", help='Name of the RNN model to use for train')\n",
    "args, unknown_args = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random, sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG16 Features\n",
    "tinyImageNetDir = \"/home/devyhia/vgg\"\n",
    "X, Y = np.load(\"{}/features/vgg16_12_Adagrad.fc2.X.npy\".format(tinyImageNetDir)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "Xt, Yt = np.load(\"{}/features/vgg16_12_Adagrad.fc2.Xt.npy\".format(tinyImageNetDir)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inception V4 Features\n",
    "tinyImageNetDir = \"/home/devyhia/vgg\"\n",
    "X, Y = np.load(\"features/model2.PreLogitsFlatten.X.npy\".format(tinyImageNetDir)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "Xt, Yt = np.load(\"features/model2.PreLogitsFlatten.Xt.npy\".format(tinyImageNetDir)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tiny Images Raw Data\n",
    "tinyImageNetDir = \"/home/devyhia/vgg\"\n",
    "rawX = np.load(\"{}/X.npy\".format(tinyImageNetDir))\n",
    "rawXt = np.load(\"{}/Xt.npy\".format(tinyImageNetDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = np.array([np.hstack([prelogX[0].reshape(24, 64), rawX[0].reshape(24, 512)]) for i in range(prelogX.shape[0])])\n",
    "# Xt = np.array([np.hstack([prelogXt[0].reshape(24, 64), rawXt[0].reshape(24, 512)]) for i in range(prelogXt.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reverse Sequence\n",
    "# reverse_idx = list(reversed(range(X.shape[1])))\n",
    "# X = X[:, reverse_idx]\n",
    "# Xt = Xt[:, reverse_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "display_step = 25\n",
    "epochs = 100\n",
    "depth = int(args.depth)\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 128 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 12 # timesteps\n",
    "n_hidden = int(args.hidden) # hidden layer num of features\n",
    "n_classes = 100 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float32\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float32\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(0, n_steps, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    #     , forget_bias=1.0\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    \n",
    "    multi_cells = rnn_cell.MultiRNNCell([lstm_cell] * depth, state_is_tuple=True)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(multi_cells, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "prob = tf.nn.softmax(pred)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "top5_correct_pred = tf.nn.in_top_k(prob, tf.argmax(y,1), 5)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "top5accuracy = tf.reduce_mean(tf.cast(top5_correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __iterate_minibatches(_X,_y, size):\n",
    "    if _X.shape[0] % size > 0:\n",
    "        raise \"The minibatch size should be a divisor of the batch size.\"\n",
    "\n",
    "    idx = np.arange(_X.shape[0]).astype(np.int32)\n",
    "    np.random.shuffle(idx) # in-place shuffling\n",
    "    for i in range(_X.shape[0] / size):\n",
    "        # To randomize the minibatches every time\n",
    "        _idx = idx[i*size:(i+1)*size]\n",
    "        _X_small = _X[_idx]\n",
    "        _y_small = _y[_idx]\n",
    "        yield _X_small, _y_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_screen(msg):\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba(sess, Xt, size=1000, step=10, randomize=True):\n",
    "    preds, probs = [], []\n",
    "    idx = range(0, Xt.shape[0])\n",
    "    sample_idx = random.sample(idx, size) if randomize else idx\n",
    "    for i in range(size / step):\n",
    "        _pred, _prob = sess.run([pred, prob], feed_dict={x: Xt[sample_idx[i*step:(i+1)*step]]})\n",
    "        preds.append(_pred)\n",
    "        probs.append(_prob)\n",
    "#         update_screen(\"\\r{} of {}\".format(i, size / step))\n",
    "    \n",
    "#     update_screen(\"\\n\")\n",
    "    preds = np.vstack(preds)\n",
    "    probs = np.vstack(probs)\n",
    "    \n",
    "    return preds, probs, sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(sess, Xt, yt, size=1000, step=10):\n",
    "    preds, probs, sample_idx = predict_proba(sess, Xt, size=size, step=step)\n",
    "\n",
    "    loss, acc, top5acc = sess.run([cost, accuracy, top5accuracy], feed_dict={pred: preds, y: yt[sample_idx]})\n",
    "\n",
    "    return loss, acc, top5acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_shape = (-1, n_steps, n_input)\n",
    "rnn_resize = lambda X: X.reshape(rnn_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH 0 ====\n",
      "Iter 25, Loss= 4.2255, Acc= 0.1060, Top-5 Acc= 0.2700\n",
      "Iter 50, Loss= 3.2057, Acc= 0.2930, Top-5 Acc= 0.5360\n",
      "Iter 75, Loss= 2.5152, Acc= 0.4070, Top-5 Acc= 0.6710\n",
      "Iter 100, Loss= 2.0476, Acc= 0.5020, Top-5 Acc= 0.7490\n",
      "Iter 125, Loss= 1.8787, Acc= 0.5460, Top-5 Acc= 0.7790\n",
      "Iter 150, Loss= 1.7094, Acc= 0.5830, Top-5 Acc= 0.8010\n",
      "Iter 175, Loss= 1.6182, Acc= 0.6080, Top-5 Acc= 0.8190\n",
      "Iter 200, Loss= 1.4323, Acc= 0.6550, Top-5 Acc= 0.8550\n",
      "Iter 225, Loss= 1.5575, Acc= 0.6220, Top-5 Acc= 0.8410\n",
      "Iter 250, Loss= 1.5945, Acc= 0.6080, Top-5 Acc= 0.8320\n",
      "Iter 275, Loss= 1.4744, Acc= 0.6420, Top-5 Acc= 0.8430\n",
      "Iter 300, Loss= 1.4385, Acc= 0.6530, Top-5 Acc= 0.8520\n",
      "Iter 325, Loss= 1.3213, Acc= 0.6570, Top-5 Acc= 0.8770\n",
      "Iter 350, Loss= 1.2643, Acc= 0.6760, Top-5 Acc= 0.8850\n",
      "Iter 375, Loss= 1.1722, Acc= 0.7000, Top-5 Acc= 0.8890\n",
      "Iter 400, Loss= 1.2745, Acc= 0.6880, Top-5 Acc= 0.8850\n",
      "Iter 425, Loss= 1.2938, Acc= 0.6970, Top-5 Acc= 0.8670\n",
      "Iter 450, Loss= 1.2265, Acc= 0.7010, Top-5 Acc= 0.8930\n",
      "Iter 475, Loss= 1.2931, Acc= 0.6990, Top-5 Acc= 0.8810\n",
      "Iter 500, Loss= 1.2545, Acc= 0.6990, Top-5 Acc= 0.8910\n",
      "Iter 525, Loss= 1.2562, Acc= 0.6880, Top-5 Acc= 0.8890\n",
      "Iter 550, Loss= 1.2740, Acc= 0.6930, Top-5 Acc= 0.8830\n",
      "Iter 575, Loss= 1.2927, Acc= 0.6860, Top-5 Acc= 0.8970\n",
      "Iter 600, Loss= 1.2168, Acc= 0.7090, Top-5 Acc= 0.8920\n",
      "Iter 625, Loss= 1.1304, Acc= 0.7130, Top-5 Acc= 0.9070\n",
      "Iter 650, Loss= 1.2805, Acc= 0.6900, Top-5 Acc= 0.8830\n",
      "Iter 675, Loss= 1.1439, Acc= 0.7180, Top-5 Acc= 0.9020\n",
      "Iter 700, Loss= 1.1839, Acc= 0.7280, Top-5 Acc= 0.8920\n",
      "Iter 725, Loss= 1.2000, Acc= 0.7110, Top-5 Acc= 0.8990\n",
      "Iter 750, Loss= 1.1893, Acc= 0.7200, Top-5 Acc= 0.8940\n",
      "Iter 775, Loss= 1.1105, Acc= 0.7310, Top-5 Acc= 0.9070\n",
      "Iter 800, Loss= 1.1812, Acc= 0.7200, Top-5 Acc= 0.9000\n",
      "Iter 825, Loss= 1.1695, Acc= 0.7140, Top-5 Acc= 0.8940\n",
      "Iter 850, Loss= 1.1583, Acc= 0.7220, Top-5 Acc= 0.9060\n",
      "Iter 875, Loss= 1.1150, Acc= 0.7220, Top-5 Acc= 0.9030\n",
      "Iter 900, Loss= 1.1794, Acc= 0.7120, Top-5 Acc= 0.9070\n",
      "Iter 925, Loss= 1.2054, Acc= 0.7230, Top-5 Acc= 0.8900\n",
      "Iter 950, Loss= 1.1371, Acc= 0.7190, Top-5 Acc= 0.9070\n",
      "Iter 975, Loss= 1.1016, Acc= 0.7250, Top-5 Acc= 0.9070\n",
      "Iter 1000, Loss= 1.1436, Acc= 0.7180, Top-5 Acc= 0.9100\n",
      "====================================\n",
      "Epoch 0: Loss=1.16119718552 Acc=0.71759980917 Top-5 Acc=0.902799725533\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 1 ====\n",
      "Iter 25, Loss= 1.0693, Acc= 0.7290, Top-5 Acc= 0.9190\n",
      "Iter 50, Loss= 1.2048, Acc= 0.7130, Top-5 Acc= 0.9050\n",
      "Iter 75, Loss= 1.2857, Acc= 0.7030, Top-5 Acc= 0.8890\n",
      "Iter 100, Loss= 1.1338, Acc= 0.7250, Top-5 Acc= 0.8940\n",
      "Iter 125, Loss= 1.1874, Acc= 0.7210, Top-5 Acc= 0.9070\n",
      "Iter 150, Loss= 1.2389, Acc= 0.7160, Top-5 Acc= 0.9000\n",
      "Iter 175, Loss= 1.1468, Acc= 0.7430, Top-5 Acc= 0.9060\n",
      "Iter 200, Loss= 1.3030, Acc= 0.7150, Top-5 Acc= 0.8860\n",
      "Iter 225, Loss= 1.3145, Acc= 0.7110, Top-5 Acc= 0.8970\n",
      "Iter 250, Loss= 1.1798, Acc= 0.7370, Top-5 Acc= 0.9040\n",
      "Iter 275, Loss= 1.1898, Acc= 0.7520, Top-5 Acc= 0.9020\n",
      "Iter 300, Loss= 1.1451, Acc= 0.7310, Top-5 Acc= 0.9040\n",
      "Iter 325, Loss= 1.1772, Acc= 0.7350, Top-5 Acc= 0.9060\n",
      "Iter 350, Loss= 1.2369, Acc= 0.7370, Top-5 Acc= 0.8940\n",
      "Iter 375, Loss= 1.1592, Acc= 0.7340, Top-5 Acc= 0.9060\n",
      "Iter 400, Loss= 1.1107, Acc= 0.7300, Top-5 Acc= 0.9140\n",
      "Iter 425, Loss= 1.2425, Acc= 0.7300, Top-5 Acc= 0.9070\n",
      "Iter 450, Loss= 1.1332, Acc= 0.7460, Top-5 Acc= 0.9140\n",
      "Iter 475, Loss= 1.1783, Acc= 0.7200, Top-5 Acc= 0.9140\n",
      "Iter 500, Loss= 1.1923, Acc= 0.7440, Top-5 Acc= 0.9010\n",
      "Iter 525, Loss= 1.1255, Acc= 0.7450, Top-5 Acc= 0.9210\n",
      "Iter 550, Loss= 1.2404, Acc= 0.7290, Top-5 Acc= 0.8970\n",
      "Iter 575, Loss= 1.1721, Acc= 0.7340, Top-5 Acc= 0.9090\n",
      "Iter 600, Loss= 1.2659, Acc= 0.7170, Top-5 Acc= 0.8980\n",
      "Iter 625, Loss= 1.0910, Acc= 0.7500, Top-5 Acc= 0.9210\n",
      "Iter 650, Loss= 1.2194, Acc= 0.7210, Top-5 Acc= 0.9030\n",
      "Iter 675, Loss= 1.1800, Acc= 0.7360, Top-5 Acc= 0.9100\n",
      "Iter 700, Loss= 1.1921, Acc= 0.7160, Top-5 Acc= 0.9030\n",
      "Iter 725, Loss= 1.1355, Acc= 0.7480, Top-5 Acc= 0.9150\n",
      "Iter 750, Loss= 1.1622, Acc= 0.7340, Top-5 Acc= 0.9070\n",
      "Iter 775, Loss= 1.3036, Acc= 0.7280, Top-5 Acc= 0.8860\n",
      "Iter 800, Loss= 1.0396, Acc= 0.7490, Top-5 Acc= 0.9240\n",
      "Iter 825, Loss= 1.1051, Acc= 0.7500, Top-5 Acc= 0.9150\n",
      "Iter 850, Loss= 1.2715, Acc= 0.7130, Top-5 Acc= 0.9030\n",
      "Iter 875, Loss= 1.2075, Acc= 0.7300, Top-5 Acc= 0.9060\n",
      "Iter 900, Loss= 1.1950, Acc= 0.7230, Top-5 Acc= 0.9080\n",
      "Iter 925, Loss= 1.1461, Acc= 0.7510, Top-5 Acc= 0.9100\n",
      "Iter 950, Loss= 1.1754, Acc= 0.7380, Top-5 Acc= 0.9040\n",
      "Iter 975, Loss= 1.1909, Acc= 0.7290, Top-5 Acc= 0.9070\n",
      "Iter 1000, Loss= 1.2026, Acc= 0.7270, Top-5 Acc= 0.9100\n",
      "====================================\n",
      "Epoch 1: Loss=1.19985806942 Acc=0.731799840927 Top-5 Acc=0.907399713993\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 2 ====\n",
      "Iter 25, Loss= 1.2564, Acc= 0.7140, Top-5 Acc= 0.9060\n",
      "Iter 50, Loss= 1.1960, Acc= 0.7270, Top-5 Acc= 0.9120\n",
      "Iter 75, Loss= 1.0814, Acc= 0.7520, Top-5 Acc= 0.9070\n",
      "Iter 100, Loss= 1.2408, Acc= 0.7120, Top-5 Acc= 0.9130\n",
      "Iter 125, Loss= 1.2816, Acc= 0.7300, Top-5 Acc= 0.9080\n",
      "Iter 150, Loss= 1.1988, Acc= 0.7430, Top-5 Acc= 0.9110\n",
      "Iter 175, Loss= 1.1859, Acc= 0.7430, Top-5 Acc= 0.9140\n",
      "Iter 200, Loss= 1.1366, Acc= 0.7560, Top-5 Acc= 0.9150\n",
      "Iter 225, Loss= 1.2329, Acc= 0.7570, Top-5 Acc= 0.9130\n",
      "Iter 250, Loss= 1.1428, Acc= 0.7520, Top-5 Acc= 0.9160\n",
      "Iter 275, Loss= 1.2682, Acc= 0.7290, Top-5 Acc= 0.9130\n",
      "Iter 300, Loss= 1.1653, Acc= 0.7460, Top-5 Acc= 0.9160\n",
      "Iter 325, Loss= 1.2820, Acc= 0.7210, Top-5 Acc= 0.9030\n",
      "Iter 350, Loss= 1.2220, Acc= 0.7440, Top-5 Acc= 0.9140\n",
      "Iter 375, Loss= 1.2205, Acc= 0.7390, Top-5 Acc= 0.9160\n",
      "Iter 400, Loss= 1.1440, Acc= 0.7670, Top-5 Acc= 0.9170\n",
      "Iter 425, Loss= 1.2665, Acc= 0.7300, Top-5 Acc= 0.9050\n",
      "Iter 450, Loss= 1.3364, Acc= 0.7280, Top-5 Acc= 0.9010\n",
      "Iter 475, Loss= 1.2223, Acc= 0.7370, Top-5 Acc= 0.9140\n",
      "Iter 500, Loss= 1.1881, Acc= 0.7520, Top-5 Acc= 0.9070\n",
      "Iter 525, Loss= 1.2725, Acc= 0.7270, Top-5 Acc= 0.9170\n",
      "Iter 550, Loss= 1.2843, Acc= 0.7220, Top-5 Acc= 0.9100\n",
      "Iter 575, Loss= 1.3153, Acc= 0.7280, Top-5 Acc= 0.8960\n",
      "Iter 600, Loss= 1.2334, Acc= 0.7530, Top-5 Acc= 0.9070\n",
      "Iter 625, Loss= 1.3500, Acc= 0.7270, Top-5 Acc= 0.9010\n",
      "Iter 650, Loss= 1.2078, Acc= 0.7610, Top-5 Acc= 0.9030\n",
      "Iter 675, Loss= 1.3080, Acc= 0.7290, Top-5 Acc= 0.9040\n",
      "Iter 700, Loss= 1.2440, Acc= 0.7310, Top-5 Acc= 0.9210\n",
      "Iter 725, Loss= 1.1503, Acc= 0.7500, Top-5 Acc= 0.9200\n",
      "Iter 750, Loss= 1.1902, Acc= 0.7420, Top-5 Acc= 0.9170\n",
      "Iter 775, Loss= 1.2898, Acc= 0.7330, Top-5 Acc= 0.9080\n",
      "Iter 800, Loss= 1.2371, Acc= 0.7400, Top-5 Acc= 0.9120\n",
      "Iter 825, Loss= 1.2222, Acc= 0.7490, Top-5 Acc= 0.9110\n",
      "Iter 850, Loss= 1.3563, Acc= 0.7220, Top-5 Acc= 0.9090\n",
      "Iter 875, Loss= 1.1135, Acc= 0.7590, Top-5 Acc= 0.9240\n",
      "Iter 900, Loss= 1.1925, Acc= 0.7460, Top-5 Acc= 0.9210\n",
      "Iter 925, Loss= 1.2344, Acc= 0.7320, Top-5 Acc= 0.9170\n",
      "Iter 950, Loss= 1.2966, Acc= 0.7350, Top-5 Acc= 0.9000\n",
      "Iter 975, Loss= 1.1866, Acc= 0.7510, Top-5 Acc= 0.9260\n",
      "Iter 1000, Loss= 1.2964, Acc= 0.7250, Top-5 Acc= 0.9090\n",
      "====================================\n",
      "Epoch 2: Loss=1.28491151333 Acc=0.734999835491 Top-5 Acc=0.906799793243\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 3 ====\n",
      "Iter 25, Loss= 1.3388, Acc= 0.7320, Top-5 Acc= 0.9060\n",
      "Iter 50, Loss= 1.2914, Acc= 0.7500, Top-5 Acc= 0.9040\n",
      "Iter 75, Loss= 1.4175, Acc= 0.7020, Top-5 Acc= 0.9070\n",
      "Iter 100, Loss= 1.2271, Acc= 0.7510, Top-5 Acc= 0.9140\n",
      "Iter 125, Loss= 1.2970, Acc= 0.7430, Top-5 Acc= 0.9110\n",
      "Iter 150, Loss= 1.3067, Acc= 0.7420, Top-5 Acc= 0.9130\n",
      "Iter 175, Loss= 1.3540, Acc= 0.7380, Top-5 Acc= 0.8970\n",
      "Iter 200, Loss= 1.4239, Acc= 0.7230, Top-5 Acc= 0.8940\n",
      "Iter 225, Loss= 1.2210, Acc= 0.7490, Top-5 Acc= 0.9220\n",
      "Iter 250, Loss= 1.3281, Acc= 0.7270, Top-5 Acc= 0.9180\n",
      "Iter 275, Loss= 1.2295, Acc= 0.7520, Top-5 Acc= 0.9180\n",
      "Iter 300, Loss= 1.4922, Acc= 0.7090, Top-5 Acc= 0.8900\n",
      "Iter 325, Loss= 1.3769, Acc= 0.7340, Top-5 Acc= 0.9070\n",
      "Iter 350, Loss= 1.2866, Acc= 0.7360, Top-5 Acc= 0.9060\n",
      "Iter 375, Loss= 1.2895, Acc= 0.7200, Top-5 Acc= 0.9220\n",
      "Iter 400, Loss= 1.2878, Acc= 0.7480, Top-5 Acc= 0.9160\n",
      "Iter 425, Loss= 1.4762, Acc= 0.7200, Top-5 Acc= 0.8950\n",
      "Iter 450, Loss= 1.5178, Acc= 0.7150, Top-5 Acc= 0.9020\n",
      "Iter 475, Loss= 1.4654, Acc= 0.7190, Top-5 Acc= 0.9000\n",
      "Iter 500, Loss= 1.2763, Acc= 0.7620, Top-5 Acc= 0.9070\n",
      "Iter 525, Loss= 1.3590, Acc= 0.7230, Top-5 Acc= 0.9020\n",
      "Iter 550, Loss= 1.4043, Acc= 0.7440, Top-5 Acc= 0.9030\n",
      "Iter 575, Loss= 1.3821, Acc= 0.7320, Top-5 Acc= 0.9010\n",
      "Iter 600, Loss= 1.3983, Acc= 0.7440, Top-5 Acc= 0.8930\n",
      "Iter 625, Loss= 1.2929, Acc= 0.7370, Top-5 Acc= 0.9140\n",
      "Iter 650, Loss= 1.4209, Acc= 0.7350, Top-5 Acc= 0.9090\n",
      "Iter 675, Loss= 1.3438, Acc= 0.7530, Top-5 Acc= 0.9140\n",
      "Iter 700, Loss= 1.4632, Acc= 0.7170, Top-5 Acc= 0.9050\n",
      "Iter 725, Loss= 1.2902, Acc= 0.7500, Top-5 Acc= 0.9110\n",
      "Iter 750, Loss= 1.3423, Acc= 0.7330, Top-5 Acc= 0.9140\n",
      "Iter 775, Loss= 1.3630, Acc= 0.7400, Top-5 Acc= 0.9140\n",
      "Iter 800, Loss= 1.4384, Acc= 0.7410, Top-5 Acc= 0.9100\n",
      "Iter 825, Loss= 1.3154, Acc= 0.7440, Top-5 Acc= 0.9160\n",
      "Iter 850, Loss= 1.4552, Acc= 0.7140, Top-5 Acc= 0.8980\n",
      "Iter 875, Loss= 1.2363, Acc= 0.7500, Top-5 Acc= 0.9150\n",
      "Iter 900, Loss= 1.3491, Acc= 0.7350, Top-5 Acc= 0.9080\n",
      "Iter 925, Loss= 1.4826, Acc= 0.7420, Top-5 Acc= 0.8960\n",
      "Iter 950, Loss= 1.2668, Acc= 0.7540, Top-5 Acc= 0.9140\n",
      "Iter 975, Loss= 1.3927, Acc= 0.7430, Top-5 Acc= 0.9060\n",
      "Iter 1000, Loss= 1.2882, Acc= 0.7420, Top-5 Acc= 0.9120\n",
      "====================================\n",
      "Epoch 3: Loss=1.34400260448 Acc=0.734799802303 Top-5 Acc=0.904999792576\n",
      "====================================\n",
      "==== EPOCH 4 ====\n",
      "Iter 25, Loss= 1.3235, Acc= 0.7430, Top-5 Acc= 0.9050\n",
      "Iter 50, Loss= 1.2494, Acc= 0.7560, Top-5 Acc= 0.9150\n",
      "Iter 75, Loss= 1.4840, Acc= 0.7310, Top-5 Acc= 0.9040\n",
      "Iter 100, Loss= 1.3327, Acc= 0.7440, Top-5 Acc= 0.9130\n",
      "Iter 125, Loss= 1.3439, Acc= 0.7460, Top-5 Acc= 0.9130\n",
      "Iter 150, Loss= 1.5576, Acc= 0.7290, Top-5 Acc= 0.9030\n",
      "Iter 175, Loss= 1.5234, Acc= 0.7300, Top-5 Acc= 0.8910\n",
      "Iter 200, Loss= 1.3844, Acc= 0.7550, Top-5 Acc= 0.9210\n",
      "Iter 225, Loss= 1.2298, Acc= 0.7530, Top-5 Acc= 0.9260\n",
      "Iter 250, Loss= 1.3676, Acc= 0.7590, Top-5 Acc= 0.9020\n",
      "Iter 275, Loss= 1.4184, Acc= 0.7340, Top-5 Acc= 0.8990\n",
      "Iter 300, Loss= 1.3455, Acc= 0.7500, Top-5 Acc= 0.9180\n",
      "Iter 325, Loss= 1.4172, Acc= 0.7510, Top-5 Acc= 0.9060\n",
      "Iter 350, Loss= 1.4392, Acc= 0.7460, Top-5 Acc= 0.9120\n",
      "Iter 375, Loss= 1.4440, Acc= 0.7380, Top-5 Acc= 0.9030\n",
      "Iter 400, Loss= 1.6008, Acc= 0.7130, Top-5 Acc= 0.8940\n",
      "Iter 425, Loss= 1.5480, Acc= 0.7310, Top-5 Acc= 0.8950\n",
      "Iter 450, Loss= 1.3429, Acc= 0.7480, Top-5 Acc= 0.9220\n",
      "Iter 475, Loss= 1.3525, Acc= 0.7550, Top-5 Acc= 0.9120\n",
      "Iter 500, Loss= 1.4572, Acc= 0.7370, Top-5 Acc= 0.9170\n",
      "Iter 525, Loss= 1.3928, Acc= 0.7400, Top-5 Acc= 0.9080\n",
      "Iter 550, Loss= 1.5111, Acc= 0.7430, Top-5 Acc= 0.9050\n",
      "Iter 575, Loss= 1.2911, Acc= 0.7550, Top-5 Acc= 0.9210\n",
      "Iter 600, Loss= 1.3361, Acc= 0.7560, Top-5 Acc= 0.9140\n",
      "Iter 625, Loss= 1.4847, Acc= 0.7260, Top-5 Acc= 0.9120\n",
      "Iter 650, Loss= 1.4744, Acc= 0.7430, Top-5 Acc= 0.8960\n",
      "Iter 675, Loss= 1.4160, Acc= 0.7410, Top-5 Acc= 0.9080\n",
      "Iter 700, Loss= 1.4296, Acc= 0.7320, Top-5 Acc= 0.9040\n",
      "Iter 725, Loss= 1.6961, Acc= 0.7240, Top-5 Acc= 0.8930\n",
      "Iter 750, Loss= 1.4576, Acc= 0.7430, Top-5 Acc= 0.9040\n",
      "Iter 775, Loss= 1.3764, Acc= 0.7620, Top-5 Acc= 0.9130\n",
      "Iter 800, Loss= 1.5042, Acc= 0.7480, Top-5 Acc= 0.9040\n",
      "Iter 825, Loss= 1.4637, Acc= 0.7470, Top-5 Acc= 0.9020\n",
      "Iter 850, Loss= 1.5488, Acc= 0.7370, Top-5 Acc= 0.9010\n",
      "Iter 875, Loss= 1.4378, Acc= 0.7340, Top-5 Acc= 0.9180\n",
      "Iter 900, Loss= 1.4820, Acc= 0.7430, Top-5 Acc= 0.8990\n",
      "Iter 925, Loss= 1.5582, Acc= 0.7180, Top-5 Acc= 0.9110\n",
      "Iter 950, Loss= 1.4608, Acc= 0.7440, Top-5 Acc= 0.9050\n",
      "Iter 975, Loss= 1.4109, Acc= 0.7420, Top-5 Acc= 0.9170\n",
      "Iter 1000, Loss= 1.5212, Acc= 0.7220, Top-5 Acc= 0.9090\n",
      "====================================\n",
      "Epoch 4: Loss=1.47119498253 Acc=0.735999822617 Top-5 Acc=0.905799746513\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 5 ====\n",
      "Iter 25, Loss= 1.4811, Acc= 0.7520, Top-5 Acc= 0.9010\n",
      "Iter 50, Loss= 1.3867, Acc= 0.7510, Top-5 Acc= 0.9240\n",
      "Iter 75, Loss= 1.6095, Acc= 0.7290, Top-5 Acc= 0.9060\n",
      "Iter 100, Loss= 1.4139, Acc= 0.7550, Top-5 Acc= 0.9140\n",
      "Iter 125, Loss= 1.6421, Acc= 0.7250, Top-5 Acc= 0.9060\n",
      "Iter 150, Loss= 1.3791, Acc= 0.7540, Top-5 Acc= 0.9140\n",
      "Iter 175, Loss= 1.4199, Acc= 0.7560, Top-5 Acc= 0.9220\n",
      "Iter 200, Loss= 1.5607, Acc= 0.7330, Top-5 Acc= 0.8920\n",
      "Iter 225, Loss= 1.5239, Acc= 0.7370, Top-5 Acc= 0.8960\n",
      "Iter 250, Loss= 1.4991, Acc= 0.7230, Top-5 Acc= 0.9110\n",
      "Iter 275, Loss= 1.5105, Acc= 0.7420, Top-5 Acc= 0.8990\n",
      "Iter 300, Loss= 1.6823, Acc= 0.7090, Top-5 Acc= 0.9020\n",
      "Iter 325, Loss= 1.4508, Acc= 0.7420, Top-5 Acc= 0.9150\n",
      "Iter 350, Loss= 1.2305, Acc= 0.7730, Top-5 Acc= 0.9270\n",
      "Iter 375, Loss= 1.5610, Acc= 0.7280, Top-5 Acc= 0.9100\n",
      "Iter 400, Loss= 1.5395, Acc= 0.7490, Top-5 Acc= 0.9070\n",
      "Iter 425, Loss= 1.5829, Acc= 0.7490, Top-5 Acc= 0.9030\n",
      "Iter 450, Loss= 1.4779, Acc= 0.7470, Top-5 Acc= 0.9090\n",
      "Iter 475, Loss= 1.6008, Acc= 0.7300, Top-5 Acc= 0.8920\n",
      "Iter 500, Loss= 1.6182, Acc= 0.7350, Top-5 Acc= 0.8920\n",
      "Iter 525, Loss= 1.4184, Acc= 0.7580, Top-5 Acc= 0.9140\n",
      "Iter 550, Loss= 1.4494, Acc= 0.7400, Top-5 Acc= 0.9160\n",
      "Iter 575, Loss= 1.4078, Acc= 0.7530, Top-5 Acc= 0.9130\n",
      "Iter 600, Loss= 1.5377, Acc= 0.7450, Top-5 Acc= 0.9080\n",
      "Iter 625, Loss= 1.4060, Acc= 0.7570, Top-5 Acc= 0.9110\n",
      "Iter 650, Loss= 1.3949, Acc= 0.7580, Top-5 Acc= 0.9110\n",
      "Iter 675, Loss= 1.5488, Acc= 0.7430, Top-5 Acc= 0.9040\n",
      "Iter 700, Loss= 1.5126, Acc= 0.7580, Top-5 Acc= 0.9030\n",
      "Iter 725, Loss= 1.6475, Acc= 0.7180, Top-5 Acc= 0.8990\n",
      "Iter 750, Loss= 1.4565, Acc= 0.7410, Top-5 Acc= 0.9190\n",
      "Iter 775, Loss= 1.6630, Acc= 0.7290, Top-5 Acc= 0.9020\n",
      "Iter 800, Loss= 1.5804, Acc= 0.7410, Top-5 Acc= 0.9030\n",
      "Iter 825, Loss= 1.5286, Acc= 0.7490, Top-5 Acc= 0.9080\n",
      "Iter 850, Loss= 1.5687, Acc= 0.7300, Top-5 Acc= 0.9090\n",
      "Iter 875, Loss= 1.6129, Acc= 0.7260, Top-5 Acc= 0.9070\n",
      "Iter 900, Loss= 1.5773, Acc= 0.7310, Top-5 Acc= 0.9030\n",
      "Iter 925, Loss= 1.4879, Acc= 0.7470, Top-5 Acc= 0.9050\n",
      "Iter 950, Loss= 1.5599, Acc= 0.7320, Top-5 Acc= 0.9070\n",
      "Iter 975, Loss= 1.5175, Acc= 0.7300, Top-5 Acc= 0.9100\n",
      "Iter 1000, Loss= 1.7279, Acc= 0.7180, Top-5 Acc= 0.8790\n",
      "====================================\n",
      "Epoch 5: Loss=1.55932712555 Acc=0.733999848366 Top-5 Acc=0.902799725533\n",
      "====================================\n",
      "==== EPOCH 6 ====\n",
      "Iter 25, Loss= 1.5663, Acc= 0.7420, Top-5 Acc= 0.8980\n",
      "Iter 50, Loss= 1.5023, Acc= 0.7430, Top-5 Acc= 0.8990\n",
      "Iter 75, Loss= 1.5606, Acc= 0.7400, Top-5 Acc= 0.9030\n",
      "Iter 100, Loss= 1.5287, Acc= 0.7600, Top-5 Acc= 0.9060\n",
      "Iter 125, Loss= 1.3879, Acc= 0.7670, Top-5 Acc= 0.9120\n",
      "Iter 150, Loss= 1.6474, Acc= 0.7220, Top-5 Acc= 0.9060\n",
      "Iter 175, Loss= 1.6479, Acc= 0.7420, Top-5 Acc= 0.9080\n",
      "Iter 200, Loss= 1.6883, Acc= 0.7340, Top-5 Acc= 0.8970\n",
      "Iter 225, Loss= 1.3168, Acc= 0.7680, Top-5 Acc= 0.9260\n",
      "Iter 250, Loss= 1.4436, Acc= 0.7480, Top-5 Acc= 0.9100\n",
      "Iter 275, Loss= 1.4858, Acc= 0.7420, Top-5 Acc= 0.9170\n",
      "Iter 300, Loss= 1.5451, Acc= 0.7370, Top-5 Acc= 0.9120\n",
      "Iter 325, Loss= 1.5213, Acc= 0.7550, Top-5 Acc= 0.9120\n",
      "Iter 350, Loss= 1.4480, Acc= 0.7580, Top-5 Acc= 0.9060\n",
      "Iter 375, Loss= 1.7363, Acc= 0.7300, Top-5 Acc= 0.8920\n",
      "Iter 400, Loss= 1.6322, Acc= 0.7400, Top-5 Acc= 0.9000\n",
      "Iter 425, Loss= 1.4523, Acc= 0.7570, Top-5 Acc= 0.9150\n",
      "Iter 450, Loss= 1.4448, Acc= 0.7430, Top-5 Acc= 0.9220\n",
      "Iter 475, Loss= 1.6612, Acc= 0.7340, Top-5 Acc= 0.9070\n",
      "Iter 500, Loss= 1.7359, Acc= 0.7270, Top-5 Acc= 0.8870\n",
      "Iter 525, Loss= 1.5895, Acc= 0.7410, Top-5 Acc= 0.9050\n",
      "Iter 550, Loss= 1.4698, Acc= 0.7650, Top-5 Acc= 0.9040\n",
      "Iter 575, Loss= 1.6573, Acc= 0.7360, Top-5 Acc= 0.8940\n",
      "Iter 600, Loss= 1.8650, Acc= 0.7170, Top-5 Acc= 0.8950\n",
      "Iter 625, Loss= 1.6815, Acc= 0.7310, Top-5 Acc= 0.8960\n",
      "Iter 650, Loss= 1.7265, Acc= 0.7160, Top-5 Acc= 0.9010\n",
      "Iter 675, Loss= 1.5314, Acc= 0.7330, Top-5 Acc= 0.9270\n",
      "Iter 700, Loss= 1.5139, Acc= 0.7290, Top-5 Acc= 0.9110\n",
      "Iter 725, Loss= 1.7286, Acc= 0.7340, Top-5 Acc= 0.8900\n",
      "Iter 750, Loss= 1.4475, Acc= 0.7670, Top-5 Acc= 0.9170\n",
      "Iter 775, Loss= 1.7611, Acc= 0.7370, Top-5 Acc= 0.9070\n",
      "Iter 800, Loss= 1.5269, Acc= 0.7390, Top-5 Acc= 0.9140\n",
      "Iter 825, Loss= 1.5506, Acc= 0.7370, Top-5 Acc= 0.9080\n",
      "Iter 850, Loss= 1.5685, Acc= 0.7420, Top-5 Acc= 0.9230\n",
      "Iter 875, Loss= 1.5055, Acc= 0.7550, Top-5 Acc= 0.9140\n",
      "Iter 900, Loss= 1.6125, Acc= 0.7290, Top-5 Acc= 0.9180\n",
      "Iter 925, Loss= 1.6763, Acc= 0.7390, Top-5 Acc= 0.8980\n",
      "Iter 950, Loss= 1.5537, Acc= 0.7420, Top-5 Acc= 0.9070\n",
      "Iter 975, Loss= 1.6669, Acc= 0.7230, Top-5 Acc= 0.8990\n",
      "Iter 1000, Loss= 1.6193, Acc= 0.7390, Top-5 Acc= 0.8990\n",
      "====================================\n",
      "Epoch 6: Loss=1.58239400387 Acc=0.742999851704 Top-5 Acc=0.90979975462\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 7 ====\n",
      "Iter 25, Loss= 1.5592, Acc= 0.7380, Top-5 Acc= 0.9090\n",
      "Iter 50, Loss= 1.5643, Acc= 0.7440, Top-5 Acc= 0.9170\n",
      "Iter 75, Loss= 1.4368, Acc= 0.7740, Top-5 Acc= 0.9210\n",
      "Iter 100, Loss= 1.7020, Acc= 0.7410, Top-5 Acc= 0.9020\n",
      "Iter 125, Loss= 1.4312, Acc= 0.7600, Top-5 Acc= 0.9180\n",
      "Iter 150, Loss= 1.4288, Acc= 0.7510, Top-5 Acc= 0.9310\n",
      "Iter 175, Loss= 1.6863, Acc= 0.7400, Top-5 Acc= 0.8970\n",
      "Iter 200, Loss= 1.6486, Acc= 0.7430, Top-5 Acc= 0.9110\n",
      "Iter 225, Loss= 1.7445, Acc= 0.7290, Top-5 Acc= 0.8990\n",
      "Iter 250, Loss= 1.6402, Acc= 0.7470, Top-5 Acc= 0.9000\n",
      "Iter 275, Loss= 1.6611, Acc= 0.7500, Top-5 Acc= 0.9060\n",
      "Iter 300, Loss= 1.6249, Acc= 0.7460, Top-5 Acc= 0.9060\n",
      "Iter 325, Loss= 1.6866, Acc= 0.7280, Top-5 Acc= 0.9060\n",
      "Iter 350, Loss= 1.6545, Acc= 0.7380, Top-5 Acc= 0.8990\n",
      "Iter 375, Loss= 1.7009, Acc= 0.7350, Top-5 Acc= 0.8940\n",
      "Iter 400, Loss= 1.6396, Acc= 0.7280, Top-5 Acc= 0.9030\n",
      "Iter 425, Loss= 1.6835, Acc= 0.7280, Top-5 Acc= 0.9090\n",
      "Iter 450, Loss= 1.6516, Acc= 0.7410, Top-5 Acc= 0.9090\n",
      "Iter 475, Loss= 1.6561, Acc= 0.7500, Top-5 Acc= 0.9090\n",
      "Iter 500, Loss= 1.6423, Acc= 0.7480, Top-5 Acc= 0.9100\n",
      "Iter 525, Loss= 1.7015, Acc= 0.7370, Top-5 Acc= 0.8950\n",
      "Iter 550, Loss= 1.8819, Acc= 0.7430, Top-5 Acc= 0.9010\n",
      "Iter 575, Loss= 1.7936, Acc= 0.7300, Top-5 Acc= 0.9010\n",
      "Iter 600, Loss= 1.9110, Acc= 0.7210, Top-5 Acc= 0.8860\n",
      "Iter 625, Loss= 1.7609, Acc= 0.7440, Top-5 Acc= 0.9010\n",
      "Iter 650, Loss= 1.7581, Acc= 0.7440, Top-5 Acc= 0.9010\n",
      "Iter 675, Loss= 1.5945, Acc= 0.7330, Top-5 Acc= 0.9040\n",
      "Iter 700, Loss= 1.6648, Acc= 0.7440, Top-5 Acc= 0.9120\n",
      "Iter 725, Loss= 1.6295, Acc= 0.7360, Top-5 Acc= 0.9090\n",
      "Iter 750, Loss= 1.6184, Acc= 0.7270, Top-5 Acc= 0.9150\n",
      "Iter 775, Loss= 1.6730, Acc= 0.7510, Top-5 Acc= 0.9060\n",
      "Iter 800, Loss= 1.6147, Acc= 0.7390, Top-5 Acc= 0.9170\n",
      "Iter 825, Loss= 1.8591, Acc= 0.7250, Top-5 Acc= 0.9030\n",
      "Iter 850, Loss= 1.6149, Acc= 0.7430, Top-5 Acc= 0.9040\n",
      "Iter 875, Loss= 1.4958, Acc= 0.7570, Top-5 Acc= 0.9090\n",
      "Iter 900, Loss= 1.7058, Acc= 0.7310, Top-5 Acc= 0.9180\n",
      "Iter 925, Loss= 1.6046, Acc= 0.7520, Top-5 Acc= 0.9220\n",
      "Iter 950, Loss= 1.7102, Acc= 0.7520, Top-5 Acc= 0.8990\n",
      "Iter 975, Loss= 1.5241, Acc= 0.7660, Top-5 Acc= 0.9100\n",
      "Iter 1000, Loss= 1.6216, Acc= 0.7380, Top-5 Acc= 0.9040\n",
      "====================================\n",
      "Epoch 7: Loss=1.69088840485 Acc=0.734999895096 Top-5 Acc=0.906399786472\n",
      "====================================\n",
      "==== EPOCH 8 ====\n",
      "Iter 25, Loss= 1.7440, Acc= 0.7430, Top-5 Acc= 0.9120\n",
      "Iter 50, Loss= 1.6892, Acc= 0.7370, Top-5 Acc= 0.9120\n",
      "Iter 75, Loss= 1.6593, Acc= 0.7470, Top-5 Acc= 0.9160\n",
      "Iter 100, Loss= 1.5559, Acc= 0.7550, Top-5 Acc= 0.9080\n",
      "Iter 125, Loss= 1.5969, Acc= 0.7580, Top-5 Acc= 0.9130\n",
      "Iter 150, Loss= 1.7670, Acc= 0.7440, Top-5 Acc= 0.8950\n",
      "Iter 175, Loss= 1.6351, Acc= 0.7460, Top-5 Acc= 0.9040\n",
      "Iter 200, Loss= 1.7340, Acc= 0.7360, Top-5 Acc= 0.9000\n",
      "Iter 225, Loss= 1.7372, Acc= 0.7570, Top-5 Acc= 0.9060\n",
      "Iter 250, Loss= 1.4639, Acc= 0.7490, Top-5 Acc= 0.9180\n",
      "Iter 275, Loss= 1.6727, Acc= 0.7410, Top-5 Acc= 0.9050\n",
      "Iter 300, Loss= 1.7799, Acc= 0.7310, Top-5 Acc= 0.9030\n",
      "Iter 325, Loss= 1.5971, Acc= 0.7470, Top-5 Acc= 0.9040\n",
      "Iter 350, Loss= 1.8055, Acc= 0.7380, Top-5 Acc= 0.9000\n",
      "Iter 375, Loss= 1.7994, Acc= 0.7460, Top-5 Acc= 0.9070\n",
      "Iter 400, Loss= 1.6887, Acc= 0.7470, Top-5 Acc= 0.9000\n",
      "Iter 425, Loss= 1.9173, Acc= 0.7190, Top-5 Acc= 0.8890\n",
      "Iter 450, Loss= 1.7696, Acc= 0.7380, Top-5 Acc= 0.8970\n",
      "Iter 475, Loss= 1.7760, Acc= 0.7450, Top-5 Acc= 0.8970\n",
      "Iter 500, Loss= 1.6466, Acc= 0.7460, Top-5 Acc= 0.9080\n",
      "Iter 525, Loss= 1.7113, Acc= 0.7430, Top-5 Acc= 0.9140\n",
      "Iter 550, Loss= 1.8277, Acc= 0.7370, Top-5 Acc= 0.9080\n",
      "Iter 575, Loss= 1.6063, Acc= 0.7360, Top-5 Acc= 0.9100\n",
      "Iter 600, Loss= 1.7279, Acc= 0.7410, Top-5 Acc= 0.8970\n",
      "Iter 625, Loss= 1.7258, Acc= 0.7480, Top-5 Acc= 0.9060\n",
      "Iter 650, Loss= 1.7323, Acc= 0.7460, Top-5 Acc= 0.9010\n",
      "Iter 675, Loss= 1.7382, Acc= 0.7340, Top-5 Acc= 0.9040\n",
      "Iter 700, Loss= 1.5282, Acc= 0.7510, Top-5 Acc= 0.9190\n",
      "Iter 725, Loss= 1.7252, Acc= 0.7410, Top-5 Acc= 0.9050\n",
      "Iter 750, Loss= 1.8480, Acc= 0.7250, Top-5 Acc= 0.8920\n",
      "Iter 775, Loss= 1.6511, Acc= 0.7400, Top-5 Acc= 0.9130\n",
      "Iter 800, Loss= 1.8128, Acc= 0.7250, Top-5 Acc= 0.9120\n",
      "Iter 825, Loss= 1.6543, Acc= 0.7550, Top-5 Acc= 0.9040\n",
      "Iter 850, Loss= 1.7098, Acc= 0.7270, Top-5 Acc= 0.9070\n",
      "Iter 875, Loss= 1.6167, Acc= 0.7430, Top-5 Acc= 0.9190\n",
      "Iter 900, Loss= 1.7603, Acc= 0.7370, Top-5 Acc= 0.8940\n",
      "Iter 925, Loss= 1.6604, Acc= 0.7540, Top-5 Acc= 0.9040\n",
      "Iter 950, Loss= 1.8288, Acc= 0.7380, Top-5 Acc= 0.9000\n",
      "Iter 975, Loss= 1.7928, Acc= 0.7380, Top-5 Acc= 0.9040\n",
      "Iter 1000, Loss= 1.5032, Acc= 0.7500, Top-5 Acc= 0.9140\n",
      "====================================\n",
      "Epoch 8: Loss=1.74667644501 Acc=0.737199902534 Top-5 Acc=0.903199791908\n",
      "====================================\n",
      "==== EPOCH 9 ====\n",
      "Iter 25, Loss= 1.7918, Acc= 0.7240, Top-5 Acc= 0.9040\n",
      "Iter 50, Loss= 1.6276, Acc= 0.7450, Top-5 Acc= 0.9060\n",
      "Iter 75, Loss= 1.7575, Acc= 0.7220, Top-5 Acc= 0.9020\n",
      "Iter 100, Loss= 1.7937, Acc= 0.7470, Top-5 Acc= 0.8940\n",
      "Iter 125, Loss= 1.5099, Acc= 0.7520, Top-5 Acc= 0.9130\n",
      "Iter 150, Loss= 1.9036, Acc= 0.7210, Top-5 Acc= 0.8890\n",
      "Iter 175, Loss= 1.7420, Acc= 0.7360, Top-5 Acc= 0.9120\n",
      "Iter 200, Loss= 1.5872, Acc= 0.7560, Top-5 Acc= 0.9070\n",
      "Iter 225, Loss= 1.7742, Acc= 0.7380, Top-5 Acc= 0.8940\n",
      "Iter 250, Loss= 1.6534, Acc= 0.7380, Top-5 Acc= 0.9090\n",
      "Iter 275, Loss= 1.7412, Acc= 0.7630, Top-5 Acc= 0.9030\n",
      "Iter 300, Loss= 1.5117, Acc= 0.7570, Top-5 Acc= 0.9230\n",
      "Iter 325, Loss= 1.7628, Acc= 0.7440, Top-5 Acc= 0.8980\n",
      "Iter 350, Loss= 1.9189, Acc= 0.7290, Top-5 Acc= 0.9040\n",
      "Iter 375, Loss= 1.9928, Acc= 0.7160, Top-5 Acc= 0.8960\n",
      "Iter 400, Loss= 1.6467, Acc= 0.7540, Top-5 Acc= 0.9130\n",
      "Iter 425, Loss= 1.7253, Acc= 0.7580, Top-5 Acc= 0.9050\n",
      "Iter 450, Loss= 1.7952, Acc= 0.7360, Top-5 Acc= 0.9000\n",
      "Iter 475, Loss= 1.8913, Acc= 0.7190, Top-5 Acc= 0.8990\n",
      "Iter 500, Loss= 1.7366, Acc= 0.7400, Top-5 Acc= 0.8970\n",
      "Iter 525, Loss= 1.8622, Acc= 0.7320, Top-5 Acc= 0.8900\n",
      "Iter 550, Loss= 1.8451, Acc= 0.7320, Top-5 Acc= 0.8950\n",
      "Iter 575, Loss= 1.7990, Acc= 0.7370, Top-5 Acc= 0.9020\n",
      "Iter 600, Loss= 1.6951, Acc= 0.7420, Top-5 Acc= 0.9180\n",
      "Iter 625, Loss= 1.7904, Acc= 0.7310, Top-5 Acc= 0.8910\n",
      "Iter 650, Loss= 1.7332, Acc= 0.7510, Top-5 Acc= 0.9020\n",
      "Iter 675, Loss= 1.6747, Acc= 0.7380, Top-5 Acc= 0.9110\n",
      "Iter 700, Loss= 1.5430, Acc= 0.7440, Top-5 Acc= 0.9170\n",
      "Iter 725, Loss= 1.7899, Acc= 0.7530, Top-5 Acc= 0.9110\n",
      "Iter 750, Loss= 1.7160, Acc= 0.7470, Top-5 Acc= 0.9100\n",
      "Iter 775, Loss= 1.8215, Acc= 0.7370, Top-5 Acc= 0.9050\n",
      "Iter 800, Loss= 1.7974, Acc= 0.7300, Top-5 Acc= 0.9110\n",
      "Iter 825, Loss= 1.7239, Acc= 0.7500, Top-5 Acc= 0.9080\n",
      "Iter 850, Loss= 1.7093, Acc= 0.7370, Top-5 Acc= 0.9140\n",
      "Iter 875, Loss= 1.6372, Acc= 0.7540, Top-5 Acc= 0.9100\n",
      "Iter 900, Loss= 1.6738, Acc= 0.7530, Top-5 Acc= 0.9110\n",
      "Iter 925, Loss= 1.9107, Acc= 0.7400, Top-5 Acc= 0.8960\n",
      "Iter 950, Loss= 1.8715, Acc= 0.7280, Top-5 Acc= 0.8930\n",
      "Iter 975, Loss= 1.8255, Acc= 0.7490, Top-5 Acc= 0.8950\n",
      "Iter 1000, Loss= 1.7340, Acc= 0.7330, Top-5 Acc= 0.9130\n",
      "====================================\n",
      "Epoch 9: Loss=1.88155078888 Acc=0.728799939156 Top-5 Acc=0.900799751282\n",
      "====================================\n",
      "==== EPOCH 10 ====\n",
      "Iter 25, Loss= 1.9642, Acc= 0.7110, Top-5 Acc= 0.8940\n",
      "Iter 50, Loss= 1.8762, Acc= 0.7350, Top-5 Acc= 0.8990\n",
      "Iter 75, Loss= 1.6379, Acc= 0.7670, Top-5 Acc= 0.9090\n",
      "Iter 100, Loss= 1.9339, Acc= 0.7300, Top-5 Acc= 0.8920\n",
      "Iter 125, Loss= 1.9417, Acc= 0.7340, Top-5 Acc= 0.8960\n",
      "Iter 150, Loss= 1.7699, Acc= 0.7420, Top-5 Acc= 0.8970\n",
      "Iter 175, Loss= 1.6411, Acc= 0.7320, Top-5 Acc= 0.9130\n",
      "Iter 200, Loss= 1.8013, Acc= 0.7410, Top-5 Acc= 0.9130\n",
      "Iter 225, Loss= 1.9142, Acc= 0.7140, Top-5 Acc= 0.9010\n",
      "Iter 250, Loss= 1.7479, Acc= 0.7410, Top-5 Acc= 0.9070\n",
      "Iter 275, Loss= 1.8149, Acc= 0.7430, Top-5 Acc= 0.9040\n",
      "Iter 300, Loss= 1.5585, Acc= 0.7580, Top-5 Acc= 0.9230\n",
      "Iter 325, Loss= 1.7737, Acc= 0.7360, Top-5 Acc= 0.9170\n",
      "Iter 350, Loss= 1.8737, Acc= 0.7270, Top-5 Acc= 0.8960\n",
      "Iter 375, Loss= 1.7046, Acc= 0.7570, Top-5 Acc= 0.9110\n",
      "Iter 400, Loss= 1.6244, Acc= 0.7560, Top-5 Acc= 0.9100\n",
      "Iter 425, Loss= 1.8561, Acc= 0.7350, Top-5 Acc= 0.9070\n",
      "Iter 450, Loss= 1.8204, Acc= 0.7410, Top-5 Acc= 0.9010\n",
      "Iter 475, Loss= 1.8513, Acc= 0.7350, Top-5 Acc= 0.9010\n",
      "Iter 500, Loss= 1.8620, Acc= 0.7300, Top-5 Acc= 0.8980\n",
      "Iter 525, Loss= 1.8752, Acc= 0.7230, Top-5 Acc= 0.9020\n",
      "Iter 550, Loss= 1.8944, Acc= 0.7330, Top-5 Acc= 0.8980\n",
      "Iter 575, Loss= 1.6973, Acc= 0.7610, Top-5 Acc= 0.9120\n",
      "Iter 600, Loss= 1.7838, Acc= 0.7440, Top-5 Acc= 0.8970\n",
      "Iter 625, Loss= 1.6020, Acc= 0.7410, Top-5 Acc= 0.9130\n",
      "Iter 650, Loss= 2.0528, Acc= 0.7150, Top-5 Acc= 0.8910\n",
      "Iter 675, Loss= 1.7967, Acc= 0.7330, Top-5 Acc= 0.9040\n",
      "Iter 700, Loss= 1.7869, Acc= 0.7400, Top-5 Acc= 0.9110\n",
      "Iter 725, Loss= 1.7055, Acc= 0.7390, Top-5 Acc= 0.9090\n",
      "Iter 750, Loss= 1.9805, Acc= 0.7210, Top-5 Acc= 0.8910\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1aac5f2150ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__iterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0m_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "# config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(init)\n",
    "    prev_acc = 0.0\n",
    "    for ep in range(epochs):\n",
    "        print(\"==== EPOCH {} ====\".format(ep))\n",
    "        step = 1\n",
    "        for _X, _Y in __iterate_minibatches(X, Y, batch_size):\n",
    "            _X = rnn_resize(_X)\n",
    "            sess.run(optimizer, feed_dict={x: _X, y: _Y})\n",
    "            if step % display_step == 0:\n",
    "                loss, acc, top5acc = calculate_loss(sess, rnn_resize(Xt), Yt)\n",
    "                print(\"Iter \" + str(step) + \", Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Acc= \" + \\\n",
    "                      \"{:.4f}\".format(acc) + \", Top-5 Acc= \" + \\\n",
    "                      \"{:.4f}\".format(top5acc))\n",
    "            step += 1\n",
    "\n",
    "        loss, acc, top5acc = calculate_loss(sess, rnn_resize(Xt), Yt, size=Xt.shape[0])\n",
    "        print(\"====================================\")\n",
    "        print(\"Epoch {}: Loss={} Acc={} Top-5 Acc={}\".format(ep, loss, acc, top5acc))\n",
    "        print(\"====================================\")\n",
    "        if acc > prev_acc:\n",
    "            prev_acc = acc\n",
    "            saver.save(sess, \"conv_rnn_prelogits/{}.tfmodel\".format(args.name))\n",
    "            print(\"++++ Saved BEST ACC\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN-RNN Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas_training = []\n",
    "probas_testing = []\n",
    "preds_training = []\n",
    "preds_testing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load RNN Predictions\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(init)\n",
    "    for i in range(3,5):\n",
    "        X, Y = np.load(\"features/model{}.PreLogitsFlatten.X.npy\".format(i)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "        Xt, Yt = np.load(\"features/model{}.PreLogitsFlatten.Xt.npy\".format(i)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))\n",
    "        saver.restore(sess, \"conv_rnn_prelogits/cnn_prelogits_rnn_model_{}.tfmodel\".format(i))\n",
    "    #     print(calculate_loss(sess, rnn_resize(Xt), Yt, size=Xt.shape[0]))\n",
    "    #     calculate_loss()\n",
    "        res_training = predict_proba(sess, rnn_resize(X), size=X.shape[0], randomize=False, step=250)\n",
    "        res_testing = predict_proba(sess, rnn_resize(Xt), size=Xt.shape[0], randomize=False, step=250)\n",
    "        preds_training += [res_training[0]]\n",
    "        preds_testing += [res_testing[0]]\n",
    "        probas_training += [res_training[1]]\n",
    "        probas_testing += [res_testing[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load CNN Predictions\n",
    "# probas_training += [ np.load(\"features/{}.Predictions.X.npy\".format(model)) for model in [\"model{}\".format(i) for i in range(2,5)] ]\n",
    "probas_testing += [ np.load(\"features/{}.Predictions.Xt.npy\".format(model)) for model in [\"model{}\".format(i) for i in range(2,5)] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas_testing += [ np.load(\"probs/{}.probs.npy\".format(\"model1\")) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas_testing += [ np.load(\"probs/cnn_rnn_rot_{}_1.probs.npy\".format(i)) for i in range(4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50000, 1636), (5000, 1636))\n",
      "(0.72913641, 0.8579998, 0.95759976)\n",
      "((50000, 1636), (5000, 1636))\n",
      "(0.66788578, 0.85719979, 0.95359969)\n",
      "((50000, 1636), (5000, 1636))\n",
      "(0.67928755, 0.86019975, 0.95879972)\n"
     ]
    }
   ],
   "source": [
    "g = tf.reset_default_graph()\n",
    "ens = EnsembleNetwork(\"test\", 1636, 100)\n",
    "    \n",
    "# Load FC(RNN+CNN_Logits) Predictions\n",
    "with tf.Session() as sess:    \n",
    "    for i in range(2,5):\n",
    "        X, Y = np.load(\"features/model{}.PreLogitsFlatten.X.npy\".format(i)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "        Xt, Yt = np.load(\"features/model{}.PreLogitsFlatten.Xt.npy\".format(i)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))\n",
    "\n",
    "        ensX = np.hstack((probas_training[i-2], X))\n",
    "        ensXt = np.hstack((probas_testing[i-2], Xt))\n",
    "\n",
    "        print(ensX.shape, ensXt.shape)\n",
    "\n",
    "        ens.saver.restore(sess, \"conv_rnn_prelogits/{}.tfmodel\".format(\"inception_rnn_{}\".format(i)))\n",
    "        print(ens.calculate_loss(sess, ensXt, Yt, size=Xt.shape[0]))\n",
    "        probas_training.append(ens.predict_proba(sess, ensX, size=ensX.shape[0], randomize=False)[1])\n",
    "        probas_testing.append(ens.predict_proba(sess, ensXt, size=ensXt.shape[0], randomize=False)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.74129826, 0.8579998, 0.9563998)\n",
      "(0.67321646, 0.85599977, 0.95259976)\n",
      "(0.71838766, 0.86059982, 0.9593997)\n"
     ]
    }
   ],
   "source": [
    "g = tf.reset_default_graph()\n",
    "ens = EnsembleNetwork(\"test\", 1536, 100)\n",
    "    \n",
    "# Load FC(CNN_Logits) Predictions\n",
    "with tf.Session() as sess:    \n",
    "    for i in range(2,5):\n",
    "        X, Y = np.load(\"features/model{}.PreLogitsFlatten.X.npy\".format(i)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "        Xt, Yt = np.load(\"features/model{}.PreLogitsFlatten.Xt.npy\".format(i)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))\n",
    "\n",
    "        ens.saver.restore(sess, \"conv_rnn_prelogits/{}.tfmodel\".format(\"fc_inception_{}_logits\".format(i)))\n",
    "        print(ens.calculate_loss(sess, Xt, Yt, size=Xt.shape[0]))\n",
    "        probas_training.append(ens.predict_proba(sess, X, size=X.shape[0], randomize=False)[1])\n",
    "        probas_testing.append(ens.predict_proba(sess, Xt, size=Xt.shape[0], randomize=False)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_test = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "y_test = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "correct_prediction_test = tf.equal(tf.argmax(probs_test,1), tf.argmax(y_test,1))\n",
    "top_5_correct_prediction_test = tf.nn.in_top_k(probs_test, tf.argmax(y_test,1), 5)\n",
    "accuracy_test = tf.reduce_mean(tf.cast(correct_prediction_test, tf.float32))\n",
    "top_5_accuracy_test = tf.reduce_mean(tf.cast(top_5_correct_prediction_test, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_models = lambda enslist: reduce(lambda p1, p2: p1 + p2, enslist) / len(enslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.87639982, 0.97219968)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     idx = range(3,6)+[12]\n",
    "#     idx = range(4) #range(len(probas_testing))\n",
    "    idx = [1,2,3,5] #,2,3,5\n",
    "    enslist = [probas_testing[i] for i in idx]\n",
    "#     enslist = probas_testing\n",
    "    ens = ensemble_models(enslist)\n",
    "    corpred, top5corpred, acc, top5acc = sess.run([correct_prediction_test, top_5_correct_prediction_test, accuracy_test, top_5_accuracy_test], feed_dict={probs_test: ens, y_test: Yt})\n",
    "    print(acc, top5acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top1_dist = np.array([ \n",
    "         100*corpred[Yt.argmax(axis=1) == label].astype(np.float32).sum() / corpred[Yt.argmax(axis=1) == label].shape[0] for label in range(0,100) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top5_dist = np.array([ \n",
    "         100*top5corpred[Yt.argmax(axis=1) == label].astype(np.float32).sum() / corpred[Yt.argmax(axis=1) == label].shape[0] for label in range(0,100) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"cnn_rnn_top1_dist.npy\", top1_dist)\n",
    "np.save(\"cnn_rnn_top5_dist.npy\", top5_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "with tf.Session() as sess:\n",
    "    top_weights = []\n",
    "    top_acc_x = 0.0\n",
    "    top_acc_xt = 0.0\n",
    "    for x in np.arange(0.1, 10, 0.1):\n",
    "        for y in np.arange(0.1, 10, 0.1):\n",
    "            weights = [x,y]\n",
    "            if x == y: continue\n",
    "            probas_ensemble_x = reduce(lambda (w1, p1), (w2, p2): w1 * p1 + w2 * p2, zip(weights, probas_training)) / (x+y)\n",
    "            probas_ensemble_xt = reduce(lambda (w1, p1), (w2, p2): w1 * p1 + w2 * p2, zip(weights, probas_testing)) / (x+y)\n",
    "            acc, top5acc_x = sess.run([accuracy_test, top_5_accuracy_test], feed_dict={probs_test: probas_ensemble_x, y_test: Y})\n",
    "            acc, top5acc_xt = sess.run([accuracy_test, top_5_accuracy_test], feed_dict={probs_test: probas_ensemble_xt, y_test: Yt})\n",
    "            if top5acc_x > top_acc_x:\n",
    "                top_acc_x = top5acc_x\n",
    "                top_acc_xt = top5acc_xt\n",
    "                top_weights = weights\n",
    "\n",
    "            update_screen(\"\\rX Acc={:.4f} Top Acc={:.4f} Xt: Acc={:.4f} Top Acc={:.4f} weights={}\".format(top5acc_x, top_acc_x, top5acc_xt, top_acc_xt, top_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas_training[1][12].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(acc, top5acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnsembleNetwork():\n",
    "    def __init__(self, name, n_in, n_out, start_learning_rate=0.1, end_learning_rate=0.0001):\n",
    "        self.name = name\n",
    "        with tf.name_scope(\"Ensemble\") as scope:\n",
    "            self.X = tf.placeholder(tf.float32, shape=[None, n_in], name=\"X\")\n",
    "            self.Y = tf.placeholder(tf.float32, shape=[None, n_out], name=\"Y\")\n",
    "#             self.PreLogits = slim.fully_connected(self.X, 512, activation_fn=None, scope='PreLogits')\n",
    "            self.Logits = slim.fully_connected(self.X, 100, activation_fn=None, scope='Logits')\n",
    "            self.Probs = tf.nn.softmax(self.Logits)\n",
    "\n",
    "            # Define loss and optimizer\n",
    "#             self.GlobalStep = tf.Variable(0, trainable=False)\n",
    "#             self.LearningRate = tf.train.polynomial_decay(start_learning_rate, self.GlobalStep, 100000, end_learning_rate, power=0.5)\n",
    "# #              = tf.train.exponential_decay(init_learning_rate, self.GlobalStep, 100000, 0.96, staircase=True)\n",
    "            self.Cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.Logits, self.Y))\n",
    "            self.Optimizer = tf.train.AdamOptimizer(epsilon=.1, learning_rate=0.01).minimize(self.Cost)\n",
    "\n",
    "            # Evaluate model\n",
    "            self.CorrectPred = tf.equal(tf.argmax(self.Logits,1), tf.argmax(self.Y,1))\n",
    "            self.Top5CorrectPred = tf.nn.in_top_k(self.Probs, tf.argmax(self.Y,1), 5)\n",
    "\n",
    "            self.Accuracy = tf.reduce_mean(tf.cast(self.CorrectPred, tf.float32))\n",
    "            self.Top5Accuracy = tf.reduce_mean(tf.cast(self.Top5CorrectPred, tf.float32))\n",
    "            \n",
    "            self.saver = tf.train.Saver()\n",
    "    \n",
    "    def __iterate_minibatches(self, _X,_y, size):\n",
    "        if _X.shape[0] % size > 0:\n",
    "            raise \"The minibatch size should be a divisor of the batch size.\"\n",
    "\n",
    "        idx = np.arange(_X.shape[0]).astype(np.int32)\n",
    "        np.random.shuffle(idx) # in-place shuffling\n",
    "        for i in range(_X.shape[0] / size):\n",
    "            # To randomize the minibatches every time\n",
    "            _idx = idx[i*size:(i+1)*size]\n",
    "            _X_small = _X[_idx]\n",
    "            _y_small = _y[_idx]\n",
    "            yield _X_small, _y_small\n",
    "    \n",
    "    def predict_proba(self, sess, Xt, size=1000, step=10, randomize=True):\n",
    "        preds, probs = [], []\n",
    "        idx = range(0, Xt.shape[0])\n",
    "        sample_idx = random.sample(idx, size) if randomize else idx\n",
    "        for i in range(size / step):\n",
    "            _pred, _prob = sess.run([self.Logits, self.Probs], feed_dict={self.X: Xt[sample_idx[i*step:(i+1)*step]]})\n",
    "            preds.append(_pred)\n",
    "            probs.append(_prob)\n",
    "\n",
    "        preds = np.vstack(preds)\n",
    "        probs = np.vstack(probs)\n",
    "\n",
    "        return preds, probs, sample_idx\n",
    "    \n",
    "    def calculate_loss(self, sess, Xt, yt, size=1000, step=10):\n",
    "        preds, probs, sample_idx = self.predict_proba(sess, Xt, size=size, step=step)\n",
    "\n",
    "        loss, acc, top5acc = sess.run([self.Cost, self.Accuracy, self.Top5Accuracy], feed_dict={self.Logits: preds, self.Y: yt[sample_idx]})\n",
    "\n",
    "        return loss, acc, top5acc\n",
    "        \n",
    "    def train(self, sess, X, Y, Xt, Yt, epochs=100, batch_size=100):\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        self.prev_acc = 0.0\n",
    "        for ep in range(epochs):\n",
    "            print(\"==== EPOCH {} ====\".format(ep))\n",
    "            step = 1\n",
    "            for _X, _Y in self.__iterate_minibatches(X, Y, batch_size):\n",
    "                sess.run(self.Optimizer, feed_dict={self.X: _X, self.Y: _Y})\n",
    "                if step % display_step == 0:\n",
    "                    loss, acc, top5acc = self.calculate_loss(sess, Xt, Yt)\n",
    "                    print(\"Iter \" + str(step) + \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Acc= \" + \\\n",
    "                          \"{:.4f}\".format(acc) + \", Top-5 Acc= \" + \\\n",
    "                          \"{:.4f}\".format(top5acc))\n",
    "                step += 1\n",
    "\n",
    "            loss, acc, top5acc = self.calculate_loss(sess, Xt, Yt, size=Xt.shape[0])\n",
    "            print(\"====================================\")\n",
    "            print(\"Epoch {}: Loss={} Acc={} Top-5 Acc={}\".format(ep, loss, acc, top5acc))\n",
    "            print(\"====================================\")\n",
    "            if top5acc > self.prev_acc:\n",
    "                self.prev_acc = top5acc\n",
    "                self.saver.save(sess, \"conv_rnn_prelogits/{}.tfmodel\".format(self.name))\n",
    "                print(\"++++ Saved BEST ACC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensX = ensemble_models(probas_training[3:9])\n",
    "ensXt = ensemble_models(probas_testing[3:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensX = np.hstack((ensX / ensX.max(), X))\n",
    "ensXt = np.hstack((ensXt / ensXt.max(), Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.reset_default_graph()\n",
    "ens = EnsembleNetwork(\"fc_ensemble_all_augmented\", ensX.shape[1], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH 0 ====\n",
      "Iter 25, Loss= 4.4248, Acc= 0.0450, Top-5 Acc= 0.1510\n",
      "Iter 50, Loss= 3.7545, Acc= 0.2900, Top-5 Acc= 0.5330\n",
      "Iter 75, Loss= 2.9286, Acc= 0.6580, Top-5 Acc= 0.8260\n",
      "Iter 100, Loss= 2.1362, Acc= 0.8010, Top-5 Acc= 0.9200\n",
      "Iter 125, Loss= 1.5907, Acc= 0.8210, Top-5 Acc= 0.9200\n",
      "Iter 150, Loss= 1.1375, Acc= 0.8570, Top-5 Acc= 0.9450\n",
      "Iter 175, Loss= 0.9622, Acc= 0.8550, Top-5 Acc= 0.9540\n",
      "Iter 200, Loss= 0.8188, Acc= 0.8620, Top-5 Acc= 0.9530\n",
      "Iter 225, Loss= 0.8102, Acc= 0.8490, Top-5 Acc= 0.9480\n",
      "Iter 250, Loss= 0.7109, Acc= 0.8590, Top-5 Acc= 0.9510\n",
      "Iter 275, Loss= 0.6793, Acc= 0.8650, Top-5 Acc= 0.9560\n",
      "Iter 300, Loss= 0.6523, Acc= 0.8670, Top-5 Acc= 0.9590\n",
      "Iter 325, Loss= 0.6146, Acc= 0.8640, Top-5 Acc= 0.9600\n",
      "Iter 350, Loss= 0.7183, Acc= 0.8440, Top-5 Acc= 0.9430\n",
      "Iter 375, Loss= 0.6359, Acc= 0.8560, Top-5 Acc= 0.9540\n",
      "Iter 400, Loss= 0.6212, Acc= 0.8510, Top-5 Acc= 0.9600\n",
      "Iter 425, Loss= 0.6154, Acc= 0.8580, Top-5 Acc= 0.9580\n",
      "Iter 450, Loss= 0.6542, Acc= 0.8490, Top-5 Acc= 0.9500\n",
      "Iter 475, Loss= 0.6191, Acc= 0.8520, Top-5 Acc= 0.9590\n",
      "Iter 500, Loss= 0.7171, Acc= 0.8420, Top-5 Acc= 0.9410\n",
      "Iter 525, Loss= 0.6207, Acc= 0.8590, Top-5 Acc= 0.9540\n",
      "Iter 550, Loss= 0.5930, Acc= 0.8570, Top-5 Acc= 0.9550\n",
      "Iter 575, Loss= 0.6285, Acc= 0.8550, Top-5 Acc= 0.9500\n",
      "Iter 600, Loss= 0.6227, Acc= 0.8620, Top-5 Acc= 0.9550\n",
      "Iter 625, Loss= 0.5690, Acc= 0.8750, Top-5 Acc= 0.9550\n",
      "Iter 650, Loss= 0.5903, Acc= 0.8640, Top-5 Acc= 0.9570\n",
      "Iter 675, Loss= 0.6527, Acc= 0.8550, Top-5 Acc= 0.9440\n",
      "Iter 700, Loss= 0.5893, Acc= 0.8640, Top-5 Acc= 0.9590\n",
      "Iter 725, Loss= 0.6711, Acc= 0.8540, Top-5 Acc= 0.9470\n",
      "Iter 750, Loss= 0.5157, Acc= 0.8790, Top-5 Acc= 0.9640\n",
      "Iter 775, Loss= 0.6091, Acc= 0.8590, Top-5 Acc= 0.9580\n",
      "Iter 800, Loss= 0.5864, Acc= 0.8640, Top-5 Acc= 0.9590\n",
      "Iter 825, Loss= 0.5670, Acc= 0.8550, Top-5 Acc= 0.9570\n",
      "Iter 850, Loss= 0.5808, Acc= 0.8690, Top-5 Acc= 0.9560\n",
      "Iter 875, Loss= 0.6337, Acc= 0.8490, Top-5 Acc= 0.9580\n",
      "Iter 900, Loss= 0.6087, Acc= 0.8510, Top-5 Acc= 0.9600\n",
      "Iter 925, Loss= 0.5721, Acc= 0.8650, Top-5 Acc= 0.9540\n",
      "Iter 950, Loss= 0.6399, Acc= 0.8540, Top-5 Acc= 0.9440\n",
      "Iter 975, Loss= 0.6524, Acc= 0.8550, Top-5 Acc= 0.9530\n",
      "Iter 1000, Loss= 0.5719, Acc= 0.8660, Top-5 Acc= 0.9590\n",
      "====================================\n",
      "Epoch 0: Loss=0.614995181561 Acc=0.857199788094 Top-5 Acc=0.954199671745\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 1 ====\n",
      "Iter 25, Loss= 0.5810, Acc= 0.8600, Top-5 Acc= 0.9600\n",
      "Iter 50, Loss= 0.5700, Acc= 0.8680, Top-5 Acc= 0.9580\n",
      "Iter 75, Loss= 0.6805, Acc= 0.8480, Top-5 Acc= 0.9560\n",
      "Iter 100, Loss= 0.6485, Acc= 0.8550, Top-5 Acc= 0.9550\n",
      "Iter 125, Loss= 0.6692, Acc= 0.8420, Top-5 Acc= 0.9400\n",
      "Iter 150, Loss= 0.6233, Acc= 0.8510, Top-5 Acc= 0.9590\n",
      "Iter 175, Loss= 0.5675, Acc= 0.8670, Top-5 Acc= 0.9560\n",
      "Iter 200, Loss= 0.5670, Acc= 0.8710, Top-5 Acc= 0.9540\n",
      "Iter 225, Loss= 0.5424, Acc= 0.8800, Top-5 Acc= 0.9570\n",
      "Iter 250, Loss= 0.5711, Acc= 0.8740, Top-5 Acc= 0.9630\n",
      "Iter 275, Loss= 0.6371, Acc= 0.8560, Top-5 Acc= 0.9550\n",
      "Iter 300, Loss= 0.6109, Acc= 0.8540, Top-5 Acc= 0.9510\n",
      "Iter 325, Loss= 0.6884, Acc= 0.8510, Top-5 Acc= 0.9490\n",
      "Iter 350, Loss= 0.5700, Acc= 0.8660, Top-5 Acc= 0.9610\n",
      "Iter 375, Loss= 0.6609, Acc= 0.8480, Top-5 Acc= 0.9490\n",
      "Iter 400, Loss= 0.6359, Acc= 0.8550, Top-5 Acc= 0.9500\n",
      "Iter 425, Loss= 0.6491, Acc= 0.8550, Top-5 Acc= 0.9490\n",
      "Iter 450, Loss= 0.6552, Acc= 0.8470, Top-5 Acc= 0.9580\n",
      "Iter 475, Loss= 0.6686, Acc= 0.8450, Top-5 Acc= 0.9500\n",
      "Iter 500, Loss= 0.5964, Acc= 0.8510, Top-5 Acc= 0.9580\n",
      "Iter 525, Loss= 0.5518, Acc= 0.8770, Top-5 Acc= 0.9580\n",
      "Iter 550, Loss= 0.6577, Acc= 0.8600, Top-5 Acc= 0.9480\n",
      "Iter 575, Loss= 0.6730, Acc= 0.8400, Top-5 Acc= 0.9590\n",
      "Iter 600, Loss= 0.6092, Acc= 0.8610, Top-5 Acc= 0.9540\n",
      "Iter 625, Loss= 0.6347, Acc= 0.8590, Top-5 Acc= 0.9610\n",
      "Iter 650, Loss= 0.6348, Acc= 0.8600, Top-5 Acc= 0.9580\n",
      "Iter 675, Loss= 0.7101, Acc= 0.8390, Top-5 Acc= 0.9490\n",
      "Iter 700, Loss= 0.6504, Acc= 0.8510, Top-5 Acc= 0.9640\n",
      "Iter 725, Loss= 0.5773, Acc= 0.8720, Top-5 Acc= 0.9550\n",
      "Iter 750, Loss= 0.6097, Acc= 0.8440, Top-5 Acc= 0.9650\n",
      "Iter 775, Loss= 0.6927, Acc= 0.8410, Top-5 Acc= 0.9590\n",
      "Iter 800, Loss= 0.5184, Acc= 0.8690, Top-5 Acc= 0.9720\n",
      "Iter 825, Loss= 0.6307, Acc= 0.8520, Top-5 Acc= 0.9550\n",
      "Iter 850, Loss= 0.6337, Acc= 0.8530, Top-5 Acc= 0.9580\n",
      "Iter 875, Loss= 0.5906, Acc= 0.8640, Top-5 Acc= 0.9610\n",
      "Iter 900, Loss= 0.6674, Acc= 0.8490, Top-5 Acc= 0.9600\n",
      "Iter 925, Loss= 0.5957, Acc= 0.8510, Top-5 Acc= 0.9550\n",
      "Iter 950, Loss= 0.6259, Acc= 0.8690, Top-5 Acc= 0.9560\n",
      "Iter 975, Loss= 0.6878, Acc= 0.8560, Top-5 Acc= 0.9510\n",
      "Iter 1000, Loss= 0.5963, Acc= 0.8640, Top-5 Acc= 0.9630\n",
      "====================================\n",
      "Epoch 1: Loss=0.635757923126 Acc=0.85699981451 Top-5 Acc=0.956399738789\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 2 ====\n",
      "Iter 25, Loss= 0.5847, Acc= 0.8720, Top-5 Acc= 0.9630\n",
      "Iter 50, Loss= 0.6913, Acc= 0.8460, Top-5 Acc= 0.9570\n",
      "Iter 75, Loss= 0.7967, Acc= 0.8430, Top-5 Acc= 0.9440\n",
      "Iter 100, Loss= 0.5907, Acc= 0.8710, Top-5 Acc= 0.9530\n",
      "Iter 125, Loss= 0.6037, Acc= 0.8670, Top-5 Acc= 0.9580\n",
      "Iter 150, Loss= 0.5958, Acc= 0.8730, Top-5 Acc= 0.9620\n",
      "Iter 175, Loss= 0.6528, Acc= 0.8560, Top-5 Acc= 0.9550\n",
      "Iter 200, Loss= 0.6178, Acc= 0.8660, Top-5 Acc= 0.9630\n",
      "Iter 225, Loss= 0.6321, Acc= 0.8500, Top-5 Acc= 0.9590\n",
      "Iter 250, Loss= 0.6583, Acc= 0.8500, Top-5 Acc= 0.9620\n",
      "Iter 275, Loss= 0.6286, Acc= 0.8640, Top-5 Acc= 0.9540\n",
      "Iter 300, Loss= 0.7027, Acc= 0.8450, Top-5 Acc= 0.9410\n",
      "Iter 325, Loss= 0.6981, Acc= 0.8490, Top-5 Acc= 0.9520\n",
      "Iter 350, Loss= 0.6450, Acc= 0.8540, Top-5 Acc= 0.9600\n",
      "Iter 375, Loss= 0.6330, Acc= 0.8660, Top-5 Acc= 0.9520\n",
      "Iter 400, Loss= 0.6536, Acc= 0.8590, Top-5 Acc= 0.9530\n",
      "Iter 425, Loss= 0.6566, Acc= 0.8560, Top-5 Acc= 0.9520\n",
      "Iter 450, Loss= 0.6179, Acc= 0.8670, Top-5 Acc= 0.9560\n",
      "Iter 475, Loss= 0.7024, Acc= 0.8540, Top-5 Acc= 0.9540\n",
      "Iter 500, Loss= 0.6891, Acc= 0.8480, Top-5 Acc= 0.9520\n",
      "Iter 525, Loss= 0.6433, Acc= 0.8630, Top-5 Acc= 0.9540\n",
      "Iter 550, Loss= 0.5755, Acc= 0.8720, Top-5 Acc= 0.9580\n",
      "Iter 575, Loss= 0.7149, Acc= 0.8540, Top-5 Acc= 0.9490\n",
      "Iter 600, Loss= 0.7294, Acc= 0.8450, Top-5 Acc= 0.9480\n",
      "Iter 625, Loss= 0.6343, Acc= 0.8610, Top-5 Acc= 0.9580\n",
      "Iter 650, Loss= 0.7476, Acc= 0.8410, Top-5 Acc= 0.9540\n",
      "Iter 675, Loss= 0.6444, Acc= 0.8740, Top-5 Acc= 0.9590\n",
      "Iter 700, Loss= 0.6357, Acc= 0.8590, Top-5 Acc= 0.9560\n",
      "Iter 725, Loss= 0.6665, Acc= 0.8560, Top-5 Acc= 0.9580\n",
      "Iter 750, Loss= 0.6519, Acc= 0.8580, Top-5 Acc= 0.9650\n",
      "Iter 775, Loss= 0.7099, Acc= 0.8390, Top-5 Acc= 0.9530\n",
      "Iter 800, Loss= 0.6975, Acc= 0.8420, Top-5 Acc= 0.9600\n",
      "Iter 825, Loss= 0.6198, Acc= 0.8640, Top-5 Acc= 0.9660\n",
      "Iter 850, Loss= 0.6424, Acc= 0.8610, Top-5 Acc= 0.9620\n",
      "Iter 875, Loss= 0.6618, Acc= 0.8550, Top-5 Acc= 0.9620\n",
      "Iter 900, Loss= 0.7084, Acc= 0.8400, Top-5 Acc= 0.9560\n",
      "Iter 925, Loss= 0.6655, Acc= 0.8550, Top-5 Acc= 0.9490\n",
      "Iter 950, Loss= 0.6042, Acc= 0.8620, Top-5 Acc= 0.9630\n",
      "Iter 975, Loss= 0.6376, Acc= 0.8630, Top-5 Acc= 0.9630\n",
      "Iter 1000, Loss= 0.6391, Acc= 0.8590, Top-5 Acc= 0.9610\n",
      "====================================\n",
      "Epoch 2: Loss=0.653962731361 Acc=0.858399748802 Top-5 Acc=0.958999693394\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 3 ====\n",
      "Iter 25, Loss= 0.6312, Acc= 0.8650, Top-5 Acc= 0.9620\n",
      "Iter 50, Loss= 0.6121, Acc= 0.8580, Top-5 Acc= 0.9630\n",
      "Iter 75, Loss= 0.6497, Acc= 0.8530, Top-5 Acc= 0.9580\n",
      "Iter 100, Loss= 0.5962, Acc= 0.8790, Top-5 Acc= 0.9570\n",
      "Iter 125, Loss= 0.5966, Acc= 0.8700, Top-5 Acc= 0.9620\n",
      "Iter 150, Loss= 0.6514, Acc= 0.8610, Top-5 Acc= 0.9550\n",
      "Iter 175, Loss= 0.6848, Acc= 0.8630, Top-5 Acc= 0.9580\n",
      "Iter 200, Loss= 0.6195, Acc= 0.8630, Top-5 Acc= 0.9520\n",
      "Iter 225, Loss= 0.6148, Acc= 0.8640, Top-5 Acc= 0.9650\n",
      "Iter 250, Loss= 0.6509, Acc= 0.8640, Top-5 Acc= 0.9580\n",
      "Iter 275, Loss= 0.5794, Acc= 0.8700, Top-5 Acc= 0.9610\n",
      "Iter 300, Loss= 0.6600, Acc= 0.8560, Top-5 Acc= 0.9610\n",
      "Iter 325, Loss= 0.6679, Acc= 0.8620, Top-5 Acc= 0.9550\n",
      "Iter 350, Loss= 0.6808, Acc= 0.8560, Top-5 Acc= 0.9540\n",
      "Iter 375, Loss= 0.5832, Acc= 0.8700, Top-5 Acc= 0.9680\n",
      "Iter 400, Loss= 0.7180, Acc= 0.8440, Top-5 Acc= 0.9560\n",
      "Iter 425, Loss= 0.6211, Acc= 0.8660, Top-5 Acc= 0.9690\n",
      "Iter 450, Loss= 0.7149, Acc= 0.8440, Top-5 Acc= 0.9580\n",
      "Iter 475, Loss= 0.6199, Acc= 0.8640, Top-5 Acc= 0.9570\n",
      "Iter 500, Loss= 0.6118, Acc= 0.8710, Top-5 Acc= 0.9620\n",
      "Iter 525, Loss= 0.6063, Acc= 0.8660, Top-5 Acc= 0.9600\n",
      "Iter 550, Loss= 0.6567, Acc= 0.8580, Top-5 Acc= 0.9660\n",
      "Iter 575, Loss= 0.6889, Acc= 0.8540, Top-5 Acc= 0.9560\n",
      "Iter 600, Loss= 0.6699, Acc= 0.8630, Top-5 Acc= 0.9620\n",
      "Iter 625, Loss= 0.6648, Acc= 0.8560, Top-5 Acc= 0.9640\n",
      "Iter 650, Loss= 0.6104, Acc= 0.8700, Top-5 Acc= 0.9680\n",
      "Iter 675, Loss= 0.6351, Acc= 0.8640, Top-5 Acc= 0.9620\n",
      "Iter 700, Loss= 0.7046, Acc= 0.8510, Top-5 Acc= 0.9480\n",
      "Iter 725, Loss= 0.6894, Acc= 0.8480, Top-5 Acc= 0.9590\n",
      "Iter 750, Loss= 0.6845, Acc= 0.8630, Top-5 Acc= 0.9610\n",
      "Iter 775, Loss= 0.6326, Acc= 0.8680, Top-5 Acc= 0.9610\n",
      "Iter 800, Loss= 0.6259, Acc= 0.8650, Top-5 Acc= 0.9610\n",
      "Iter 825, Loss= 0.6499, Acc= 0.8580, Top-5 Acc= 0.9560\n",
      "Iter 850, Loss= 0.6681, Acc= 0.8620, Top-5 Acc= 0.9600\n",
      "Iter 875, Loss= 0.5863, Acc= 0.8670, Top-5 Acc= 0.9650\n",
      "Iter 900, Loss= 0.6132, Acc= 0.8650, Top-5 Acc= 0.9610\n",
      "Iter 925, Loss= 0.6926, Acc= 0.8520, Top-5 Acc= 0.9550\n",
      "Iter 950, Loss= 0.7124, Acc= 0.8460, Top-5 Acc= 0.9580\n",
      "Iter 975, Loss= 0.6735, Acc= 0.8500, Top-5 Acc= 0.9540\n",
      "Iter 1000, Loss= 0.5818, Acc= 0.8780, Top-5 Acc= 0.9640\n",
      "====================================\n",
      "Epoch 3: Loss=0.669176638126 Acc=0.858399748802 Top-5 Acc=0.957399785519\n",
      "====================================\n",
      "==== EPOCH 4 ====\n",
      "Iter 25, Loss= 0.5850, Acc= 0.8730, Top-5 Acc= 0.9600\n",
      "Iter 50, Loss= 0.6590, Acc= 0.8540, Top-5 Acc= 0.9560\n",
      "Iter 75, Loss= 0.7120, Acc= 0.8490, Top-5 Acc= 0.9580\n",
      "Iter 100, Loss= 0.5804, Acc= 0.8810, Top-5 Acc= 0.9610\n",
      "Iter 125, Loss= 0.6390, Acc= 0.8670, Top-5 Acc= 0.9660\n",
      "Iter 150, Loss= 0.6694, Acc= 0.8500, Top-5 Acc= 0.9630\n",
      "Iter 175, Loss= 0.6852, Acc= 0.8520, Top-5 Acc= 0.9590\n",
      "Iter 200, Loss= 0.6792, Acc= 0.8610, Top-5 Acc= 0.9590\n",
      "Iter 225, Loss= 0.6275, Acc= 0.8690, Top-5 Acc= 0.9570\n",
      "Iter 250, Loss= 0.5906, Acc= 0.8680, Top-5 Acc= 0.9630\n",
      "Iter 275, Loss= 0.6686, Acc= 0.8520, Top-5 Acc= 0.9610\n",
      "Iter 300, Loss= 0.8571, Acc= 0.8260, Top-5 Acc= 0.9430\n",
      "Iter 325, Loss= 0.6565, Acc= 0.8670, Top-5 Acc= 0.9560\n",
      "Iter 350, Loss= 0.6380, Acc= 0.8700, Top-5 Acc= 0.9610\n",
      "Iter 375, Loss= 0.6447, Acc= 0.8630, Top-5 Acc= 0.9650\n",
      "Iter 400, Loss= 0.6387, Acc= 0.8630, Top-5 Acc= 0.9590\n",
      "Iter 425, Loss= 0.6262, Acc= 0.8590, Top-5 Acc= 0.9620\n",
      "Iter 450, Loss= 0.7545, Acc= 0.8340, Top-5 Acc= 0.9560\n",
      "Iter 475, Loss= 0.6763, Acc= 0.8550, Top-5 Acc= 0.9560\n",
      "Iter 500, Loss= 0.6596, Acc= 0.8600, Top-5 Acc= 0.9600\n",
      "Iter 525, Loss= 0.6248, Acc= 0.8720, Top-5 Acc= 0.9640\n",
      "Iter 550, Loss= 0.7205, Acc= 0.8470, Top-5 Acc= 0.9570\n",
      "Iter 575, Loss= 0.7474, Acc= 0.8500, Top-5 Acc= 0.9590\n",
      "Iter 600, Loss= 0.6777, Acc= 0.8560, Top-5 Acc= 0.9630\n",
      "Iter 625, Loss= 0.7014, Acc= 0.8600, Top-5 Acc= 0.9560\n",
      "Iter 650, Loss= 0.7003, Acc= 0.8490, Top-5 Acc= 0.9550\n",
      "Iter 675, Loss= 0.6396, Acc= 0.8580, Top-5 Acc= 0.9530\n",
      "Iter 700, Loss= 0.6937, Acc= 0.8580, Top-5 Acc= 0.9520\n",
      "Iter 725, Loss= 0.6442, Acc= 0.8680, Top-5 Acc= 0.9580\n",
      "Iter 750, Loss= 0.6382, Acc= 0.8620, Top-5 Acc= 0.9640\n",
      "Iter 775, Loss= 0.6078, Acc= 0.8590, Top-5 Acc= 0.9610\n",
      "Iter 800, Loss= 0.7916, Acc= 0.8540, Top-5 Acc= 0.9540\n",
      "Iter 825, Loss= 0.6567, Acc= 0.8620, Top-5 Acc= 0.9600\n",
      "Iter 850, Loss= 0.6544, Acc= 0.8550, Top-5 Acc= 0.9650\n",
      "Iter 875, Loss= 0.6585, Acc= 0.8670, Top-5 Acc= 0.9580\n",
      "Iter 900, Loss= 0.6316, Acc= 0.8670, Top-5 Acc= 0.9580\n",
      "Iter 925, Loss= 0.7013, Acc= 0.8460, Top-5 Acc= 0.9520\n",
      "Iter 950, Loss= 0.7318, Acc= 0.8540, Top-5 Acc= 0.9550\n",
      "Iter 975, Loss= 0.6538, Acc= 0.8600, Top-5 Acc= 0.9610\n",
      "Iter 1000, Loss= 0.6694, Acc= 0.8630, Top-5 Acc= 0.9550\n",
      "====================================\n",
      "Epoch 4: Loss=0.681490123272 Acc=0.859199762344 Top-5 Acc=0.958599686623\n",
      "====================================\n",
      "==== EPOCH 5 ====\n",
      "Iter 25, Loss= 0.7269, Acc= 0.8510, Top-5 Acc= 0.9530\n",
      "Iter 50, Loss= 0.6361, Acc= 0.8720, Top-5 Acc= 0.9680\n",
      "Iter 75, Loss= 0.5419, Acc= 0.8830, Top-5 Acc= 0.9650\n",
      "Iter 100, Loss= 0.7377, Acc= 0.8410, Top-5 Acc= 0.9550\n",
      "Iter 125, Loss= 0.6504, Acc= 0.8660, Top-5 Acc= 0.9670\n",
      "Iter 150, Loss= 0.7277, Acc= 0.8520, Top-5 Acc= 0.9570\n",
      "Iter 175, Loss= 0.6562, Acc= 0.8620, Top-5 Acc= 0.9550\n",
      "Iter 200, Loss= 0.6120, Acc= 0.8730, Top-5 Acc= 0.9640\n",
      "Iter 225, Loss= 0.6825, Acc= 0.8580, Top-5 Acc= 0.9590\n",
      "Iter 250, Loss= 0.6564, Acc= 0.8680, Top-5 Acc= 0.9620\n",
      "Iter 275, Loss= 0.7980, Acc= 0.8480, Top-5 Acc= 0.9510\n",
      "Iter 300, Loss= 0.5910, Acc= 0.8710, Top-5 Acc= 0.9590\n",
      "Iter 325, Loss= 0.6819, Acc= 0.8600, Top-5 Acc= 0.9560\n",
      "Iter 350, Loss= 0.6582, Acc= 0.8640, Top-5 Acc= 0.9610\n",
      "Iter 375, Loss= 0.7445, Acc= 0.8450, Top-5 Acc= 0.9550\n",
      "Iter 400, Loss= 0.7759, Acc= 0.8440, Top-5 Acc= 0.9600\n",
      "Iter 425, Loss= 0.7366, Acc= 0.8540, Top-5 Acc= 0.9490\n",
      "Iter 450, Loss= 0.6826, Acc= 0.8520, Top-5 Acc= 0.9620\n",
      "Iter 475, Loss= 0.6940, Acc= 0.8550, Top-5 Acc= 0.9580\n",
      "Iter 500, Loss= 0.6408, Acc= 0.8700, Top-5 Acc= 0.9670\n",
      "Iter 525, Loss= 0.7040, Acc= 0.8580, Top-5 Acc= 0.9590\n",
      "Iter 550, Loss= 0.6589, Acc= 0.8670, Top-5 Acc= 0.9650\n",
      "Iter 575, Loss= 0.6937, Acc= 0.8590, Top-5 Acc= 0.9550\n",
      "Iter 600, Loss= 0.6958, Acc= 0.8630, Top-5 Acc= 0.9530\n",
      "Iter 625, Loss= 0.7161, Acc= 0.8570, Top-5 Acc= 0.9590\n",
      "Iter 650, Loss= 0.6278, Acc= 0.8640, Top-5 Acc= 0.9660\n",
      "Iter 675, Loss= 0.7299, Acc= 0.8470, Top-5 Acc= 0.9570\n",
      "Iter 700, Loss= 0.7100, Acc= 0.8520, Top-5 Acc= 0.9590\n",
      "Iter 725, Loss= 0.6777, Acc= 0.8550, Top-5 Acc= 0.9570\n",
      "Iter 750, Loss= 0.9089, Acc= 0.8240, Top-5 Acc= 0.9490\n",
      "Iter 775, Loss= 0.7215, Acc= 0.8540, Top-5 Acc= 0.9570\n",
      "Iter 800, Loss= 0.7388, Acc= 0.8590, Top-5 Acc= 0.9610\n",
      "Iter 825, Loss= 0.6747, Acc= 0.8550, Top-5 Acc= 0.9550\n",
      "Iter 850, Loss= 0.6955, Acc= 0.8540, Top-5 Acc= 0.9530\n",
      "Iter 875, Loss= 0.7525, Acc= 0.8560, Top-5 Acc= 0.9540\n",
      "Iter 900, Loss= 0.6572, Acc= 0.8600, Top-5 Acc= 0.9620\n",
      "Iter 925, Loss= 0.5791, Acc= 0.8720, Top-5 Acc= 0.9670\n",
      "Iter 950, Loss= 0.6604, Acc= 0.8520, Top-5 Acc= 0.9560\n",
      "Iter 975, Loss= 0.7053, Acc= 0.8450, Top-5 Acc= 0.9580\n",
      "Iter 1000, Loss= 0.6734, Acc= 0.8600, Top-5 Acc= 0.9650\n",
      "====================================\n",
      "Epoch 5: Loss=0.690036296844 Acc=0.857399761677 Top-5 Acc=0.959399819374\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 6 ====\n",
      "Iter 25, Loss= 0.7043, Acc= 0.8610, Top-5 Acc= 0.9620\n",
      "Iter 50, Loss= 0.7376, Acc= 0.8480, Top-5 Acc= 0.9530\n",
      "Iter 75, Loss= 0.7303, Acc= 0.8550, Top-5 Acc= 0.9500\n",
      "Iter 100, Loss= 0.5773, Acc= 0.8710, Top-5 Acc= 0.9640\n",
      "Iter 125, Loss= 0.7215, Acc= 0.8530, Top-5 Acc= 0.9530\n",
      "Iter 150, Loss= 0.7319, Acc= 0.8580, Top-5 Acc= 0.9620\n",
      "Iter 175, Loss= 0.6661, Acc= 0.8630, Top-5 Acc= 0.9600\n",
      "Iter 200, Loss= 0.7495, Acc= 0.8560, Top-5 Acc= 0.9580\n",
      "Iter 225, Loss= 0.7797, Acc= 0.8360, Top-5 Acc= 0.9470\n",
      "Iter 250, Loss= 0.7341, Acc= 0.8500, Top-5 Acc= 0.9530\n",
      "Iter 275, Loss= 0.6527, Acc= 0.8640, Top-5 Acc= 0.9610\n",
      "Iter 300, Loss= 0.6569, Acc= 0.8550, Top-5 Acc= 0.9620\n",
      "Iter 325, Loss= 0.7135, Acc= 0.8590, Top-5 Acc= 0.9560\n",
      "Iter 350, Loss= 0.6792, Acc= 0.8580, Top-5 Acc= 0.9580\n",
      "Iter 375, Loss= 0.5726, Acc= 0.8790, Top-5 Acc= 0.9720\n",
      "Iter 400, Loss= 0.7119, Acc= 0.8590, Top-5 Acc= 0.9550\n",
      "Iter 425, Loss= 0.6701, Acc= 0.8690, Top-5 Acc= 0.9590\n",
      "Iter 450, Loss= 0.6536, Acc= 0.8620, Top-5 Acc= 0.9640\n",
      "Iter 475, Loss= 0.6911, Acc= 0.8640, Top-5 Acc= 0.9570\n",
      "Iter 500, Loss= 0.6875, Acc= 0.8610, Top-5 Acc= 0.9560\n",
      "Iter 525, Loss= 0.6485, Acc= 0.8660, Top-5 Acc= 0.9590\n",
      "Iter 550, Loss= 0.6918, Acc= 0.8610, Top-5 Acc= 0.9570\n",
      "Iter 575, Loss= 0.7801, Acc= 0.8500, Top-5 Acc= 0.9460\n",
      "Iter 600, Loss= 0.6903, Acc= 0.8550, Top-5 Acc= 0.9630\n",
      "Iter 625, Loss= 0.6894, Acc= 0.8560, Top-5 Acc= 0.9590\n",
      "Iter 650, Loss= 0.7157, Acc= 0.8570, Top-5 Acc= 0.9510\n",
      "Iter 675, Loss= 0.7005, Acc= 0.8640, Top-5 Acc= 0.9560\n",
      "Iter 700, Loss= 0.6536, Acc= 0.8590, Top-5 Acc= 0.9680\n",
      "Iter 725, Loss= 0.7405, Acc= 0.8450, Top-5 Acc= 0.9580\n",
      "Iter 750, Loss= 0.6438, Acc= 0.8750, Top-5 Acc= 0.9620\n",
      "Iter 775, Loss= 0.6493, Acc= 0.8640, Top-5 Acc= 0.9610\n",
      "Iter 800, Loss= 0.6614, Acc= 0.8720, Top-5 Acc= 0.9630\n",
      "Iter 825, Loss= 0.7069, Acc= 0.8520, Top-5 Acc= 0.9600\n",
      "Iter 850, Loss= 0.7524, Acc= 0.8460, Top-5 Acc= 0.9550\n",
      "Iter 875, Loss= 0.7381, Acc= 0.8580, Top-5 Acc= 0.9490\n",
      "Iter 900, Loss= 0.6176, Acc= 0.8710, Top-5 Acc= 0.9680\n",
      "Iter 925, Loss= 0.6553, Acc= 0.8670, Top-5 Acc= 0.9600\n",
      "Iter 950, Loss= 0.6996, Acc= 0.8550, Top-5 Acc= 0.9620\n",
      "Iter 975, Loss= 0.6398, Acc= 0.8720, Top-5 Acc= 0.9630\n",
      "Iter 1000, Loss= 0.7145, Acc= 0.8520, Top-5 Acc= 0.9600\n",
      "====================================\n",
      "Epoch 6: Loss=0.699424505234 Acc=0.859199762344 Top-5 Acc=0.958999633789\n",
      "====================================\n",
      "==== EPOCH 7 ====\n",
      "Iter 25, Loss= 0.7470, Acc= 0.8570, Top-5 Acc= 0.9500\n",
      "Iter 50, Loss= 0.6793, Acc= 0.8710, Top-5 Acc= 0.9660\n",
      "Iter 75, Loss= 0.7172, Acc= 0.8480, Top-5 Acc= 0.9570\n",
      "Iter 100, Loss= 0.6084, Acc= 0.8690, Top-5 Acc= 0.9610\n",
      "Iter 125, Loss= 0.7153, Acc= 0.8620, Top-5 Acc= 0.9620\n",
      "Iter 150, Loss= 0.6592, Acc= 0.8680, Top-5 Acc= 0.9540\n",
      "Iter 175, Loss= 0.6710, Acc= 0.8570, Top-5 Acc= 0.9580\n",
      "Iter 200, Loss= 0.6692, Acc= 0.8580, Top-5 Acc= 0.9680\n",
      "Iter 225, Loss= 0.7830, Acc= 0.8540, Top-5 Acc= 0.9590\n",
      "Iter 250, Loss= 0.8511, Acc= 0.8390, Top-5 Acc= 0.9530\n",
      "Iter 275, Loss= 0.7340, Acc= 0.8590, Top-5 Acc= 0.9520\n",
      "Iter 300, Loss= 0.7443, Acc= 0.8480, Top-5 Acc= 0.9560\n",
      "Iter 325, Loss= 0.6795, Acc= 0.8670, Top-5 Acc= 0.9650\n",
      "Iter 350, Loss= 0.7568, Acc= 0.8560, Top-5 Acc= 0.9570\n",
      "Iter 375, Loss= 0.7061, Acc= 0.8600, Top-5 Acc= 0.9530\n",
      "Iter 400, Loss= 0.6511, Acc= 0.8730, Top-5 Acc= 0.9660\n",
      "Iter 425, Loss= 0.6231, Acc= 0.8720, Top-5 Acc= 0.9710\n",
      "Iter 450, Loss= 0.7686, Acc= 0.8510, Top-5 Acc= 0.9610\n",
      "Iter 475, Loss= 0.7382, Acc= 0.8540, Top-5 Acc= 0.9520\n",
      "Iter 500, Loss= 0.6313, Acc= 0.8760, Top-5 Acc= 0.9650\n",
      "Iter 525, Loss= 0.6443, Acc= 0.8690, Top-5 Acc= 0.9600\n",
      "Iter 550, Loss= 0.7714, Acc= 0.8500, Top-5 Acc= 0.9470\n",
      "Iter 575, Loss= 0.7123, Acc= 0.8550, Top-5 Acc= 0.9590\n",
      "Iter 600, Loss= 0.8302, Acc= 0.8360, Top-5 Acc= 0.9560\n",
      "Iter 625, Loss= 0.7450, Acc= 0.8490, Top-5 Acc= 0.9560\n",
      "Iter 650, Loss= 0.6828, Acc= 0.8610, Top-5 Acc= 0.9540\n",
      "Iter 675, Loss= 0.7211, Acc= 0.8680, Top-5 Acc= 0.9600\n",
      "Iter 700, Loss= 0.7542, Acc= 0.8490, Top-5 Acc= 0.9520\n",
      "Iter 725, Loss= 0.7932, Acc= 0.8440, Top-5 Acc= 0.9490\n",
      "Iter 750, Loss= 0.6687, Acc= 0.8720, Top-5 Acc= 0.9600\n",
      "Iter 775, Loss= 0.6837, Acc= 0.8630, Top-5 Acc= 0.9630\n",
      "Iter 800, Loss= 0.6692, Acc= 0.8700, Top-5 Acc= 0.9610\n",
      "Iter 825, Loss= 0.7785, Acc= 0.8580, Top-5 Acc= 0.9520\n",
      "Iter 850, Loss= 0.7372, Acc= 0.8500, Top-5 Acc= 0.9540\n",
      "Iter 875, Loss= 0.8744, Acc= 0.8300, Top-5 Acc= 0.9460\n",
      "Iter 900, Loss= 0.6827, Acc= 0.8520, Top-5 Acc= 0.9580\n",
      "Iter 925, Loss= 0.8100, Acc= 0.8370, Top-5 Acc= 0.9460\n",
      "Iter 950, Loss= 0.6159, Acc= 0.8700, Top-5 Acc= 0.9660\n",
      "Iter 975, Loss= 0.6455, Acc= 0.8620, Top-5 Acc= 0.9620\n",
      "Iter 1000, Loss= 0.7094, Acc= 0.8500, Top-5 Acc= 0.9660\n",
      "====================================\n",
      "Epoch 7: Loss=0.706715106964 Acc=0.858399748802 Top-5 Acc=0.959199726582\n",
      "====================================\n",
      "==== EPOCH 8 ====\n",
      "Iter 25, Loss= 0.7293, Acc= 0.8500, Top-5 Acc= 0.9610\n",
      "Iter 50, Loss= 0.7495, Acc= 0.8520, Top-5 Acc= 0.9530\n",
      "Iter 75, Loss= 0.7336, Acc= 0.8640, Top-5 Acc= 0.9510\n",
      "Iter 100, Loss= 0.7571, Acc= 0.8530, Top-5 Acc= 0.9550\n",
      "Iter 125, Loss= 0.7856, Acc= 0.8520, Top-5 Acc= 0.9470\n",
      "Iter 150, Loss= 0.6781, Acc= 0.8600, Top-5 Acc= 0.9630\n",
      "Iter 175, Loss= 0.7308, Acc= 0.8560, Top-5 Acc= 0.9480\n",
      "Iter 200, Loss= 0.6962, Acc= 0.8550, Top-5 Acc= 0.9650\n",
      "Iter 225, Loss= 0.7425, Acc= 0.8520, Top-5 Acc= 0.9550\n",
      "Iter 250, Loss= 0.7243, Acc= 0.8500, Top-5 Acc= 0.9530\n",
      "Iter 275, Loss= 0.6387, Acc= 0.8650, Top-5 Acc= 0.9570\n",
      "Iter 300, Loss= 0.7452, Acc= 0.8480, Top-5 Acc= 0.9530\n",
      "Iter 325, Loss= 0.6446, Acc= 0.8700, Top-5 Acc= 0.9660\n",
      "Iter 350, Loss= 0.6745, Acc= 0.8710, Top-5 Acc= 0.9600\n",
      "Iter 375, Loss= 0.7990, Acc= 0.8390, Top-5 Acc= 0.9580\n",
      "Iter 400, Loss= 0.6707, Acc= 0.8670, Top-5 Acc= 0.9600\n",
      "Iter 425, Loss= 0.7237, Acc= 0.8540, Top-5 Acc= 0.9570\n",
      "Iter 450, Loss= 0.7348, Acc= 0.8620, Top-5 Acc= 0.9570\n",
      "Iter 475, Loss= 0.6470, Acc= 0.8620, Top-5 Acc= 0.9610\n",
      "Iter 500, Loss= 0.6874, Acc= 0.8610, Top-5 Acc= 0.9540\n",
      "Iter 525, Loss= 0.7569, Acc= 0.8480, Top-5 Acc= 0.9520\n",
      "Iter 550, Loss= 0.6448, Acc= 0.8610, Top-5 Acc= 0.9700\n",
      "Iter 575, Loss= 0.6822, Acc= 0.8610, Top-5 Acc= 0.9570\n",
      "Iter 600, Loss= 0.7391, Acc= 0.8520, Top-5 Acc= 0.9550\n",
      "Iter 625, Loss= 0.6799, Acc= 0.8630, Top-5 Acc= 0.9570\n",
      "Iter 650, Loss= 0.6441, Acc= 0.8620, Top-5 Acc= 0.9620\n",
      "Iter 675, Loss= 0.8224, Acc= 0.8510, Top-5 Acc= 0.9520\n",
      "Iter 700, Loss= 0.6966, Acc= 0.8540, Top-5 Acc= 0.9610\n",
      "Iter 725, Loss= 0.7555, Acc= 0.8610, Top-5 Acc= 0.9570\n",
      "Iter 750, Loss= 0.6279, Acc= 0.8660, Top-5 Acc= 0.9640\n",
      "Iter 775, Loss= 0.8103, Acc= 0.8450, Top-5 Acc= 0.9580\n",
      "Iter 800, Loss= 0.7092, Acc= 0.8610, Top-5 Acc= 0.9640\n",
      "Iter 825, Loss= 0.6789, Acc= 0.8490, Top-5 Acc= 0.9620\n",
      "Iter 850, Loss= 0.6801, Acc= 0.8650, Top-5 Acc= 0.9640\n",
      "Iter 875, Loss= 0.7270, Acc= 0.8610, Top-5 Acc= 0.9600\n",
      "Iter 900, Loss= 0.7420, Acc= 0.8560, Top-5 Acc= 0.9600\n",
      "Iter 925, Loss= 0.6022, Acc= 0.8740, Top-5 Acc= 0.9720\n",
      "Iter 950, Loss= 0.6863, Acc= 0.8650, Top-5 Acc= 0.9590\n",
      "Iter 975, Loss= 0.7662, Acc= 0.8500, Top-5 Acc= 0.9510\n",
      "Iter 1000, Loss= 0.7870, Acc= 0.8470, Top-5 Acc= 0.9510\n",
      "====================================\n",
      "Epoch 8: Loss=0.713816761971 Acc=0.859199762344 Top-5 Acc=0.958799779415\n",
      "====================================\n",
      "==== EPOCH 9 ====\n",
      "Iter 25, Loss= 0.7767, Acc= 0.8530, Top-5 Acc= 0.9560\n",
      "Iter 50, Loss= 0.8754, Acc= 0.8390, Top-5 Acc= 0.9520\n",
      "Iter 75, Loss= 0.6689, Acc= 0.8550, Top-5 Acc= 0.9640\n",
      "Iter 100, Loss= 0.6267, Acc= 0.8780, Top-5 Acc= 0.9670\n",
      "Iter 125, Loss= 0.6607, Acc= 0.8670, Top-5 Acc= 0.9570\n",
      "Iter 150, Loss= 0.6929, Acc= 0.8520, Top-5 Acc= 0.9600\n",
      "Iter 175, Loss= 0.7036, Acc= 0.8600, Top-5 Acc= 0.9610\n",
      "Iter 200, Loss= 0.6106, Acc= 0.8720, Top-5 Acc= 0.9680\n",
      "Iter 225, Loss= 0.7130, Acc= 0.8480, Top-5 Acc= 0.9610\n",
      "Iter 250, Loss= 0.7390, Acc= 0.8600, Top-5 Acc= 0.9530\n",
      "Iter 275, Loss= 0.6203, Acc= 0.8660, Top-5 Acc= 0.9700\n",
      "Iter 300, Loss= 0.7204, Acc= 0.8590, Top-5 Acc= 0.9520\n",
      "Iter 325, Loss= 0.6728, Acc= 0.8720, Top-5 Acc= 0.9650\n",
      "Iter 350, Loss= 0.7881, Acc= 0.8470, Top-5 Acc= 0.9590\n",
      "Iter 375, Loss= 0.6272, Acc= 0.8770, Top-5 Acc= 0.9710\n",
      "Iter 400, Loss= 0.6780, Acc= 0.8680, Top-5 Acc= 0.9650\n",
      "Iter 425, Loss= 0.7915, Acc= 0.8450, Top-5 Acc= 0.9640\n",
      "Iter 450, Loss= 0.8079, Acc= 0.8490, Top-5 Acc= 0.9670\n",
      "Iter 475, Loss= 0.7443, Acc= 0.8570, Top-5 Acc= 0.9600\n",
      "Iter 500, Loss= 0.6533, Acc= 0.8650, Top-5 Acc= 0.9520\n",
      "Iter 525, Loss= 0.7722, Acc= 0.8430, Top-5 Acc= 0.9530\n",
      "Iter 550, Loss= 0.7522, Acc= 0.8530, Top-5 Acc= 0.9540\n",
      "Iter 575, Loss= 0.7844, Acc= 0.8410, Top-5 Acc= 0.9500\n",
      "Iter 600, Loss= 0.7337, Acc= 0.8550, Top-5 Acc= 0.9580\n",
      "Iter 625, Loss= 0.8447, Acc= 0.8340, Top-5 Acc= 0.9480\n",
      "Iter 650, Loss= 0.6317, Acc= 0.8680, Top-5 Acc= 0.9560\n",
      "Iter 675, Loss= 0.7000, Acc= 0.8630, Top-5 Acc= 0.9550\n",
      "Iter 700, Loss= 0.7628, Acc= 0.8530, Top-5 Acc= 0.9610\n",
      "Iter 725, Loss= 0.7300, Acc= 0.8470, Top-5 Acc= 0.9620\n",
      "Iter 750, Loss= 0.7504, Acc= 0.8600, Top-5 Acc= 0.9610\n",
      "Iter 775, Loss= 0.7309, Acc= 0.8610, Top-5 Acc= 0.9570\n",
      "Iter 800, Loss= 0.6042, Acc= 0.8720, Top-5 Acc= 0.9650\n",
      "Iter 825, Loss= 0.6719, Acc= 0.8750, Top-5 Acc= 0.9630\n",
      "Iter 850, Loss= 0.6211, Acc= 0.8810, Top-5 Acc= 0.9660\n",
      "Iter 875, Loss= 0.8367, Acc= 0.8440, Top-5 Acc= 0.9520\n",
      "Iter 900, Loss= 0.7312, Acc= 0.8540, Top-5 Acc= 0.9560\n",
      "Iter 925, Loss= 0.7509, Acc= 0.8480, Top-5 Acc= 0.9590\n",
      "Iter 950, Loss= 0.6808, Acc= 0.8680, Top-5 Acc= 0.9680\n",
      "Iter 975, Loss= 0.6842, Acc= 0.8670, Top-5 Acc= 0.9630\n",
      "Iter 1000, Loss= 0.7723, Acc= 0.8470, Top-5 Acc= 0.9510\n",
      "====================================\n",
      "Epoch 9: Loss=0.72062420845 Acc=0.858999729156 Top-5 Acc=0.958599746227\n",
      "====================================\n",
      "==== EPOCH 10 ====\n",
      "Iter 25, Loss= 0.7866, Acc= 0.8490, Top-5 Acc= 0.9530\n",
      "Iter 50, Loss= 0.8612, Acc= 0.8470, Top-5 Acc= 0.9420\n",
      "Iter 75, Loss= 0.7183, Acc= 0.8590, Top-5 Acc= 0.9580\n",
      "Iter 100, Loss= 0.6819, Acc= 0.8700, Top-5 Acc= 0.9590\n",
      "Iter 125, Loss= 0.7635, Acc= 0.8490, Top-5 Acc= 0.9590\n",
      "Iter 150, Loss= 0.7620, Acc= 0.8440, Top-5 Acc= 0.9610\n",
      "Iter 175, Loss= 0.7083, Acc= 0.8570, Top-5 Acc= 0.9580\n",
      "Iter 200, Loss= 0.7969, Acc= 0.8420, Top-5 Acc= 0.9590\n",
      "Iter 225, Loss= 0.6671, Acc= 0.8600, Top-5 Acc= 0.9630\n",
      "Iter 250, Loss= 0.7907, Acc= 0.8370, Top-5 Acc= 0.9540\n",
      "Iter 275, Loss= 0.6992, Acc= 0.8650, Top-5 Acc= 0.9580\n",
      "Iter 300, Loss= 0.9109, Acc= 0.8230, Top-5 Acc= 0.9510\n",
      "Iter 325, Loss= 0.7160, Acc= 0.8600, Top-5 Acc= 0.9590\n",
      "Iter 350, Loss= 0.6529, Acc= 0.8690, Top-5 Acc= 0.9650\n",
      "Iter 375, Loss= 0.6974, Acc= 0.8650, Top-5 Acc= 0.9570\n",
      "Iter 400, Loss= 0.7690, Acc= 0.8470, Top-5 Acc= 0.9520\n",
      "Iter 425, Loss= 0.6785, Acc= 0.8610, Top-5 Acc= 0.9620\n",
      "Iter 450, Loss= 0.7388, Acc= 0.8530, Top-5 Acc= 0.9570\n",
      "Iter 475, Loss= 0.7081, Acc= 0.8630, Top-5 Acc= 0.9510\n",
      "Iter 500, Loss= 0.6291, Acc= 0.8690, Top-5 Acc= 0.9700\n",
      "Iter 525, Loss= 0.7342, Acc= 0.8530, Top-5 Acc= 0.9630\n",
      "Iter 550, Loss= 0.6334, Acc= 0.8770, Top-5 Acc= 0.9590\n",
      "Iter 575, Loss= 0.6216, Acc= 0.8710, Top-5 Acc= 0.9680\n",
      "Iter 600, Loss= 0.7416, Acc= 0.8560, Top-5 Acc= 0.9520\n",
      "Iter 625, Loss= 0.7645, Acc= 0.8620, Top-5 Acc= 0.9600\n",
      "Iter 650, Loss= 0.7489, Acc= 0.8590, Top-5 Acc= 0.9570\n",
      "Iter 675, Loss= 0.8155, Acc= 0.8510, Top-5 Acc= 0.9610\n",
      "Iter 700, Loss= 0.7342, Acc= 0.8600, Top-5 Acc= 0.9610\n",
      "Iter 725, Loss= 0.7539, Acc= 0.8590, Top-5 Acc= 0.9560\n",
      "Iter 750, Loss= 0.7024, Acc= 0.8690, Top-5 Acc= 0.9600\n",
      "Iter 775, Loss= 0.7555, Acc= 0.8550, Top-5 Acc= 0.9570\n",
      "Iter 800, Loss= 0.6822, Acc= 0.8630, Top-5 Acc= 0.9640\n",
      "Iter 825, Loss= 0.6781, Acc= 0.8700, Top-5 Acc= 0.9570\n",
      "Iter 850, Loss= 0.7457, Acc= 0.8690, Top-5 Acc= 0.9540\n",
      "Iter 875, Loss= 0.7763, Acc= 0.8490, Top-5 Acc= 0.9580\n",
      "Iter 900, Loss= 0.7212, Acc= 0.8550, Top-5 Acc= 0.9630\n",
      "Iter 925, Loss= 0.7034, Acc= 0.8630, Top-5 Acc= 0.9570\n",
      "Iter 950, Loss= 0.7723, Acc= 0.8500, Top-5 Acc= 0.9580\n",
      "Iter 975, Loss= 0.8765, Acc= 0.8250, Top-5 Acc= 0.9460\n",
      "Iter 1000, Loss= 0.7641, Acc= 0.8570, Top-5 Acc= 0.9460\n",
      "====================================\n",
      "Epoch 10: Loss=0.72620344162 Acc=0.858999788761 Top-5 Acc=0.958599686623\n",
      "====================================\n",
      "==== EPOCH 11 ====\n",
      "Iter 25, Loss= 0.7160, Acc= 0.8650, Top-5 Acc= 0.9580\n",
      "Iter 50, Loss= 0.8645, Acc= 0.8400, Top-5 Acc= 0.9560\n",
      "Iter 75, Loss= 0.7565, Acc= 0.8530, Top-5 Acc= 0.9630\n",
      "Iter 100, Loss= 0.6768, Acc= 0.8700, Top-5 Acc= 0.9610\n",
      "Iter 125, Loss= 0.7962, Acc= 0.8420, Top-5 Acc= 0.9560\n",
      "Iter 150, Loss= 0.6761, Acc= 0.8640, Top-5 Acc= 0.9660\n",
      "Iter 175, Loss= 0.6279, Acc= 0.8770, Top-5 Acc= 0.9700\n",
      "Iter 200, Loss= 0.8077, Acc= 0.8470, Top-5 Acc= 0.9600\n",
      "Iter 225, Loss= 0.6939, Acc= 0.8650, Top-5 Acc= 0.9570\n",
      "Iter 250, Loss= 0.7227, Acc= 0.8630, Top-5 Acc= 0.9600\n",
      "Iter 275, Loss= 0.8386, Acc= 0.8440, Top-5 Acc= 0.9510\n",
      "Iter 300, Loss= 0.8684, Acc= 0.8300, Top-5 Acc= 0.9510\n",
      "Iter 325, Loss= 0.6256, Acc= 0.8770, Top-5 Acc= 0.9680\n",
      "Iter 350, Loss= 0.7727, Acc= 0.8480, Top-5 Acc= 0.9530\n",
      "Iter 375, Loss= 0.7669, Acc= 0.8520, Top-5 Acc= 0.9540\n",
      "Iter 400, Loss= 0.7423, Acc= 0.8590, Top-5 Acc= 0.9600\n",
      "Iter 425, Loss= 0.6805, Acc= 0.8610, Top-5 Acc= 0.9610\n",
      "Iter 450, Loss= 0.7448, Acc= 0.8580, Top-5 Acc= 0.9610\n",
      "Iter 475, Loss= 0.7259, Acc= 0.8590, Top-5 Acc= 0.9630\n",
      "Iter 500, Loss= 0.7510, Acc= 0.8530, Top-5 Acc= 0.9550\n",
      "Iter 525, Loss= 0.7942, Acc= 0.8560, Top-5 Acc= 0.9610\n",
      "Iter 550, Loss= 0.7122, Acc= 0.8610, Top-5 Acc= 0.9600\n",
      "Iter 575, Loss= 0.7205, Acc= 0.8640, Top-5 Acc= 0.9640\n",
      "Iter 600, Loss= 0.7473, Acc= 0.8630, Top-5 Acc= 0.9580\n",
      "Iter 625, Loss= 0.6836, Acc= 0.8690, Top-5 Acc= 0.9610\n",
      "Iter 650, Loss= 0.7524, Acc= 0.8580, Top-5 Acc= 0.9520\n",
      "Iter 675, Loss= 0.7569, Acc= 0.8530, Top-5 Acc= 0.9530\n",
      "Iter 700, Loss= 0.7186, Acc= 0.8600, Top-5 Acc= 0.9620\n",
      "Iter 725, Loss= 0.7537, Acc= 0.8520, Top-5 Acc= 0.9590\n",
      "Iter 750, Loss= 0.7547, Acc= 0.8600, Top-5 Acc= 0.9560\n",
      "Iter 775, Loss= 0.7900, Acc= 0.8530, Top-5 Acc= 0.9530\n",
      "Iter 800, Loss= 0.7287, Acc= 0.8560, Top-5 Acc= 0.9610\n",
      "Iter 825, Loss= 0.7870, Acc= 0.8570, Top-5 Acc= 0.9530\n",
      "Iter 850, Loss= 0.6726, Acc= 0.8710, Top-5 Acc= 0.9580\n",
      "Iter 875, Loss= 0.6822, Acc= 0.8740, Top-5 Acc= 0.9590\n",
      "Iter 900, Loss= 0.6897, Acc= 0.8640, Top-5 Acc= 0.9640\n",
      "Iter 925, Loss= 0.7075, Acc= 0.8570, Top-5 Acc= 0.9580\n",
      "Iter 950, Loss= 0.8275, Acc= 0.8430, Top-5 Acc= 0.9610\n",
      "Iter 975, Loss= 0.6666, Acc= 0.8740, Top-5 Acc= 0.9620\n",
      "Iter 1000, Loss= 0.7508, Acc= 0.8540, Top-5 Acc= 0.9630\n",
      "====================================\n",
      "Epoch 11: Loss=0.730178833008 Acc=0.85859978199 Top-5 Acc=0.959799706936\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 12 ====\n",
      "Iter 25, Loss= 0.8579, Acc= 0.8420, Top-5 Acc= 0.9480\n",
      "Iter 50, Loss= 0.7491, Acc= 0.8500, Top-5 Acc= 0.9520\n",
      "Iter 75, Loss= 0.7278, Acc= 0.8680, Top-5 Acc= 0.9610\n",
      "Iter 100, Loss= 0.8251, Acc= 0.8370, Top-5 Acc= 0.9570\n",
      "Iter 125, Loss= 0.7981, Acc= 0.8510, Top-5 Acc= 0.9570\n",
      "Iter 150, Loss= 0.7861, Acc= 0.8500, Top-5 Acc= 0.9540\n",
      "Iter 175, Loss= 0.6901, Acc= 0.8620, Top-5 Acc= 0.9540\n",
      "Iter 200, Loss= 0.7497, Acc= 0.8450, Top-5 Acc= 0.9610\n",
      "Iter 225, Loss= 0.7537, Acc= 0.8600, Top-5 Acc= 0.9640\n",
      "Iter 250, Loss= 0.7411, Acc= 0.8540, Top-5 Acc= 0.9590\n",
      "Iter 275, Loss= 0.7275, Acc= 0.8540, Top-5 Acc= 0.9490\n",
      "Iter 300, Loss= 0.7485, Acc= 0.8630, Top-5 Acc= 0.9590\n",
      "Iter 325, Loss= 0.8207, Acc= 0.8500, Top-5 Acc= 0.9600\n",
      "Iter 350, Loss= 0.7358, Acc= 0.8610, Top-5 Acc= 0.9600\n",
      "Iter 375, Loss= 0.6807, Acc= 0.8650, Top-5 Acc= 0.9620\n",
      "Iter 400, Loss= 0.7911, Acc= 0.8530, Top-5 Acc= 0.9600\n",
      "Iter 425, Loss= 0.7349, Acc= 0.8500, Top-5 Acc= 0.9580\n",
      "Iter 450, Loss= 0.6975, Acc= 0.8650, Top-5 Acc= 0.9510\n",
      "Iter 475, Loss= 0.7114, Acc= 0.8580, Top-5 Acc= 0.9640\n",
      "Iter 500, Loss= 0.9103, Acc= 0.8370, Top-5 Acc= 0.9470\n",
      "Iter 525, Loss= 0.7693, Acc= 0.8540, Top-5 Acc= 0.9590\n",
      "Iter 550, Loss= 0.7345, Acc= 0.8610, Top-5 Acc= 0.9630\n",
      "Iter 575, Loss= 0.6516, Acc= 0.8660, Top-5 Acc= 0.9660\n",
      "Iter 600, Loss= 0.7148, Acc= 0.8560, Top-5 Acc= 0.9600\n",
      "Iter 625, Loss= 0.7421, Acc= 0.8580, Top-5 Acc= 0.9600\n",
      "Iter 650, Loss= 0.7018, Acc= 0.8540, Top-5 Acc= 0.9610\n",
      "Iter 675, Loss= 0.7168, Acc= 0.8630, Top-5 Acc= 0.9650\n",
      "Iter 700, Loss= 0.7193, Acc= 0.8650, Top-5 Acc= 0.9690\n",
      "Iter 725, Loss= 0.7347, Acc= 0.8590, Top-5 Acc= 0.9570\n",
      "Iter 750, Loss= 0.6474, Acc= 0.8630, Top-5 Acc= 0.9630\n",
      "Iter 775, Loss= 0.7680, Acc= 0.8440, Top-5 Acc= 0.9610\n",
      "Iter 800, Loss= 0.7252, Acc= 0.8610, Top-5 Acc= 0.9540\n",
      "Iter 825, Loss= 0.7091, Acc= 0.8630, Top-5 Acc= 0.9540\n",
      "Iter 850, Loss= 0.7830, Acc= 0.8650, Top-5 Acc= 0.9530\n",
      "Iter 875, Loss= 0.7871, Acc= 0.8590, Top-5 Acc= 0.9620\n",
      "Iter 900, Loss= 0.8163, Acc= 0.8510, Top-5 Acc= 0.9500\n",
      "Iter 925, Loss= 0.7356, Acc= 0.8670, Top-5 Acc= 0.9610\n",
      "Iter 950, Loss= 0.7068, Acc= 0.8760, Top-5 Acc= 0.9690\n",
      "Iter 975, Loss= 0.7415, Acc= 0.8590, Top-5 Acc= 0.9550\n",
      "Iter 1000, Loss= 0.7182, Acc= 0.8620, Top-5 Acc= 0.9530\n",
      "====================================\n",
      "Epoch 12: Loss=0.735842347145 Acc=0.859999835491 Top-5 Acc=0.958599746227\n",
      "====================================\n",
      "==== EPOCH 13 ====\n",
      "Iter 25, Loss= 0.6875, Acc= 0.8760, Top-5 Acc= 0.9550\n",
      "Iter 50, Loss= 0.7241, Acc= 0.8610, Top-5 Acc= 0.9600\n",
      "Iter 75, Loss= 0.7204, Acc= 0.8610, Top-5 Acc= 0.9580\n",
      "Iter 100, Loss= 0.7535, Acc= 0.8560, Top-5 Acc= 0.9590\n",
      "Iter 125, Loss= 0.7770, Acc= 0.8450, Top-5 Acc= 0.9610\n",
      "Iter 150, Loss= 0.7319, Acc= 0.8640, Top-5 Acc= 0.9630\n",
      "Iter 175, Loss= 0.7806, Acc= 0.8540, Top-5 Acc= 0.9590\n",
      "Iter 200, Loss= 0.8214, Acc= 0.8430, Top-5 Acc= 0.9650\n",
      "Iter 225, Loss= 0.5867, Acc= 0.8790, Top-5 Acc= 0.9660\n",
      "Iter 250, Loss= 0.6761, Acc= 0.8700, Top-5 Acc= 0.9650\n",
      "Iter 275, Loss= 0.6849, Acc= 0.8730, Top-5 Acc= 0.9650\n",
      "Iter 300, Loss= 0.8980, Acc= 0.8360, Top-5 Acc= 0.9480\n",
      "Iter 325, Loss= 0.7853, Acc= 0.8520, Top-5 Acc= 0.9610\n",
      "Iter 350, Loss= 0.7000, Acc= 0.8730, Top-5 Acc= 0.9640\n",
      "Iter 375, Loss= 0.6467, Acc= 0.8790, Top-5 Acc= 0.9650\n",
      "Iter 400, Loss= 0.8178, Acc= 0.8460, Top-5 Acc= 0.9410\n",
      "Iter 425, Loss= 0.6566, Acc= 0.8760, Top-5 Acc= 0.9630\n",
      "Iter 450, Loss= 0.8443, Acc= 0.8420, Top-5 Acc= 0.9520\n",
      "Iter 475, Loss= 0.7182, Acc= 0.8540, Top-5 Acc= 0.9680\n",
      "Iter 500, Loss= 0.7263, Acc= 0.8590, Top-5 Acc= 0.9590\n",
      "Iter 525, Loss= 0.7033, Acc= 0.8610, Top-5 Acc= 0.9570\n",
      "Iter 550, Loss= 0.7562, Acc= 0.8660, Top-5 Acc= 0.9580\n",
      "Iter 575, Loss= 0.6696, Acc= 0.8730, Top-5 Acc= 0.9560\n",
      "Iter 600, Loss= 0.7090, Acc= 0.8720, Top-5 Acc= 0.9610\n",
      "Iter 625, Loss= 0.8098, Acc= 0.8530, Top-5 Acc= 0.9520\n",
      "Iter 650, Loss= 0.7395, Acc= 0.8500, Top-5 Acc= 0.9580\n",
      "Iter 675, Loss= 0.7833, Acc= 0.8480, Top-5 Acc= 0.9570\n",
      "Iter 700, Loss= 0.6660, Acc= 0.8660, Top-5 Acc= 0.9620\n",
      "Iter 725, Loss= 0.8233, Acc= 0.8550, Top-5 Acc= 0.9560\n",
      "Iter 750, Loss= 0.7504, Acc= 0.8590, Top-5 Acc= 0.9610\n",
      "Iter 775, Loss= 0.6800, Acc= 0.8660, Top-5 Acc= 0.9630\n",
      "Iter 800, Loss= 0.6757, Acc= 0.8570, Top-5 Acc= 0.9650\n",
      "Iter 825, Loss= 0.8226, Acc= 0.8430, Top-5 Acc= 0.9560\n",
      "Iter 850, Loss= 0.7929, Acc= 0.8540, Top-5 Acc= 0.9530\n",
      "Iter 875, Loss= 0.6979, Acc= 0.8620, Top-5 Acc= 0.9680\n",
      "Iter 900, Loss= 0.8209, Acc= 0.8480, Top-5 Acc= 0.9550\n",
      "Iter 925, Loss= 0.6569, Acc= 0.8690, Top-5 Acc= 0.9630\n",
      "Iter 950, Loss= 0.7439, Acc= 0.8570, Top-5 Acc= 0.9670\n",
      "Iter 975, Loss= 0.6441, Acc= 0.8730, Top-5 Acc= 0.9610\n",
      "Iter 1000, Loss= 0.7156, Acc= 0.8680, Top-5 Acc= 0.9600\n",
      "====================================\n",
      "Epoch 13: Loss=0.739487946033 Acc=0.859799742699 Top-5 Acc=0.958999693394\n",
      "====================================\n",
      "==== EPOCH 14 ====\n",
      "Iter 25, Loss= 0.7340, Acc= 0.8600, Top-5 Acc= 0.9550\n",
      "Iter 50, Loss= 0.7522, Acc= 0.8560, Top-5 Acc= 0.9600\n",
      "Iter 75, Loss= 0.8977, Acc= 0.8350, Top-5 Acc= 0.9460\n",
      "Iter 100, Loss= 0.6015, Acc= 0.8790, Top-5 Acc= 0.9710\n",
      "Iter 125, Loss= 0.7119, Acc= 0.8670, Top-5 Acc= 0.9690\n",
      "Iter 150, Loss= 0.7698, Acc= 0.8560, Top-5 Acc= 0.9560\n",
      "Iter 175, Loss= 0.7405, Acc= 0.8590, Top-5 Acc= 0.9650\n",
      "Iter 200, Loss= 0.6608, Acc= 0.8730, Top-5 Acc= 0.9640\n",
      "Iter 225, Loss= 0.6549, Acc= 0.8780, Top-5 Acc= 0.9640\n",
      "Iter 250, Loss= 0.7545, Acc= 0.8460, Top-5 Acc= 0.9570\n",
      "Iter 275, Loss= 0.7008, Acc= 0.8720, Top-5 Acc= 0.9630\n",
      "Iter 300, Loss= 0.6777, Acc= 0.8680, Top-5 Acc= 0.9570\n",
      "Iter 325, Loss= 0.7331, Acc= 0.8640, Top-5 Acc= 0.9550\n",
      "Iter 350, Loss= 0.6555, Acc= 0.8720, Top-5 Acc= 0.9680\n",
      "Iter 375, Loss= 0.7612, Acc= 0.8560, Top-5 Acc= 0.9630\n",
      "Iter 400, Loss= 0.7026, Acc= 0.8590, Top-5 Acc= 0.9620\n",
      "Iter 425, Loss= 0.6374, Acc= 0.8710, Top-5 Acc= 0.9670\n",
      "Iter 450, Loss= 0.7180, Acc= 0.8630, Top-5 Acc= 0.9550\n",
      "Iter 475, Loss= 0.7791, Acc= 0.8550, Top-5 Acc= 0.9600\n",
      "Iter 500, Loss= 0.7226, Acc= 0.8620, Top-5 Acc= 0.9570\n",
      "Iter 525, Loss= 0.9096, Acc= 0.8300, Top-5 Acc= 0.9400\n",
      "Iter 550, Loss= 0.7553, Acc= 0.8590, Top-5 Acc= 0.9570\n",
      "Iter 575, Loss= 0.7866, Acc= 0.8650, Top-5 Acc= 0.9570\n",
      "Iter 600, Loss= 0.6720, Acc= 0.8730, Top-5 Acc= 0.9600\n",
      "Iter 625, Loss= 0.7208, Acc= 0.8710, Top-5 Acc= 0.9630\n",
      "Iter 650, Loss= 0.7781, Acc= 0.8440, Top-5 Acc= 0.9580\n",
      "Iter 675, Loss= 0.7367, Acc= 0.8450, Top-5 Acc= 0.9490\n",
      "Iter 700, Loss= 0.7314, Acc= 0.8550, Top-5 Acc= 0.9560\n",
      "Iter 725, Loss= 0.6257, Acc= 0.8770, Top-5 Acc= 0.9660\n",
      "Iter 750, Loss= 0.7726, Acc= 0.8420, Top-5 Acc= 0.9650\n",
      "Iter 775, Loss= 0.6907, Acc= 0.8700, Top-5 Acc= 0.9610\n",
      "Iter 800, Loss= 0.7641, Acc= 0.8560, Top-5 Acc= 0.9530\n",
      "Iter 825, Loss= 0.7741, Acc= 0.8550, Top-5 Acc= 0.9580\n",
      "Iter 850, Loss= 0.7295, Acc= 0.8600, Top-5 Acc= 0.9610\n",
      "Iter 875, Loss= 0.7081, Acc= 0.8730, Top-5 Acc= 0.9570\n",
      "Iter 900, Loss= 0.7623, Acc= 0.8520, Top-5 Acc= 0.9600\n",
      "Iter 925, Loss= 0.7984, Acc= 0.8570, Top-5 Acc= 0.9560\n",
      "Iter 950, Loss= 0.8794, Acc= 0.8460, Top-5 Acc= 0.9480\n",
      "Iter 975, Loss= 0.7634, Acc= 0.8510, Top-5 Acc= 0.9510\n",
      "Iter 1000, Loss= 0.7437, Acc= 0.8590, Top-5 Acc= 0.9670\n",
      "====================================\n",
      "Epoch 14: Loss=0.743996977806 Acc=0.859599769115 Top-5 Acc=0.958999693394\n",
      "====================================\n",
      "==== EPOCH 15 ====\n",
      "Iter 25, Loss= 0.7889, Acc= 0.8520, Top-5 Acc= 0.9580\n",
      "Iter 50, Loss= 0.7836, Acc= 0.8510, Top-5 Acc= 0.9500\n",
      "Iter 75, Loss= 0.7047, Acc= 0.8680, Top-5 Acc= 0.9640\n",
      "Iter 100, Loss= 0.6974, Acc= 0.8570, Top-5 Acc= 0.9590\n",
      "Iter 125, Loss= 0.6395, Acc= 0.8820, Top-5 Acc= 0.9690\n",
      "Iter 150, Loss= 0.6840, Acc= 0.8690, Top-5 Acc= 0.9610\n",
      "Iter 175, Loss= 0.6440, Acc= 0.8640, Top-5 Acc= 0.9680\n",
      "Iter 200, Loss= 0.7734, Acc= 0.8490, Top-5 Acc= 0.9550\n",
      "Iter 225, Loss= 0.6771, Acc= 0.8630, Top-5 Acc= 0.9670\n",
      "Iter 250, Loss= 0.7657, Acc= 0.8600, Top-5 Acc= 0.9610\n",
      "Iter 275, Loss= 0.6763, Acc= 0.8660, Top-5 Acc= 0.9700\n",
      "Iter 300, Loss= 0.8393, Acc= 0.8480, Top-5 Acc= 0.9510\n",
      "Iter 325, Loss= 0.7176, Acc= 0.8710, Top-5 Acc= 0.9590\n",
      "Iter 350, Loss= 0.7394, Acc= 0.8630, Top-5 Acc= 0.9610\n",
      "Iter 375, Loss= 0.8787, Acc= 0.8350, Top-5 Acc= 0.9470\n",
      "Iter 400, Loss= 0.7643, Acc= 0.8550, Top-5 Acc= 0.9660\n",
      "Iter 425, Loss= 0.7388, Acc= 0.8500, Top-5 Acc= 0.9500\n",
      "Iter 450, Loss= 0.7575, Acc= 0.8600, Top-5 Acc= 0.9570\n",
      "Iter 475, Loss= 0.7640, Acc= 0.8680, Top-5 Acc= 0.9620\n",
      "Iter 500, Loss= 0.7084, Acc= 0.8630, Top-5 Acc= 0.9660\n",
      "Iter 525, Loss= 0.7237, Acc= 0.8540, Top-5 Acc= 0.9650\n",
      "Iter 550, Loss= 0.7464, Acc= 0.8620, Top-5 Acc= 0.9610\n",
      "Iter 575, Loss= 0.7038, Acc= 0.8670, Top-5 Acc= 0.9560\n",
      "Iter 600, Loss= 0.7472, Acc= 0.8640, Top-5 Acc= 0.9610\n",
      "Iter 625, Loss= 0.8206, Acc= 0.8570, Top-5 Acc= 0.9560\n",
      "Iter 650, Loss= 0.7287, Acc= 0.8720, Top-5 Acc= 0.9570\n",
      "Iter 675, Loss= 0.7494, Acc= 0.8620, Top-5 Acc= 0.9590\n",
      "Iter 700, Loss= 0.7564, Acc= 0.8570, Top-5 Acc= 0.9610\n",
      "Iter 725, Loss= 0.7245, Acc= 0.8640, Top-5 Acc= 0.9710\n",
      "Iter 750, Loss= 0.6793, Acc= 0.8650, Top-5 Acc= 0.9660\n",
      "Iter 775, Loss= 0.7179, Acc= 0.8700, Top-5 Acc= 0.9580\n",
      "Iter 800, Loss= 0.7111, Acc= 0.8610, Top-5 Acc= 0.9590\n",
      "Iter 825, Loss= 0.7766, Acc= 0.8660, Top-5 Acc= 0.9530\n",
      "Iter 850, Loss= 0.6862, Acc= 0.8670, Top-5 Acc= 0.9590\n",
      "Iter 875, Loss= 0.8022, Acc= 0.8510, Top-5 Acc= 0.9570\n",
      "Iter 900, Loss= 0.7900, Acc= 0.8590, Top-5 Acc= 0.9560\n",
      "Iter 925, Loss= 0.7403, Acc= 0.8560, Top-5 Acc= 0.9560\n",
      "Iter 950, Loss= 0.7566, Acc= 0.8560, Top-5 Acc= 0.9560\n",
      "Iter 975, Loss= 0.7231, Acc= 0.8610, Top-5 Acc= 0.9610\n",
      "Iter 1000, Loss= 0.7491, Acc= 0.8580, Top-5 Acc= 0.9610\n",
      "====================================\n",
      "Epoch 15: Loss=0.748341441154 Acc=0.859399855137 Top-5 Acc=0.95879971981\n",
      "====================================\n",
      "==== EPOCH 16 ====\n",
      "Iter 25, Loss= 0.6397, Acc= 0.8700, Top-5 Acc= 0.9680\n",
      "Iter 50, Loss= 0.8174, Acc= 0.8440, Top-5 Acc= 0.9490\n",
      "Iter 75, Loss= 0.7130, Acc= 0.8630, Top-5 Acc= 0.9640\n",
      "Iter 100, Loss= 0.7156, Acc= 0.8660, Top-5 Acc= 0.9600\n",
      "Iter 125, Loss= 0.7587, Acc= 0.8570, Top-5 Acc= 0.9650\n",
      "Iter 150, Loss= 0.7752, Acc= 0.8550, Top-5 Acc= 0.9620\n",
      "Iter 175, Loss= 0.7045, Acc= 0.8750, Top-5 Acc= 0.9620\n",
      "Iter 200, Loss= 0.7895, Acc= 0.8630, Top-5 Acc= 0.9540\n",
      "Iter 225, Loss= 0.8130, Acc= 0.8480, Top-5 Acc= 0.9500\n",
      "Iter 250, Loss= 0.6722, Acc= 0.8680, Top-5 Acc= 0.9660\n",
      "Iter 275, Loss= 0.7028, Acc= 0.8580, Top-5 Acc= 0.9670\n",
      "Iter 300, Loss= 0.7574, Acc= 0.8610, Top-5 Acc= 0.9610\n",
      "Iter 325, Loss= 0.7503, Acc= 0.8610, Top-5 Acc= 0.9570\n",
      "Iter 350, Loss= 0.7089, Acc= 0.8630, Top-5 Acc= 0.9570\n",
      "Iter 375, Loss= 0.7435, Acc= 0.8620, Top-5 Acc= 0.9560\n",
      "Iter 400, Loss= 0.7221, Acc= 0.8560, Top-5 Acc= 0.9560\n",
      "Iter 425, Loss= 0.7445, Acc= 0.8540, Top-5 Acc= 0.9620\n",
      "Iter 450, Loss= 0.6500, Acc= 0.8650, Top-5 Acc= 0.9640\n",
      "Iter 475, Loss= 0.7642, Acc= 0.8620, Top-5 Acc= 0.9590\n",
      "Iter 500, Loss= 0.7477, Acc= 0.8680, Top-5 Acc= 0.9610\n",
      "Iter 525, Loss= 0.7648, Acc= 0.8540, Top-5 Acc= 0.9590\n",
      "Iter 550, Loss= 0.7025, Acc= 0.8710, Top-5 Acc= 0.9650\n",
      "Iter 575, Loss= 0.7427, Acc= 0.8680, Top-5 Acc= 0.9610\n",
      "Iter 600, Loss= 0.6527, Acc= 0.8790, Top-5 Acc= 0.9600\n",
      "Iter 625, Loss= 0.7782, Acc= 0.8500, Top-5 Acc= 0.9600\n",
      "Iter 650, Loss= 0.7344, Acc= 0.8570, Top-5 Acc= 0.9700\n",
      "Iter 675, Loss= 0.7060, Acc= 0.8600, Top-5 Acc= 0.9680\n",
      "Iter 700, Loss= 0.7800, Acc= 0.8610, Top-5 Acc= 0.9520\n",
      "Iter 725, Loss= 0.8497, Acc= 0.8540, Top-5 Acc= 0.9520\n",
      "Iter 750, Loss= 0.7248, Acc= 0.8600, Top-5 Acc= 0.9630\n",
      "Iter 775, Loss= 0.6959, Acc= 0.8690, Top-5 Acc= 0.9620\n",
      "Iter 800, Loss= 0.7615, Acc= 0.8550, Top-5 Acc= 0.9600\n",
      "Iter 825, Loss= 0.7229, Acc= 0.8660, Top-5 Acc= 0.9590\n",
      "Iter 850, Loss= 0.8181, Acc= 0.8560, Top-5 Acc= 0.9560\n",
      "Iter 875, Loss= 0.7509, Acc= 0.8670, Top-5 Acc= 0.9560\n",
      "Iter 900, Loss= 0.6637, Acc= 0.8710, Top-5 Acc= 0.9660\n",
      "Iter 925, Loss= 0.7265, Acc= 0.8580, Top-5 Acc= 0.9640\n",
      "Iter 950, Loss= 0.7615, Acc= 0.8530, Top-5 Acc= 0.9520\n",
      "Iter 975, Loss= 0.7941, Acc= 0.8470, Top-5 Acc= 0.9620\n",
      "Iter 1000, Loss= 0.7567, Acc= 0.8600, Top-5 Acc= 0.9560\n",
      "====================================\n",
      "Epoch 16: Loss=0.751519262791 Acc=0.860199809074 Top-5 Acc=0.958999693394\n",
      "====================================\n",
      "==== EPOCH 17 ====\n",
      "Iter 25, Loss= 0.7763, Acc= 0.8610, Top-5 Acc= 0.9600\n",
      "Iter 50, Loss= 0.8400, Acc= 0.8570, Top-5 Acc= 0.9470\n",
      "Iter 75, Loss= 0.7390, Acc= 0.8600, Top-5 Acc= 0.9580\n",
      "Iter 100, Loss= 0.7713, Acc= 0.8500, Top-5 Acc= 0.9550\n",
      "Iter 125, Loss= 0.7182, Acc= 0.8620, Top-5 Acc= 0.9630\n",
      "Iter 150, Loss= 0.7814, Acc= 0.8510, Top-5 Acc= 0.9530\n",
      "Iter 175, Loss= 0.6756, Acc= 0.8720, Top-5 Acc= 0.9600\n",
      "Iter 200, Loss= 0.8073, Acc= 0.8520, Top-5 Acc= 0.9610\n",
      "Iter 225, Loss= 0.6740, Acc= 0.8780, Top-5 Acc= 0.9670\n",
      "Iter 250, Loss= 0.7895, Acc= 0.8630, Top-5 Acc= 0.9460\n",
      "Iter 275, Loss= 0.8772, Acc= 0.8430, Top-5 Acc= 0.9560\n",
      "Iter 300, Loss= 0.7683, Acc= 0.8410, Top-5 Acc= 0.9500\n",
      "Iter 325, Loss= 0.6039, Acc= 0.8750, Top-5 Acc= 0.9670\n",
      "Iter 350, Loss= 0.6759, Acc= 0.8690, Top-5 Acc= 0.9630\n",
      "Iter 375, Loss= 0.7388, Acc= 0.8540, Top-5 Acc= 0.9560\n",
      "Iter 400, Loss= 0.6753, Acc= 0.8660, Top-5 Acc= 0.9700\n",
      "Iter 425, Loss= 0.7041, Acc= 0.8630, Top-5 Acc= 0.9570\n",
      "Iter 450, Loss= 0.7140, Acc= 0.8650, Top-5 Acc= 0.9570\n",
      "Iter 475, Loss= 0.7075, Acc= 0.8600, Top-5 Acc= 0.9620\n",
      "Iter 500, Loss= 0.8458, Acc= 0.8460, Top-5 Acc= 0.9450\n",
      "Iter 525, Loss= 0.7575, Acc= 0.8520, Top-5 Acc= 0.9640\n",
      "Iter 550, Loss= 0.8248, Acc= 0.8350, Top-5 Acc= 0.9540\n",
      "Iter 575, Loss= 0.7610, Acc= 0.8610, Top-5 Acc= 0.9630\n",
      "Iter 600, Loss= 0.6955, Acc= 0.8590, Top-5 Acc= 0.9700\n",
      "Iter 625, Loss= 0.8178, Acc= 0.8580, Top-5 Acc= 0.9530\n",
      "Iter 650, Loss= 0.7688, Acc= 0.8500, Top-5 Acc= 0.9610\n",
      "Iter 675, Loss= 0.7402, Acc= 0.8540, Top-5 Acc= 0.9600\n",
      "Iter 700, Loss= 0.7646, Acc= 0.8600, Top-5 Acc= 0.9510\n",
      "Iter 725, Loss= 0.7289, Acc= 0.8560, Top-5 Acc= 0.9590\n",
      "Iter 750, Loss= 0.7640, Acc= 0.8630, Top-5 Acc= 0.9570\n",
      "Iter 775, Loss= 0.8791, Acc= 0.8550, Top-5 Acc= 0.9480\n",
      "Iter 800, Loss= 0.8279, Acc= 0.8500, Top-5 Acc= 0.9520\n",
      "Iter 825, Loss= 0.8186, Acc= 0.8560, Top-5 Acc= 0.9550\n",
      "Iter 850, Loss= 0.7701, Acc= 0.8560, Top-5 Acc= 0.9670\n",
      "Iter 875, Loss= 0.7316, Acc= 0.8690, Top-5 Acc= 0.9560\n",
      "Iter 900, Loss= 0.8579, Acc= 0.8460, Top-5 Acc= 0.9560\n",
      "Iter 925, Loss= 0.7178, Acc= 0.8590, Top-5 Acc= 0.9600\n",
      "Iter 950, Loss= 0.6656, Acc= 0.8690, Top-5 Acc= 0.9610\n",
      "Iter 975, Loss= 0.8409, Acc= 0.8530, Top-5 Acc= 0.9520\n",
      "Iter 1000, Loss= 0.8460, Acc= 0.8430, Top-5 Acc= 0.9550\n",
      "====================================\n",
      "Epoch 17: Loss=0.75484919548 Acc=0.859799742699 Top-5 Acc=0.958999752998\n",
      "====================================\n",
      "==== EPOCH 18 ====\n",
      "Iter 25, Loss= 0.8174, Acc= 0.8490, Top-5 Acc= 0.9520\n",
      "Iter 50, Loss= 0.7061, Acc= 0.8560, Top-5 Acc= 0.9600\n",
      "Iter 75, Loss= 0.7796, Acc= 0.8560, Top-5 Acc= 0.9570\n",
      "Iter 100, Loss= 0.7499, Acc= 0.8500, Top-5 Acc= 0.9610\n",
      "Iter 125, Loss= 0.7371, Acc= 0.8670, Top-5 Acc= 0.9600\n",
      "Iter 150, Loss= 0.6661, Acc= 0.8760, Top-5 Acc= 0.9580\n",
      "Iter 175, Loss= 0.8514, Acc= 0.8530, Top-5 Acc= 0.9480\n",
      "Iter 200, Loss= 0.8512, Acc= 0.8430, Top-5 Acc= 0.9500\n",
      "Iter 225, Loss= 0.7521, Acc= 0.8620, Top-5 Acc= 0.9590\n",
      "Iter 250, Loss= 0.7374, Acc= 0.8560, Top-5 Acc= 0.9550\n",
      "Iter 275, Loss= 0.7025, Acc= 0.8760, Top-5 Acc= 0.9620\n",
      "Iter 300, Loss= 0.7367, Acc= 0.8710, Top-5 Acc= 0.9550\n",
      "Iter 325, Loss= 0.8182, Acc= 0.8530, Top-5 Acc= 0.9490\n",
      "Iter 350, Loss= 0.6958, Acc= 0.8690, Top-5 Acc= 0.9640\n",
      "Iter 375, Loss= 0.7535, Acc= 0.8550, Top-5 Acc= 0.9600\n",
      "Iter 400, Loss= 0.7475, Acc= 0.8530, Top-5 Acc= 0.9660\n",
      "Iter 425, Loss= 0.6922, Acc= 0.8720, Top-5 Acc= 0.9680\n",
      "Iter 450, Loss= 0.7449, Acc= 0.8570, Top-5 Acc= 0.9580\n",
      "Iter 475, Loss= 0.7739, Acc= 0.8570, Top-5 Acc= 0.9460\n",
      "Iter 500, Loss= 0.7738, Acc= 0.8520, Top-5 Acc= 0.9530\n",
      "Iter 525, Loss= 0.9001, Acc= 0.8360, Top-5 Acc= 0.9570\n",
      "Iter 550, Loss= 0.9365, Acc= 0.8350, Top-5 Acc= 0.9470\n",
      "Iter 575, Loss= 0.7575, Acc= 0.8540, Top-5 Acc= 0.9670\n",
      "Iter 600, Loss= 0.7616, Acc= 0.8530, Top-5 Acc= 0.9620\n",
      "Iter 625, Loss= 0.7332, Acc= 0.8570, Top-5 Acc= 0.9570\n",
      "Iter 650, Loss= 0.7486, Acc= 0.8540, Top-5 Acc= 0.9630\n",
      "Iter 675, Loss= 0.7330, Acc= 0.8640, Top-5 Acc= 0.9660\n",
      "Iter 700, Loss= 0.8203, Acc= 0.8380, Top-5 Acc= 0.9640\n",
      "Iter 725, Loss= 0.6806, Acc= 0.8650, Top-5 Acc= 0.9610\n",
      "Iter 750, Loss= 0.7371, Acc= 0.8610, Top-5 Acc= 0.9670\n",
      "Iter 775, Loss= 0.7068, Acc= 0.8700, Top-5 Acc= 0.9620\n",
      "Iter 800, Loss= 0.7039, Acc= 0.8610, Top-5 Acc= 0.9570\n",
      "Iter 825, Loss= 0.6992, Acc= 0.8840, Top-5 Acc= 0.9750\n",
      "Iter 850, Loss= 0.7763, Acc= 0.8660, Top-5 Acc= 0.9570\n",
      "Iter 875, Loss= 0.7429, Acc= 0.8560, Top-5 Acc= 0.9530\n",
      "Iter 900, Loss= 0.7330, Acc= 0.8560, Top-5 Acc= 0.9600\n",
      "Iter 925, Loss= 0.7715, Acc= 0.8620, Top-5 Acc= 0.9510\n",
      "Iter 950, Loss= 0.7484, Acc= 0.8620, Top-5 Acc= 0.9560\n",
      "Iter 975, Loss= 0.7259, Acc= 0.8720, Top-5 Acc= 0.9700\n",
      "Iter 1000, Loss= 0.8013, Acc= 0.8570, Top-5 Acc= 0.9550\n",
      "====================================\n",
      "Epoch 18: Loss=0.758064687252 Acc=0.860399782658 Top-5 Acc=0.95879971981\n",
      "====================================\n",
      "==== EPOCH 19 ====\n",
      "Iter 25, Loss= 0.6950, Acc= 0.8660, Top-5 Acc= 0.9640\n",
      "Iter 50, Loss= 0.7303, Acc= 0.8640, Top-5 Acc= 0.9640\n",
      "Iter 75, Loss= 0.6977, Acc= 0.8750, Top-5 Acc= 0.9670\n",
      "Iter 100, Loss= 0.7861, Acc= 0.8620, Top-5 Acc= 0.9570\n",
      "Iter 125, Loss= 0.7943, Acc= 0.8510, Top-5 Acc= 0.9580\n",
      "Iter 150, Loss= 0.8019, Acc= 0.8530, Top-5 Acc= 0.9580\n",
      "Iter 175, Loss= 0.7971, Acc= 0.8560, Top-5 Acc= 0.9480\n",
      "Iter 200, Loss= 0.7827, Acc= 0.8620, Top-5 Acc= 0.9610\n",
      "Iter 225, Loss= 0.6961, Acc= 0.8680, Top-5 Acc= 0.9600\n",
      "Iter 250, Loss= 0.7035, Acc= 0.8730, Top-5 Acc= 0.9620\n",
      "Iter 275, Loss= 0.7355, Acc= 0.8610, Top-5 Acc= 0.9680\n",
      "Iter 300, Loss= 0.7920, Acc= 0.8640, Top-5 Acc= 0.9580\n",
      "Iter 325, Loss= 0.7206, Acc= 0.8620, Top-5 Acc= 0.9620\n",
      "Iter 350, Loss= 0.7962, Acc= 0.8630, Top-5 Acc= 0.9560\n",
      "Iter 375, Loss= 0.7167, Acc= 0.8620, Top-5 Acc= 0.9640\n",
      "Iter 400, Loss= 0.7692, Acc= 0.8600, Top-5 Acc= 0.9560\n",
      "Iter 425, Loss= 0.7184, Acc= 0.8710, Top-5 Acc= 0.9650\n",
      "Iter 450, Loss= 0.7183, Acc= 0.8640, Top-5 Acc= 0.9580\n",
      "Iter 475, Loss= 0.7623, Acc= 0.8620, Top-5 Acc= 0.9600\n",
      "Iter 500, Loss= 0.7467, Acc= 0.8670, Top-5 Acc= 0.9610\n",
      "Iter 525, Loss= 0.6891, Acc= 0.8640, Top-5 Acc= 0.9600\n",
      "Iter 550, Loss= 0.6965, Acc= 0.8700, Top-5 Acc= 0.9640\n",
      "Iter 575, Loss= 0.6735, Acc= 0.8660, Top-5 Acc= 0.9660\n",
      "Iter 600, Loss= 0.8045, Acc= 0.8530, Top-5 Acc= 0.9580\n",
      "Iter 625, Loss= 0.7145, Acc= 0.8630, Top-5 Acc= 0.9610\n",
      "Iter 650, Loss= 0.7604, Acc= 0.8590, Top-5 Acc= 0.9610\n",
      "Iter 675, Loss= 0.7878, Acc= 0.8610, Top-5 Acc= 0.9500\n",
      "Iter 700, Loss= 0.7261, Acc= 0.8650, Top-5 Acc= 0.9500\n",
      "Iter 725, Loss= 0.7128, Acc= 0.8580, Top-5 Acc= 0.9590\n",
      "Iter 750, Loss= 0.8016, Acc= 0.8630, Top-5 Acc= 0.9590\n",
      "Iter 775, Loss= 0.6733, Acc= 0.8760, Top-5 Acc= 0.9620\n",
      "Iter 800, Loss= 0.7588, Acc= 0.8570, Top-5 Acc= 0.9500\n",
      "Iter 825, Loss= 0.8797, Acc= 0.8430, Top-5 Acc= 0.9530\n",
      "Iter 850, Loss= 0.7239, Acc= 0.8610, Top-5 Acc= 0.9630\n",
      "Iter 875, Loss= 0.7667, Acc= 0.8530, Top-5 Acc= 0.9510\n",
      "Iter 900, Loss= 0.8700, Acc= 0.8490, Top-5 Acc= 0.9550\n",
      "Iter 925, Loss= 0.7410, Acc= 0.8590, Top-5 Acc= 0.9550\n",
      "Iter 950, Loss= 0.8692, Acc= 0.8400, Top-5 Acc= 0.9560\n",
      "Iter 975, Loss= 0.6875, Acc= 0.8680, Top-5 Acc= 0.9590\n",
      "Iter 1000, Loss= 0.8644, Acc= 0.8460, Top-5 Acc= 0.9600\n",
      "====================================\n",
      "Epoch 19: Loss=0.761949121952 Acc=0.860599756241 Top-5 Acc=0.958399713039\n",
      "====================================\n",
      "==== EPOCH 20 ====\n",
      "Iter 25, Loss= 0.7964, Acc= 0.8530, Top-5 Acc= 0.9590\n",
      "Iter 50, Loss= 0.7578, Acc= 0.8480, Top-5 Acc= 0.9630\n",
      "Iter 75, Loss= 0.7913, Acc= 0.8520, Top-5 Acc= 0.9590\n",
      "Iter 100, Loss= 0.7383, Acc= 0.8660, Top-5 Acc= 0.9560\n",
      "Iter 125, Loss= 0.7209, Acc= 0.8650, Top-5 Acc= 0.9610\n",
      "Iter 150, Loss= 0.7485, Acc= 0.8660, Top-5 Acc= 0.9610\n",
      "Iter 175, Loss= 0.6626, Acc= 0.8740, Top-5 Acc= 0.9570\n",
      "Iter 200, Loss= 0.8895, Acc= 0.8360, Top-5 Acc= 0.9510\n",
      "Iter 225, Loss= 0.8276, Acc= 0.8540, Top-5 Acc= 0.9580\n",
      "Iter 250, Loss= 0.7542, Acc= 0.8650, Top-5 Acc= 0.9620\n",
      "Iter 275, Loss= 0.7769, Acc= 0.8580, Top-5 Acc= 0.9560\n",
      "Iter 300, Loss= 0.6826, Acc= 0.8660, Top-5 Acc= 0.9650\n",
      "Iter 325, Loss= 0.7529, Acc= 0.8590, Top-5 Acc= 0.9470\n",
      "Iter 350, Loss= 0.8060, Acc= 0.8590, Top-5 Acc= 0.9540\n",
      "Iter 375, Loss= 0.7401, Acc= 0.8540, Top-5 Acc= 0.9560\n",
      "Iter 400, Loss= 0.7934, Acc= 0.8510, Top-5 Acc= 0.9560\n",
      "Iter 425, Loss= 0.8187, Acc= 0.8540, Top-5 Acc= 0.9560\n",
      "Iter 450, Loss= 0.7344, Acc= 0.8680, Top-5 Acc= 0.9610\n",
      "Iter 475, Loss= 0.6464, Acc= 0.8770, Top-5 Acc= 0.9690\n",
      "Iter 500, Loss= 0.7383, Acc= 0.8490, Top-5 Acc= 0.9590\n",
      "Iter 525, Loss= 0.7585, Acc= 0.8580, Top-5 Acc= 0.9610\n",
      "Iter 550, Loss= 0.7729, Acc= 0.8550, Top-5 Acc= 0.9520\n",
      "Iter 575, Loss= 0.7794, Acc= 0.8540, Top-5 Acc= 0.9560\n",
      "Iter 600, Loss= 0.7238, Acc= 0.8660, Top-5 Acc= 0.9600\n",
      "Iter 625, Loss= 0.7233, Acc= 0.8660, Top-5 Acc= 0.9680\n",
      "Iter 650, Loss= 0.8039, Acc= 0.8490, Top-5 Acc= 0.9500\n",
      "Iter 675, Loss= 0.7535, Acc= 0.8550, Top-5 Acc= 0.9480\n",
      "Iter 700, Loss= 0.7830, Acc= 0.8600, Top-5 Acc= 0.9530\n",
      "Iter 725, Loss= 0.8047, Acc= 0.8520, Top-5 Acc= 0.9560\n",
      "Iter 750, Loss= 0.8526, Acc= 0.8500, Top-5 Acc= 0.9550\n",
      "Iter 775, Loss= 0.7319, Acc= 0.8720, Top-5 Acc= 0.9570\n",
      "Iter 800, Loss= 0.8176, Acc= 0.8520, Top-5 Acc= 0.9570\n",
      "Iter 825, Loss= 0.7531, Acc= 0.8540, Top-5 Acc= 0.9520\n",
      "Iter 850, Loss= 0.7985, Acc= 0.8600, Top-5 Acc= 0.9490\n",
      "Iter 875, Loss= 0.8238, Acc= 0.8520, Top-5 Acc= 0.9500\n",
      "Iter 900, Loss= 0.7806, Acc= 0.8510, Top-5 Acc= 0.9560\n",
      "Iter 925, Loss= 0.6985, Acc= 0.8720, Top-5 Acc= 0.9550\n",
      "Iter 950, Loss= 0.8536, Acc= 0.8500, Top-5 Acc= 0.9480\n",
      "Iter 975, Loss= 0.8088, Acc= 0.8600, Top-5 Acc= 0.9590\n",
      "Iter 1000, Loss= 0.7791, Acc= 0.8650, Top-5 Acc= 0.9530\n",
      "====================================\n",
      "Epoch 20: Loss=0.765087008476 Acc=0.86059987545 Top-5 Acc=0.958599686623\n",
      "====================================\n",
      "==== EPOCH 21 ====\n",
      "Iter 25, Loss= 0.7347, Acc= 0.8490, Top-5 Acc= 0.9580\n",
      "Iter 50, Loss= 0.7522, Acc= 0.8720, Top-5 Acc= 0.9630\n",
      "Iter 75, Loss= 0.7878, Acc= 0.8620, Top-5 Acc= 0.9570\n",
      "Iter 100, Loss= 0.8254, Acc= 0.8490, Top-5 Acc= 0.9540\n",
      "Iter 125, Loss= 0.8170, Acc= 0.8460, Top-5 Acc= 0.9540\n",
      "Iter 150, Loss= 0.7260, Acc= 0.8610, Top-5 Acc= 0.9660\n",
      "Iter 175, Loss= 0.6953, Acc= 0.8660, Top-5 Acc= 0.9580\n",
      "Iter 200, Loss= 0.7418, Acc= 0.8640, Top-5 Acc= 0.9510\n",
      "Iter 225, Loss= 0.7774, Acc= 0.8660, Top-5 Acc= 0.9570\n",
      "Iter 250, Loss= 0.8109, Acc= 0.8450, Top-5 Acc= 0.9580\n",
      "Iter 275, Loss= 0.6757, Acc= 0.8730, Top-5 Acc= 0.9570\n",
      "Iter 300, Loss= 0.7535, Acc= 0.8590, Top-5 Acc= 0.9580\n",
      "Iter 325, Loss= 0.7057, Acc= 0.8670, Top-5 Acc= 0.9630\n",
      "Iter 350, Loss= 0.7957, Acc= 0.8560, Top-5 Acc= 0.9570\n",
      "Iter 375, Loss= 0.7159, Acc= 0.8690, Top-5 Acc= 0.9660\n",
      "Iter 400, Loss= 0.7151, Acc= 0.8690, Top-5 Acc= 0.9520\n",
      "Iter 425, Loss= 0.6826, Acc= 0.8770, Top-5 Acc= 0.9610\n",
      "Iter 450, Loss= 0.6331, Acc= 0.8810, Top-5 Acc= 0.9730\n",
      "Iter 475, Loss= 0.8105, Acc= 0.8500, Top-5 Acc= 0.9580\n",
      "Iter 500, Loss= 0.8252, Acc= 0.8520, Top-5 Acc= 0.9550\n",
      "Iter 525, Loss= 0.7580, Acc= 0.8630, Top-5 Acc= 0.9630\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-365-08fc33b99dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-314-94d2b6abd53a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, X, Y, Xt, Yt, epochs, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iter \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Loss= \"\u001b[0m \u001b[0;34m+\u001b[0m                           \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Acc= \"\u001b[0m \u001b[0;34m+\u001b[0m                           \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Top-5 Acc= \"\u001b[0m \u001b[0;34m+\u001b[0m                           \u001b[0;34m\"{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop5acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-314-94d2b6abd53a>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(self, sess, Xt, yt, size, step)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTop5Accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-314-94d2b6abd53a>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, sess, Xt, size, step, randomize)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrandomize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0m_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ens.train(sess, ensX, Y, ensXt, Yt, epochs=30, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ens.saver.restore(sess, \"conv_rnn_prelogits/{}.tfmodel\".format(\"fc_ensemble_all_augmented\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.73017883, 0.85859978, 0.95979977)\n"
     ]
    }
   ],
   "source": [
    "print(ens.calculate_loss(sess, ensXt, Yt, size=Xt.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predXt = ens.predict_proba(sess, ensXt, size=ensXt.shape[0], randomize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas2 = [ ensemble_models(probas_testing[3:9]), predXt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas2_ensemble = ensemble_models(probas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.86539978, 0.96719968)\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = lambda enslist: reduce(lambda p1, p2: p1 + p2, enslist) / len(enslist)\n",
    "with tf.Session() as sess:\n",
    "    idx = range(3,6)+range(6,9)\n",
    "    acc, top5acc = sess.run([accuracy_test, top_5_accuracy_test], feed_dict={probs_test: probas2_ensemble, y_test: Yt})\n",
    "    print(acc, top5acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
