{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "from matplotlib.mlab import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='RNN-CNN Network.')\n",
    "parser.add_argument('--depth', default=4, help='Depth of the RNN network')\n",
    "parser.add_argument('--hidden', default=128, help='Hidden units of the RNN network')\n",
    "parser.add_argument('--gpu', default=3, help='GPU to use for train')\n",
    "parser.add_argument('--rot', default=0, help='RNN Rotation')\n",
    "parser.add_argument('--name', default=\"rnn_augmented_with_4_rotations\", help='Name of the RNN model to use for train')\n",
    "parser.add_argument('--predict', default=\"no\", help='RNN Rotation')\n",
    "args, unknown_args = parser.parse_known_args()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename=\"logs/{}.log\".format(args.name), format='%(message)s', level=logging.DEBUG)\n",
    "logging.info(\"Hello from logging ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random, sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG16 Features\n",
    "# tinyImageNetDir = \"/home/devyhia/vgg\"\n",
    "# X, Y = np.load(\"{}/features/vgg16_12_Adagrad.fc2.X.npy\".format(tinyImageNetDir)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "# Xt, Yt = np.load(\"{}/features/vgg16_12_Adagrad.fc2.Xt.npy\".format(tinyImageNetDir)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inception V4 Features\n",
    "tinyImageNetDir = \"/home/devyhia/vgg\"\n",
    "X, Y = np.load(\"features/model2.PreLogitsFlatten.X.npy\".format(tinyImageNetDir)), np.load(\"{}/y.npy\".format(tinyImageNetDir))\n",
    "Xt, Yt = np.load(\"features/model2.PreLogitsFlatten.Xt.npy\".format(tinyImageNetDir)), np.load(\"{}/yt.npy\".format(tinyImageNetDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tiny Images Raw Data\n",
    "tinyImageNetDir = \"/home/devyhia/vgg\"\n",
    "rawX = np.load(\"{}/X.npy\".format(tinyImageNetDir))\n",
    "rawXt = np.load(\"{}/Xt.npy\".format(tinyImageNetDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = np.array([np.hstack([prelogX[0].reshape(24, 64), rawX[0].reshape(24, 512)]) for i in range(prelogX.shape[0])])\n",
    "# Xt = np.array([np.hstack([prelogXt[0].reshape(24, 64), rawXt[0].reshape(24, 512)]) for i in range(prelogXt.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reverse Sequence\n",
    "# reverse_idx = list(reversed(range(X.shape[1])))\n",
    "# X = X[:, reverse_idx]\n",
    "# Xt = Xt[:, reverse_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "display_step = 25\n",
    "epochs = 10\n",
    "depth = 4\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 64 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 64 # timesteps\n",
    "n_hidden = 128\n",
    "n_classes = 100 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float32\", [None, X.shape[1]])\n",
    "y = tf.placeholder(\"float32\", [None, n_classes])\n",
    "\n",
    "# Images to be passed\n",
    "x_raw = tf.placeholder(\"float32\", [None, 64, 64, 3])\n",
    "x_raw_gray_0 = tf.image.rgb_to_grayscale(x_raw)\n",
    "x_raw_gray_90 = tf.map_fn(lambda _img: tf.image.rot90(_img, 1), x_raw_gray_0)\n",
    "x_raw_gray_180 = tf.map_fn(lambda _img: tf.image.rot90(_img, 2), x_raw_gray_0)\n",
    "x_raw_gray_270 = tf.map_fn(lambda _img: tf.image.rot90(_img, 3), x_raw_gray_0)\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "def RNN(x, weights, biases, scope=\"RNN\"):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    x = tf.reshape(x, (-1, n_steps, n_input))\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(0, n_steps, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    #     , forget_bias=1.0\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    \n",
    "    multi_cells = rnn_cell.MultiRNNCell([lstm_cell] * depth, state_is_tuple=True)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(multi_cells, x, dtype=tf.float32, scope=scope)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "\n",
    "if args.rot == 0:\n",
    "    pred_rnn_x_raw = RNN(x_raw_gray_0, weights, biases, scope=\"RNN_0\")\n",
    "elif args.rot == 1:\n",
    "    pred_rnn_x_raw = RNN(x_raw_gray_90, weights, biases, scope=\"RNN_90\")\n",
    "elif args.rot == 2:\n",
    "    pred_rnn_x_raw = RNN(x_raw_gray_180, weights, biases, scope=\"RNN_180\")\n",
    "elif args.rot == 3:\n",
    "    pred_rnn_x_raw = RNN(x_raw_gray_270, weights, biases, scope=\"RNN_270\")\n",
    "else:\n",
    "    pred_rnn_x_raw = RNN(x_raw_gray_0, weights, biases, scope=\"RNN_0\")\n",
    "    \n",
    "pred_fc = slim.fully_connected(x, n_classes, activation_fn=None)\n",
    "\n",
    "pred = pred_fc + pred_rnn_x_raw # + pred_rnn_x_raw_90 # + pred_rnn_x_raw_180 + pred_rnn_x_raw_270\n",
    "prob = tf.nn.softmax(pred)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "top5_correct_pred = tf.nn.in_top_k(prob, tf.argmax(y,1), 5)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "top5accuracy = tf.reduce_mean(tf.cast(top5_correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def __iterate_minibatches(_X, _rawX, _y, size):\n",
    "    if _X.shape[0] % size > 0:\n",
    "        raise \"The minibatch size should be a divisor of the batch size.\"\n",
    "\n",
    "    idx = np.arange(_X.shape[0]).astype(np.int32)\n",
    "    np.random.shuffle(idx) # in-place shuffling\n",
    "    for i in range(_X.shape[0] / size):\n",
    "        # To randomize the minibatches every time\n",
    "        _idx = idx[i*size:(i+1)*size]\n",
    "        yield _X[_idx], _rawX[_idx], _y[_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_screen(msg):\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba(sess, Xt, rawXt, size=1000, step=10, randomize=True):\n",
    "    preds, probs = [], []\n",
    "    idx = range(0, Xt.shape[0])\n",
    "    sample_idx = random.sample(idx, size) if randomize else idx\n",
    "    for i in range(size / step):\n",
    "        itr = sample_idx[i*step:(i+1)*step]\n",
    "        _pred, _prob = sess.run([pred, prob], feed_dict={x: Xt[itr], x_raw: rawXt[itr]})\n",
    "        preds.append(_pred)\n",
    "        probs.append(_prob)\n",
    "#         update_screen(\"\\r{} of {}\".format(i, size / step))\n",
    "    \n",
    "#     update_screen(\"\\n\")\n",
    "    preds = np.vstack(preds)\n",
    "    probs = np.vstack(probs)\n",
    "    \n",
    "    return preds, probs, sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(sess, Xt, rawXt, yt, size=1000, step=10):\n",
    "    preds, probs, sample_idx = predict_proba(sess, Xt, rawXt, size=size, step=step)\n",
    "\n",
    "    loss, acc, top5acc = sess.run([cost, accuracy, top5accuracy], feed_dict={pred: preds, y: yt[sample_idx]})\n",
    "\n",
    "    return loss, acc, top5acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Launch the graph\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.25)\n",
    "    config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(init)\n",
    "        prev_acc = 0.0\n",
    "        for ep in range(epochs):\n",
    "            logging.info(\"==== EPOCH {} ====\".format(ep))\n",
    "            step = 1\n",
    "            for _X, _rawX, _Y in __iterate_minibatches(X, rawX, Y, batch_size):\n",
    "                sess.run(optimizer, feed_dict={x: _X, x_raw: _rawX, y: _Y})\n",
    "                if step % display_step == 0:\n",
    "                    loss, acc, top5acc = calculate_loss(sess, Xt, rawXt, Yt)\n",
    "                    logging.info(\"Iter \" + str(step) + \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Acc= \" + \\\n",
    "                          \"{:.4f}\".format(acc) + \", Top-5 Acc= \" + \\\n",
    "                          \"{:.4f}\".format(top5acc))\n",
    "                step += 1\n",
    "\n",
    "            loss, acc, top5acc = calculate_loss(sess, Xt, rawXt, Yt, size=Xt.shape[0])\n",
    "            logging.info(\"====================================\")\n",
    "            logging.info(\"Epoch {}: Loss={} Acc={} Top-5 Acc={}\".format(ep, loss, acc, top5acc))\n",
    "            logging.info(\"====================================\")\n",
    "            if acc > prev_acc:\n",
    "                prev_acc = acc\n",
    "                saver.save(sess, \"conv_rnn_prelogits/{}.tfmodel\".format(args.name))\n",
    "                logging.info(\"++++ Saved BEST ACC\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_predictions():\n",
    "    # Launch the graph\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.25)\n",
    "    config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(init)\n",
    "        saver.restore(sess, \"conv_rnn_prelogits/{}.tfmodel\".format(args.name))\n",
    "        res = predict_proba(sess, Xt, rawXt, size=Xt.shape[0], randomize=False)\n",
    "        np.save(\"probs/{}.probs.npy\".format(args.name), res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EPOCH 0 ====\n",
      "Iter 25, Loss= 1.8993, Acc= 0.7480, Top-5 Acc= 0.8850\n",
      "Iter 50, Loss= 0.7278, Acc= 0.8630, Top-5 Acc= 0.9420\n",
      "Iter 75, Loss= 0.7011, Acc= 0.8460, Top-5 Acc= 0.9450\n",
      "Iter 100, Loss= 0.6073, Acc= 0.8550, Top-5 Acc= 0.9540\n",
      "Iter 125, Loss= 0.5933, Acc= 0.8650, Top-5 Acc= 0.9510\n",
      "Iter 150, Loss= 0.6610, Acc= 0.8580, Top-5 Acc= 0.9430\n",
      "Iter 175, Loss= 0.7193, Acc= 0.8300, Top-5 Acc= 0.9430\n",
      "Iter 200, Loss= 0.5793, Acc= 0.8750, Top-5 Acc= 0.9580\n",
      "Iter 225, Loss= 0.5828, Acc= 0.8760, Top-5 Acc= 0.9590\n",
      "Iter 250, Loss= 0.5892, Acc= 0.8710, Top-5 Acc= 0.9550\n",
      "Iter 275, Loss= 0.5922, Acc= 0.8750, Top-5 Acc= 0.9550\n",
      "Iter 300, Loss= 0.6589, Acc= 0.8520, Top-5 Acc= 0.9440\n",
      "Iter 325, Loss= 0.7013, Acc= 0.8420, Top-5 Acc= 0.9570\n",
      "Iter 350, Loss= 0.7114, Acc= 0.8530, Top-5 Acc= 0.9540\n",
      "Iter 375, Loss= 0.5996, Acc= 0.8570, Top-5 Acc= 0.9620\n",
      "Iter 400, Loss= 0.6325, Acc= 0.8700, Top-5 Acc= 0.9540\n",
      "Iter 425, Loss= 0.7158, Acc= 0.8510, Top-5 Acc= 0.9450\n",
      "Iter 450, Loss= 0.6639, Acc= 0.8540, Top-5 Acc= 0.9480\n",
      "Iter 475, Loss= 0.6485, Acc= 0.8670, Top-5 Acc= 0.9460\n",
      "Iter 500, Loss= 0.8056, Acc= 0.8440, Top-5 Acc= 0.9520\n",
      "Iter 525, Loss= 0.7072, Acc= 0.8550, Top-5 Acc= 0.9520\n",
      "Iter 550, Loss= 0.6695, Acc= 0.8600, Top-5 Acc= 0.9530\n",
      "Iter 575, Loss= 0.6527, Acc= 0.8600, Top-5 Acc= 0.9600\n",
      "Iter 600, Loss= 0.6841, Acc= 0.8600, Top-5 Acc= 0.9500\n",
      "Iter 625, Loss= 0.7154, Acc= 0.8590, Top-5 Acc= 0.9510\n",
      "Iter 650, Loss= 0.7134, Acc= 0.8600, Top-5 Acc= 0.9480\n",
      "Iter 675, Loss= 0.6360, Acc= 0.8670, Top-5 Acc= 0.9540\n",
      "Iter 700, Loss= 0.7147, Acc= 0.8530, Top-5 Acc= 0.9570\n",
      "Iter 725, Loss= 0.7591, Acc= 0.8520, Top-5 Acc= 0.9540\n",
      "Iter 750, Loss= 0.7392, Acc= 0.8570, Top-5 Acc= 0.9500\n",
      "Iter 775, Loss= 0.7888, Acc= 0.8500, Top-5 Acc= 0.9460\n",
      "Iter 800, Loss= 0.7307, Acc= 0.8480, Top-5 Acc= 0.9580\n",
      "Iter 825, Loss= 0.8169, Acc= 0.8390, Top-5 Acc= 0.9470\n",
      "Iter 850, Loss= 0.7036, Acc= 0.8580, Top-5 Acc= 0.9560\n",
      "Iter 875, Loss= 0.8298, Acc= 0.8470, Top-5 Acc= 0.9410\n",
      "Iter 900, Loss= 0.6826, Acc= 0.8620, Top-5 Acc= 0.9540\n",
      "Iter 925, Loss= 0.8081, Acc= 0.8610, Top-5 Acc= 0.9380\n",
      "Iter 950, Loss= 0.7366, Acc= 0.8600, Top-5 Acc= 0.9410\n",
      "Iter 975, Loss= 0.7909, Acc= 0.8510, Top-5 Acc= 0.9490\n",
      "Iter 1000, Loss= 0.8361, Acc= 0.8510, Top-5 Acc= 0.9390\n",
      "====================================\n",
      "Epoch 0: Loss=0.773652791977 Acc=0.855799794197 Top-5 Acc=0.948199689388\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 1 ====\n",
      "Iter 25, Loss= 0.7211, Acc= 0.8600, Top-5 Acc= 0.9500\n",
      "Iter 50, Loss= 0.6384, Acc= 0.8680, Top-5 Acc= 0.9660\n",
      "Iter 75, Loss= 0.6290, Acc= 0.8830, Top-5 Acc= 0.9590\n",
      "Iter 100, Loss= 0.7429, Acc= 0.8540, Top-5 Acc= 0.9530\n",
      "Iter 125, Loss= 0.7453, Acc= 0.8720, Top-5 Acc= 0.9570\n",
      "Iter 150, Loss= 0.7818, Acc= 0.8560, Top-5 Acc= 0.9550\n",
      "Iter 175, Loss= 0.7462, Acc= 0.8630, Top-5 Acc= 0.9610\n",
      "Iter 200, Loss= 0.7769, Acc= 0.8500, Top-5 Acc= 0.9510\n",
      "Iter 225, Loss= 0.8546, Acc= 0.8520, Top-5 Acc= 0.9430\n",
      "Iter 250, Loss= 0.7678, Acc= 0.8530, Top-5 Acc= 0.9480\n",
      "Iter 275, Loss= 0.7650, Acc= 0.8490, Top-5 Acc= 0.9580\n",
      "Iter 300, Loss= 0.6793, Acc= 0.8620, Top-5 Acc= 0.9570\n",
      "Iter 325, Loss= 0.8225, Acc= 0.8600, Top-5 Acc= 0.9490\n",
      "Iter 350, Loss= 0.8493, Acc= 0.8480, Top-5 Acc= 0.9510\n",
      "Iter 375, Loss= 0.7661, Acc= 0.8670, Top-5 Acc= 0.9560\n",
      "Iter 400, Loss= 0.6641, Acc= 0.8850, Top-5 Acc= 0.9610\n",
      "Iter 425, Loss= 0.7181, Acc= 0.8640, Top-5 Acc= 0.9600\n",
      "Iter 450, Loss= 0.7688, Acc= 0.8650, Top-5 Acc= 0.9530\n",
      "Iter 475, Loss= 0.7539, Acc= 0.8530, Top-5 Acc= 0.9620\n",
      "Iter 500, Loss= 0.8505, Acc= 0.8310, Top-5 Acc= 0.9380\n",
      "Iter 525, Loss= 0.7942, Acc= 0.8610, Top-5 Acc= 0.9480\n",
      "Iter 550, Loss= 0.7219, Acc= 0.8730, Top-5 Acc= 0.9570\n",
      "Iter 575, Loss= 0.8160, Acc= 0.8600, Top-5 Acc= 0.9460\n",
      "Iter 600, Loss= 0.8211, Acc= 0.8550, Top-5 Acc= 0.9520\n",
      "Iter 625, Loss= 0.8425, Acc= 0.8590, Top-5 Acc= 0.9500\n",
      "Iter 650, Loss= 0.8959, Acc= 0.8460, Top-5 Acc= 0.9430\n",
      "Iter 675, Loss= 0.8154, Acc= 0.8590, Top-5 Acc= 0.9560\n",
      "Iter 700, Loss= 0.8350, Acc= 0.8460, Top-5 Acc= 0.9580\n",
      "Iter 725, Loss= 0.8134, Acc= 0.8640, Top-5 Acc= 0.9440\n",
      "Iter 750, Loss= 0.8093, Acc= 0.8580, Top-5 Acc= 0.9500\n",
      "Iter 775, Loss= 0.9007, Acc= 0.8460, Top-5 Acc= 0.9490\n",
      "Iter 800, Loss= 0.8287, Acc= 0.8560, Top-5 Acc= 0.9510\n",
      "Iter 825, Loss= 0.8464, Acc= 0.8620, Top-5 Acc= 0.9450\n",
      "Iter 850, Loss= 0.7887, Acc= 0.8590, Top-5 Acc= 0.9550\n",
      "Iter 875, Loss= 0.8124, Acc= 0.8590, Top-5 Acc= 0.9550\n",
      "Iter 900, Loss= 0.8749, Acc= 0.8510, Top-5 Acc= 0.9510\n",
      "Iter 925, Loss= 0.7661, Acc= 0.8600, Top-5 Acc= 0.9570\n",
      "Iter 950, Loss= 0.7913, Acc= 0.8450, Top-5 Acc= 0.9520\n",
      "Iter 975, Loss= 0.8806, Acc= 0.8560, Top-5 Acc= 0.9400\n",
      "Iter 1000, Loss= 0.9322, Acc= 0.8570, Top-5 Acc= 0.9430\n",
      "====================================\n",
      "Epoch 1: Loss=0.834879755974 Acc=0.85599976778 Top-5 Acc=0.95159971714\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 2 ====\n",
      "Iter 25, Loss= 0.7381, Acc= 0.8770, Top-5 Acc= 0.9610\n",
      "Iter 50, Loss= 0.7819, Acc= 0.8640, Top-5 Acc= 0.9570\n",
      "Iter 75, Loss= 0.8529, Acc= 0.8560, Top-5 Acc= 0.9510\n",
      "Iter 100, Loss= 0.7867, Acc= 0.8690, Top-5 Acc= 0.9520\n",
      "Iter 125, Loss= 0.8226, Acc= 0.8610, Top-5 Acc= 0.9600\n",
      "Iter 150, Loss= 0.8538, Acc= 0.8510, Top-5 Acc= 0.9550\n",
      "Iter 175, Loss= 0.7809, Acc= 0.8630, Top-5 Acc= 0.9580\n",
      "Iter 200, Loss= 0.8114, Acc= 0.8650, Top-5 Acc= 0.9540\n",
      "Iter 225, Loss= 0.8916, Acc= 0.8560, Top-5 Acc= 0.9470\n",
      "Iter 250, Loss= 0.7451, Acc= 0.8700, Top-5 Acc= 0.9570\n",
      "Iter 275, Loss= 0.8940, Acc= 0.8310, Top-5 Acc= 0.9500\n",
      "Iter 300, Loss= 0.8403, Acc= 0.8570, Top-5 Acc= 0.9520\n",
      "Iter 325, Loss= 0.8240, Acc= 0.8550, Top-5 Acc= 0.9560\n",
      "Iter 350, Loss= 0.8284, Acc= 0.8590, Top-5 Acc= 0.9500\n",
      "Iter 375, Loss= 0.8819, Acc= 0.8560, Top-5 Acc= 0.9590\n",
      "Iter 400, Loss= 0.7316, Acc= 0.8750, Top-5 Acc= 0.9610\n",
      "Iter 425, Loss= 0.7014, Acc= 0.8710, Top-5 Acc= 0.9620\n",
      "Iter 450, Loss= 0.8921, Acc= 0.8470, Top-5 Acc= 0.9610\n",
      "Iter 475, Loss= 0.8932, Acc= 0.8620, Top-5 Acc= 0.9510\n",
      "Iter 500, Loss= 0.8567, Acc= 0.8520, Top-5 Acc= 0.9490\n",
      "Iter 525, Loss= 0.8518, Acc= 0.8590, Top-5 Acc= 0.9520\n",
      "Iter 550, Loss= 0.8686, Acc= 0.8410, Top-5 Acc= 0.9630\n",
      "Iter 575, Loss= 0.8664, Acc= 0.8650, Top-5 Acc= 0.9560\n",
      "Iter 600, Loss= 0.9289, Acc= 0.8470, Top-5 Acc= 0.9540\n",
      "Iter 625, Loss= 0.8384, Acc= 0.8540, Top-5 Acc= 0.9510\n",
      "Iter 650, Loss= 0.8723, Acc= 0.8570, Top-5 Acc= 0.9550\n",
      "Iter 675, Loss= 0.8821, Acc= 0.8610, Top-5 Acc= 0.9520\n",
      "Iter 700, Loss= 0.8142, Acc= 0.8620, Top-5 Acc= 0.9610\n",
      "Iter 725, Loss= 0.8074, Acc= 0.8610, Top-5 Acc= 0.9550\n",
      "Iter 750, Loss= 0.9283, Acc= 0.8500, Top-5 Acc= 0.9470\n",
      "Iter 775, Loss= 0.7331, Acc= 0.8800, Top-5 Acc= 0.9640\n",
      "Iter 800, Loss= 0.9326, Acc= 0.8430, Top-5 Acc= 0.9500\n",
      "Iter 825, Loss= 0.9115, Acc= 0.8460, Top-5 Acc= 0.9560\n",
      "Iter 850, Loss= 0.8389, Acc= 0.8600, Top-5 Acc= 0.9570\n",
      "Iter 875, Loss= 0.9630, Acc= 0.8540, Top-5 Acc= 0.9500\n",
      "Iter 900, Loss= 0.8383, Acc= 0.8670, Top-5 Acc= 0.9520\n",
      "Iter 925, Loss= 0.7709, Acc= 0.8720, Top-5 Acc= 0.9540\n",
      "Iter 950, Loss= 0.8116, Acc= 0.8630, Top-5 Acc= 0.9580\n",
      "Iter 975, Loss= 0.8892, Acc= 0.8470, Top-5 Acc= 0.9570\n",
      "Iter 1000, Loss= 0.9050, Acc= 0.8570, Top-5 Acc= 0.9490\n",
      "====================================\n",
      "Epoch 2: Loss=0.86204880476 Acc=0.859999716282 Top-5 Acc=0.95519977808\n",
      "====================================\n",
      "++++ Saved BEST ACC\n",
      "==== EPOCH 3 ====\n",
      "Iter 25, Loss= 0.9331, Acc= 0.8580, Top-5 Acc= 0.9570\n",
      "Iter 50, Loss= 0.8500, Acc= 0.8550, Top-5 Acc= 0.9570\n",
      "Iter 75, Loss= 0.8948, Acc= 0.8490, Top-5 Acc= 0.9620\n",
      "Iter 100, Loss= 0.9047, Acc= 0.8430, Top-5 Acc= 0.9510\n",
      "Iter 125, Loss= 1.0108, Acc= 0.8390, Top-5 Acc= 0.9470\n",
      "Iter 150, Loss= 0.9034, Acc= 0.8480, Top-5 Acc= 0.9520\n",
      "Iter 175, Loss= 1.0437, Acc= 0.8370, Top-5 Acc= 0.9500\n",
      "Iter 200, Loss= 0.9245, Acc= 0.8460, Top-5 Acc= 0.9520\n",
      "Iter 225, Loss= 0.8319, Acc= 0.8670, Top-5 Acc= 0.9590\n",
      "Iter 250, Loss= 0.9341, Acc= 0.8530, Top-5 Acc= 0.9450\n",
      "Iter 275, Loss= 0.8294, Acc= 0.8610, Top-5 Acc= 0.9540\n",
      "Iter 300, Loss= 0.8049, Acc= 0.8580, Top-5 Acc= 0.9600\n",
      "Iter 325, Loss= 0.8967, Acc= 0.8550, Top-5 Acc= 0.9560\n",
      "Iter 350, Loss= 0.9301, Acc= 0.8500, Top-5 Acc= 0.9520\n",
      "Iter 375, Loss= 0.8729, Acc= 0.8570, Top-5 Acc= 0.9530\n",
      "Iter 400, Loss= 0.7401, Acc= 0.8740, Top-5 Acc= 0.9630\n",
      "Iter 425, Loss= 0.7130, Acc= 0.8770, Top-5 Acc= 0.9690\n",
      "Iter 450, Loss= 0.8002, Acc= 0.8810, Top-5 Acc= 0.9570\n",
      "Iter 475, Loss= 0.8057, Acc= 0.8710, Top-5 Acc= 0.9560\n",
      "Iter 500, Loss= 0.8650, Acc= 0.8720, Top-5 Acc= 0.9540\n",
      "Iter 525, Loss= 0.8543, Acc= 0.8670, Top-5 Acc= 0.9570\n",
      "Iter 550, Loss= 0.8700, Acc= 0.8590, Top-5 Acc= 0.9580\n",
      "Iter 575, Loss= 0.8210, Acc= 0.8600, Top-5 Acc= 0.9580\n",
      "Iter 600, Loss= 0.8634, Acc= 0.8510, Top-5 Acc= 0.9590\n",
      "Iter 625, Loss= 0.9741, Acc= 0.8530, Top-5 Acc= 0.9570\n",
      "Iter 650, Loss= 0.9544, Acc= 0.8500, Top-5 Acc= 0.9410\n",
      "Iter 675, Loss= 0.8089, Acc= 0.8650, Top-5 Acc= 0.9650\n",
      "Iter 700, Loss= 0.7995, Acc= 0.8660, Top-5 Acc= 0.9580\n",
      "Iter 725, Loss= 0.8180, Acc= 0.8580, Top-5 Acc= 0.9610\n",
      "Iter 750, Loss= 0.8976, Acc= 0.8610, Top-5 Acc= 0.9540\n",
      "Iter 775, Loss= 0.8350, Acc= 0.8580, Top-5 Acc= 0.9550\n",
      "Iter 800, Loss= 1.0284, Acc= 0.8450, Top-5 Acc= 0.9570\n",
      "Iter 825, Loss= 0.8912, Acc= 0.8540, Top-5 Acc= 0.9610\n",
      "Iter 850, Loss= 1.0157, Acc= 0.8410, Top-5 Acc= 0.9470\n",
      "Iter 875, Loss= 0.9612, Acc= 0.8400, Top-5 Acc= 0.9530\n",
      "Iter 900, Loss= 0.7865, Acc= 0.8590, Top-5 Acc= 0.9570\n",
      "Iter 925, Loss= 0.8235, Acc= 0.8670, Top-5 Acc= 0.9610\n",
      "Iter 950, Loss= 0.7637, Acc= 0.8720, Top-5 Acc= 0.9610\n",
      "Iter 975, Loss= 0.8600, Acc= 0.8620, Top-5 Acc= 0.9580\n",
      "Iter 1000, Loss= 0.9684, Acc= 0.8500, Top-5 Acc= 0.9550\n",
      "====================================\n",
      "Epoch 3: Loss=0.898254930973 Acc=0.858199775219 Top-5 Acc=0.955399692059\n",
      "====================================\n",
      "==== EPOCH 4 ====\n",
      "Iter 25, Loss= 0.8508, Acc= 0.8660, Top-5 Acc= 0.9510\n",
      "Iter 50, Loss= 0.8974, Acc= 0.8450, Top-5 Acc= 0.9650\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-31447a892a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rawX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__iterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_raw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_rawX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deeplearners/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if args.predict == \"no\":\n",
    "    train()\n",
    "else:\n",
    "    print(\"Predicting ...\")\n",
    "    gen_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
